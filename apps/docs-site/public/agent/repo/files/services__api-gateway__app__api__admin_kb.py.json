{
  "path": "services/api-gateway/app/api/admin_kb.py",
  "language": "python",
  "size": 15723,
  "last_modified": "2025-12-04T11:26:45.144Z",
  "lines": 490,
  "content": "\"\"\"\nAdmin Knowledge Base Management API (Phase 5)\n\nProvides endpoints for administrators to manage the medical knowledge base:\n- Upload documents (text/PDF)\n- List indexed documents\n- Delete documents\n- View indexing status\n\nThese endpoints require admin authentication.\n\"\"\"\n\nimport time\nimport uuid\nfrom datetime import datetime, timezone\nfrom typing import List, Optional\n\nfrom app.core.api_envelope import ErrorCodes, error_response, success_response\nfrom app.core.business_metrics import (\n    kb_chunks_total,\n    kb_document_uploads_total,\n    kb_documents_total,\n    kb_indexing_duration,\n)\nfrom app.core.config import settings\nfrom app.core.database import get_db\nfrom app.core.dependencies import ensure_admin_privileges, get_current_admin_or_viewer\nfrom app.core.logging import get_logger\nfrom app.models.document import Document\nfrom app.models.user import User\nfrom app.services.admin_audit_log_service import admin_audit_log_service\nfrom app.services.kb_indexer import IndexingResult, KBIndexer\nfrom fastapi import APIRouter, Depends, File, Request, UploadFile, status\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel\nfrom sqlalchemy.orm import Session\n\nrouter = APIRouter(prefix=\"/api/admin/kb\", tags=[\"admin\", \"kb\"])\nlogger = get_logger(__name__)\n\n\n# Request/Response Models\n\n\nclass DocumentUploadResponse(BaseModel):\n    \"\"\"Response after document upload.\"\"\"\n\n    document_id: str\n    title: str\n    status: str\n    chunks_indexed: int\n    message: str\n\n\nclass DocumentListItem(BaseModel):\n    \"\"\"Document metadata for list response.\"\"\"\n\n    document_id: str\n    title: str\n    source_type: str\n    upload_date: str\n    chunks_indexed: int\n\n\nclass DocumentListResponse(BaseModel):\n    \"\"\"Response for document list endpoint.\"\"\"\n\n    documents: List[DocumentListItem]\n    total: int\n\n\n# Global KB Indexer instance\n# In production, this would be injected via dependency injection\nkb_indexer = KBIndexer(qdrant_url=settings.QDRANT_URL)\n\n\n@router.post(\"/documents\", response_model=dict)\nasync def upload_document(\n    file: UploadFile = File(...),\n    title: Optional[str] = None,\n    source_type: str = \"uploaded\",\n    db: Session = Depends(get_db),\n    current_admin_user: User = Depends(get_current_admin_or_viewer),\n    request: Request = None,\n):\n    \"\"\"\n    Upload and index a document to the knowledge base.\n\n    Supports:\n    - Text files (.txt)\n    - PDF files (.pdf)\n\n    The document will be:\n    1. Extracted (text/PDF)\n    2. Chunked into segments\n    3. Embedded using OpenAI\n    4. Stored in Qdrant vector database\n\n    Args:\n        file: Document file to upload\n        title: Document title (defaults to filename)\n        source_type: Type of source (uploaded, guideline, journal, etc.)\n        db: Database session\n\n    Returns:\n        Upload result with document ID and indexing status\n    \"\"\"\n    ensure_admin_privileges(current_admin_user)\n    try:\n        # Validate file type\n        allowed_extensions = [\".txt\", \".pdf\"]\n        file_extension = None\n        for ext in allowed_extensions:\n            if file.filename.lower().endswith(ext):\n                file_extension = ext\n                break\n\n        if not file_extension:\n            return JSONResponse(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                content=error_response(\n                    code=ErrorCodes.VALIDATION_ERROR,\n                    message=f\"Unsupported file type. Allowed: {', '.join(allowed_extensions)}\",\n                ),\n            )\n\n        # Read file content\n        file_content = await file.read()\n\n        # Generate document ID\n        document_id = str(uuid.uuid4())\n\n        # Use filename as title if not provided\n        doc_title = title or file.filename\n\n        # Track indexing duration (P3.3 - Business Metrics)\n        start_time = time.time()\n\n        # Index the document\n        if file_extension == \".pdf\":\n            result: IndexingResult = await kb_indexer.index_pdf_document(\n                pdf_bytes=file_content,\n                document_id=document_id,\n                title=doc_title,\n                source_type=source_type,\n                metadata={\n                    \"filename\": file.filename,\n                    \"upload_date\": datetime.now(timezone.utc).isoformat(),\n                },\n            )\n        else:  # .txt\n            text_content = file_content.decode(\"utf-8\")\n            result: IndexingResult = await kb_indexer.index_document(\n                content=text_content,\n                document_id=document_id,\n                title=doc_title,\n                source_type=source_type,\n                metadata={\n                    \"filename\": file.filename,\n                    \"upload_date\": datetime.now(timezone.utc).isoformat(),\n                },\n            )\n\n        # Record indexing duration\n        duration = time.time() - start_time\n        kb_indexing_duration.observe(duration)\n\n        # Format response\n        if result.success:\n            # Store document metadata in PostgreSQL\n            try:\n                db_document = Document(\n                    document_id=document_id,\n                    title=doc_title,\n                    source_type=source_type,\n                    filename=file.filename,\n                    file_type=file_extension.lstrip(\".\"),\n                    chunks_indexed=result.chunks_indexed,\n                    indexing_status=\"indexed\",\n                    metadata={\n                        \"upload_date\": datetime.now(timezone.utc).isoformat(),\n                        \"file_size\": len(file_content),\n                    },\n                )\n                db.add(db_document)\n                db.commit()\n                db.refresh(db_document)\n\n                logger.info(f\"Stored document metadata in database: {document_id}\")\n            except Exception as e:\n                logger.error(f\"Failed to store document metadata: {e}\", exc_info=True)\n                db.rollback()\n                # Continue even if metadata storage fails (document is still indexed in vector DB)\n\n            # Track upload metrics (P3.3 - Business Metrics)\n            file_type = file_extension.lstrip(\".\")\n            kb_document_uploads_total.labels(source_type=source_type, file_type=file_type).inc()\n            kb_chunks_total.inc(result.chunks_indexed)\n            kb_documents_total.inc()\n\n            response_data = DocumentUploadResponse(\n                document_id=result.document_id,\n                title=doc_title,\n                status=\"indexed\",\n                chunks_indexed=result.chunks_indexed,\n                message=f\"Successfully indexed document with {result.chunks_indexed} chunks\",\n            )\n\n            logger.info(f\"Successfully uploaded and indexed document: {document_id}\")\n            admin_audit_log_service.log_action(\n                db=db,\n                actor=current_admin_user,\n                action=\"kb.upload\",\n                target_type=\"document\",\n                target_id=document_id,\n                metadata={\"title\": doc_title, \"source_type\": source_type},\n                request=request,\n            )\n\n            return success_response(data=response_data.model_dump(), version=\"2.0.0\")\n        else:\n            logger.error(f\"Failed to index document: {result.error_message}\")\n\n            admin_audit_log_service.log_action(\n                db=db,\n                actor=current_admin_user,\n                action=\"kb.upload\",\n                target_type=\"document\",\n                target_id=document_id,\n                success=False,\n                metadata={\"error\": result.error_message},\n                request=request,\n            )\n\n            return JSONResponse(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                content=error_response(\n                    code=ErrorCodes.INTERNAL_ERROR,\n                    message=f\"Document indexing failed: {result.error_message}\",\n                ),\n            )\n\n    except Exception as e:\n        logger.error(f\"Error uploading document: {e}\", exc_info=True)\n\n        admin_audit_log_service.log_action(\n            db=db,\n            actor=current_admin_user,\n            action=\"kb.upload\",\n            target_type=\"document\",\n            success=False,\n            metadata={\"error\": str(e)},\n            request=request,\n        )\n\n        return JSONResponse(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            content=error_response(\n                code=ErrorCodes.INTERNAL_ERROR,\n                message=f\"Failed to upload document: {str(e)}\",\n            ),\n        )\n\n\n@router.get(\"/documents\", response_model=dict)\nasync def list_documents(\n    skip: int = 0,\n    limit: int = 50,\n    source_type: Optional[str] = None,\n    db: Session = Depends(get_db),\n    current_admin_user: User = Depends(get_current_admin_or_viewer),\n):\n    \"\"\"\n    List all documents in the knowledge base.\n\n    Returns document metadata including:\n    - Document ID\n    - Title\n    - Source type\n    - Upload date\n    - Number of chunks indexed\n\n    Args:\n        skip: Number of documents to skip (pagination)\n        limit: Maximum number of documents to return (max 1000)\n        source_type: Filter by source type (optional)\n        db: Database session\n\n    Returns:\n        List of documents with metadata\n    \"\"\"\n    try:\n        # Enforce maximum limit to prevent excessive queries\n        limit = min(limit, 1000)\n\n        # Query database for document metadata\n        query = db.query(Document).order_by(Document.created_at.desc())\n\n        # Filter by source_type if provided\n        if source_type:\n            query = query.filter(Document.source_type == source_type)\n\n        # Get total count (for pagination)\n        total = query.count()\n\n        # Apply pagination\n        documents = query.offset(skip).limit(limit).all()\n\n        # Convert to response format\n        document_list = [\n            DocumentListItem(\n                document_id=doc.document_id,\n                title=doc.title,\n                source_type=doc.source_type,\n                upload_date=doc.created_at.isoformat(),\n                chunks_indexed=doc.chunks_indexed,\n            )\n            for doc in documents\n        ]\n\n        response_data = DocumentListResponse(documents=document_list, total=total)\n\n        logger.info(\n            f\"Listed {len(document_list)} documents: \"\n            f\"skip={skip}, limit={limit}, source_type={source_type}, total={total}\"\n        )\n\n        return success_response(data=response_data.model_dump(), version=\"2.0.0\")\n\n    except Exception as e:\n        logger.error(f\"Error listing documents: {e}\", exc_info=True)\n\n        return JSONResponse(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            content=error_response(\n                code=ErrorCodes.INTERNAL_ERROR,\n                message=f\"Failed to list documents: {str(e)}\",\n            ),\n        )\n\n\n@router.delete(\"/documents/{document_id}\", response_model=dict)\nasync def delete_document(\n    document_id: str,\n    db: Session = Depends(get_db),\n    current_admin_user: User = Depends(get_current_admin_or_viewer),\n    request: Request = None,\n):\n    \"\"\"\n    Delete a document from the knowledge base.\n\n    Removes all document chunks from the vector database.\n\n    Args:\n        document_id: Document identifier\n        db: Database session\n\n    Returns:\n        Deletion status\n    \"\"\"\n    ensure_admin_privileges(current_admin_user)\n    try:\n        # Delete from PostgreSQL metadata store\n        document = db.query(Document).filter(Document.document_id == document_id).first()\n\n        if not document:\n            return JSONResponse(\n                status_code=status.HTTP_404_NOT_FOUND,\n                content=error_response(\n                    code=ErrorCodes.NOT_FOUND,\n                    message=f\"Document not found: {document_id}\",\n                ),\n            )\n\n        # Delete from vector database\n        vector_success = kb_indexer.delete_document(document_id)\n\n        # Delete from PostgreSQL (even if vector delete fails, cleanup metadata)\n        db.delete(document)\n        db.commit()\n\n        logger.info(\n            f\"Successfully deleted document: {document_id} \"\n            f\"(vector_db={'success' if vector_success else 'failed'}, metadata=success)\"\n        )\n\n        admin_audit_log_service.log_action(\n            db=db,\n            actor=current_admin_user,\n            action=\"kb.delete\",\n            target_type=\"document\",\n            target_id=document_id,\n            metadata={\"vector_deleted\": vector_success},\n            request=request,\n        )\n\n        return success_response(\n            data={\n                \"document_id\": document_id,\n                \"status\": \"deleted\",\n                \"message\": \"Document successfully removed from knowledge base\",\n            },\n            version=\"2.0.0\",\n        )\n\n    except Exception as e:\n        logger.error(f\"Error deleting document {document_id}: {e}\", exc_info=True)\n\n        admin_audit_log_service.log_action(\n            db=db,\n            actor=current_admin_user,\n            action=\"kb.delete\",\n            target_type=\"document\",\n            target_id=document_id,\n            success=False,\n            metadata={\"error\": str(e)},\n            request=request,\n        )\n\n        return JSONResponse(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            content=error_response(\n                code=ErrorCodes.INTERNAL_ERROR,\n                message=f\"Failed to delete document: {str(e)}\",\n            ),\n        )\n\n\n@router.get(\"/documents/{document_id}\", response_model=dict)\nasync def get_document(\n    document_id: str,\n    db: Session = Depends(get_db),\n    current_admin_user: User = Depends(get_current_admin_or_viewer),\n):\n    \"\"\"\n    Get detailed information about a specific document.\n\n    Returns document metadata and chunk information.\n\n    Args:\n        document_id: Document identifier\n        db: Database session\n\n    Returns:\n        Document details\n    \"\"\"\n    try:\n        # Query database for document metadata\n        document = db.query(Document).filter(Document.document_id == document_id).first()\n\n        if not document:\n            return JSONResponse(\n                status_code=status.HTTP_404_NOT_FOUND,\n                content=error_response(\n                    code=ErrorCodes.NOT_FOUND,\n                    message=f\"Document not found: {document_id}\",\n                ),\n            )\n\n        # Convert to response format\n        document_data = {\n            \"document_id\": document.document_id,\n            \"title\": document.title,\n            \"source_type\": document.source_type,\n            \"filename\": document.filename,\n            \"file_type\": document.file_type,\n            \"chunks_indexed\": document.chunks_indexed,\n            \"total_tokens\": document.total_tokens,\n            \"indexing_status\": document.indexing_status,\n            \"indexing_error\": document.indexing_error,\n            \"metadata\": document.metadata,\n            \"created_at\": document.created_at.isoformat(),\n            \"updated_at\": document.updated_at.isoformat(),\n        }\n\n        logger.info(f\"Retrieved document details: {document_id}\")\n\n        return success_response(data=document_data, version=\"2.0.0\")\n\n    except Exception as e:\n        logger.error(f\"Error retrieving document {document_id}: {e}\", exc_info=True)\n\n        return JSONResponse(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            content=error_response(\n                code=ErrorCodes.INTERNAL_ERROR,\n                message=f\"Failed to retrieve document: {str(e)}\",\n            ),\n        )\n"
}
