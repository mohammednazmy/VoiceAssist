{
  "path": "services/api-gateway/app/services/preemptive_stt_service.py",
  "language": "python",
  "size": 20547,
  "last_modified": "2025-12-05T00:59:11.992Z",
  "lines": 588,
  "content": "\"\"\"\nPre-emptive STT Service\n\nImplements pre-emptive speech-to-text that keeps listening even while\nthe AI is speaking, enabling instant barge-in with zero connection latency.\n\nKey features:\n- Continuous STT session (no restart on barge-in)\n- Echo cancellation to filter TTS playback\n- Energy-based noise gate during AI speech\n- Latency tracking for barge-in events\n\nPhase: v4.2.0 Barge-in Improvements\n\"\"\"\n\nimport asyncio\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Awaitable, Callable, List, Optional\n\nfrom app.core.logging import get_logger\nfrom app.services.streaming_stt_service import (\n    DeepgramStreamingSession,\n    STTSessionConfig,\n    StreamingSTTService,\n    streaming_stt_service,\n)\n\nlogger = get_logger(__name__)\n\n\n# ==============================================================================\n# Types and Configuration\n# ==============================================================================\n\n\nclass PreemptiveMode(str, Enum):\n    \"\"\"Mode of the pre-emptive STT session.\"\"\"\n\n    ACTIVE = \"active\"          # Normal listening (user's turn)\n    PREEMPTIVE = \"preemptive\"  # Listening during AI speech\n    PAUSED = \"paused\"          # Temporarily paused\n    STOPPED = \"stopped\"        # Session stopped\n\n\n@dataclass\nclass PreemptiveConfig:\n    \"\"\"Configuration for pre-emptive STT.\"\"\"\n\n    # Energy threshold for detecting speech during AI playback\n    # Higher = more aggressive filtering (fewer false positives)\n    # Lower = more sensitive (might pick up TTS echo)\n    energy_threshold_db: float = -35.0\n\n    # Minimum duration (ms) of speech to trigger barge-in during AI speech\n    # Helps filter brief noise bursts\n    min_speech_duration_ms: int = 150\n\n    # Cool-down after AI stops speaking before switching to active mode\n    # Allows TTS echo to settle\n    echo_settle_ms: int = 300\n\n    # Maximum latency target for barge-in detection (ms)\n    target_barge_in_latency_ms: int = 200\n\n    # Whether to use energy-based noise gate during preemptive mode\n    use_noise_gate: bool = True\n\n    # Confidence threshold for preemptive barge-in\n    preemptive_confidence_threshold: float = 0.70\n\n\n@dataclass\nclass BargeInMetrics:\n    \"\"\"Metrics for barge-in performance.\"\"\"\n\n    # Latency from speech start to barge-in trigger\n    detection_latency_ms: float = 0.0\n\n    # Time from barge-in trigger to TTS stop\n    cancel_latency_ms: float = 0.0\n\n    # Total end-to-end latency\n    total_latency_ms: float = 0.0\n\n    # Whether this was a true barge-in (during AI speech)\n    was_preemptive: bool = False\n\n    # Transcript that triggered the barge-in\n    trigger_transcript: str = \"\"\n\n    # Confidence of the transcript\n    confidence: float = 0.0\n\n    # Timestamp\n    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))\n\n\n@dataclass\nclass PreemptiveState:\n    \"\"\"State of the pre-emptive STT session.\"\"\"\n\n    mode: PreemptiveMode = PreemptiveMode.STOPPED\n\n    # When AI started speaking (for echo cancellation timing)\n    ai_speech_started_at: Optional[float] = None\n\n    # When AI stopped speaking\n    ai_speech_stopped_at: Optional[float] = None\n\n    # Accumulated transcript during preemptive mode\n    preemptive_transcript: str = \"\"\n\n    # Speech detection state\n    speech_detected_at: Optional[float] = None\n    speech_duration_ms: float = 0.0\n\n    # Energy tracking for noise gate\n    recent_energy_db: List[float] = field(default_factory=list)\n\n    # Barge-in metrics history\n    barge_in_history: List[BargeInMetrics] = field(default_factory=list)\n\n\n# ==============================================================================\n# Pre-emptive STT Session\n# ==============================================================================\n\n\nclass PreemptiveSTTSession:\n    \"\"\"\n    Pre-emptive STT session that maintains continuous listening.\n\n    Unlike standard STT which restarts on barge-in, this session:\n    1. Stays connected to Deepgram continuously\n    2. Applies noise gating during AI speech to filter echo\n    3. Triggers barge-in without connection delay\n    4. Tracks detailed latency metrics\n    \"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        stt_service: StreamingSTTService,\n        config: PreemptiveConfig,\n        stt_config: STTSessionConfig,\n        on_partial: Callable[[str, float], Awaitable[None]],\n        on_final: Callable[[str], Awaitable[None]],\n        on_endpoint: Callable[[], Awaitable[None]],\n        on_barge_in: Callable[[BargeInMetrics], Awaitable[None]],\n        on_speech_start: Optional[Callable[[], Awaitable[None]]] = None,\n        on_words: Optional[Callable[[list], Awaitable[None]]] = None,\n    ):\n        self.session_id = session_id\n        self._stt_service = stt_service\n        self.config = config\n        self.stt_config = stt_config\n\n        # External callbacks\n        self._on_partial = on_partial\n        self._on_final = on_final\n        self._on_endpoint = on_endpoint\n        self._on_barge_in = on_barge_in\n        self._on_speech_start = on_speech_start\n        self._on_words = on_words\n\n        # Internal session\n        self._deepgram_session: Optional[DeepgramStreamingSession] = None\n\n        # State\n        self._state = PreemptiveState()\n        self._lock = asyncio.Lock()\n\n        # For latency tracking\n        self._barge_in_pending_metrics: Optional[BargeInMetrics] = None\n\n        logger.info(\n            f\"PreemptiveSTTSession created: {session_id}\",\n            extra={\n                \"energy_threshold_db\": config.energy_threshold_db,\n                \"min_speech_duration_ms\": config.min_speech_duration_ms,\n            },\n        )\n\n    @property\n    def mode(self) -> PreemptiveMode:\n        \"\"\"Get current mode.\"\"\"\n        return self._state.mode\n\n    @property\n    def state(self) -> PreemptiveState:\n        \"\"\"Get current state (read-only copy).\"\"\"\n        return PreemptiveState(\n            mode=self._state.mode,\n            ai_speech_started_at=self._state.ai_speech_started_at,\n            ai_speech_stopped_at=self._state.ai_speech_stopped_at,\n            preemptive_transcript=self._state.preemptive_transcript,\n            speech_detected_at=self._state.speech_detected_at,\n            speech_duration_ms=self._state.speech_duration_ms,\n            recent_energy_db=list(self._state.recent_energy_db),\n            barge_in_history=list(self._state.barge_in_history),\n        )\n\n    async def start(self) -> bool:\n        \"\"\"Start the pre-emptive STT session.\"\"\"\n        async with self._lock:\n            if self._state.mode != PreemptiveMode.STOPPED:\n                logger.warning(f\"Session already started: {self.session_id}\")\n                return False\n\n            # Create and start Deepgram session\n            self._deepgram_session = await self._stt_service.create_session(\n                on_partial=self._handle_partial,\n                on_final=self._handle_final,\n                on_endpoint=self._handle_endpoint,\n                on_speech_start=self._handle_speech_start,\n                on_words=self._on_words,\n                config=self.stt_config,\n            )\n\n            if not await self._deepgram_session.start():\n                logger.error(f\"Failed to start Deepgram session: {self.session_id}\")\n                return False\n\n            self._state.mode = PreemptiveMode.ACTIVE\n            logger.info(f\"PreemptiveSTTSession started: {self.session_id}\")\n            return True\n\n    async def stop(self) -> str:\n        \"\"\"Stop the session and return final transcript.\"\"\"\n        async with self._lock:\n            self._state.mode = PreemptiveMode.STOPPED\n\n            if self._deepgram_session:\n                transcript = await self._deepgram_session.stop()\n                self._deepgram_session = None\n                return transcript\n\n            return \"\"\n\n    async def send_audio(self, audio_data: bytes) -> None:\n        \"\"\"\n        Send audio data to the STT session.\n\n        In preemptive mode, applies noise gating to filter TTS echo.\n        \"\"\"\n        if self._state.mode in (PreemptiveMode.STOPPED, PreemptiveMode.PAUSED):\n            return\n\n        if not self._deepgram_session:\n            return\n\n        # In preemptive mode, apply noise gate\n        if self._state.mode == PreemptiveMode.PREEMPTIVE and self.config.use_noise_gate:\n            # Calculate audio energy\n            energy_db = self._calculate_energy_db(audio_data)\n            self._track_energy(energy_db)\n\n            # Only send if above threshold\n            if energy_db < self.config.energy_threshold_db:\n                return\n\n        await self._deepgram_session.send_audio(audio_data)\n\n    def notify_ai_speaking_started(self) -> None:\n        \"\"\"Notify that AI has started speaking. Switch to preemptive mode.\"\"\"\n        self._state.mode = PreemptiveMode.PREEMPTIVE\n        self._state.ai_speech_started_at = time.time()\n        self._state.ai_speech_stopped_at = None\n        self._state.preemptive_transcript = \"\"\n        self._state.speech_detected_at = None\n        self._state.speech_duration_ms = 0.0\n\n        logger.debug(f\"[PreemptiveSTT] AI speaking started, mode=PREEMPTIVE\")\n\n    def notify_ai_speaking_stopped(self) -> None:\n        \"\"\"Notify that AI has stopped speaking.\"\"\"\n        self._state.ai_speech_stopped_at = time.time()\n\n        # Schedule transition to active mode after echo settle time\n        asyncio.create_task(self._transition_to_active_after_settle())\n\n        logger.debug(f\"[PreemptiveSTT] AI speaking stopped, waiting for echo settle\")\n\n    async def _transition_to_active_after_settle(self) -> None:\n        \"\"\"Transition to active mode after echo settle time.\"\"\"\n        await asyncio.sleep(self.config.echo_settle_ms / 1000.0)\n\n        # Only transition if still in preemptive mode\n        if self._state.mode == PreemptiveMode.PREEMPTIVE:\n            self._state.mode = PreemptiveMode.ACTIVE\n            logger.debug(f\"[PreemptiveSTT] Transitioned to ACTIVE mode\")\n\n    def complete_barge_in(self) -> Optional[BargeInMetrics]:\n        \"\"\"\n        Complete a pending barge-in and return metrics.\n\n        Called when TTS has been cancelled.\n        \"\"\"\n        if self._barge_in_pending_metrics:\n            metrics = self._barge_in_pending_metrics\n            metrics.cancel_latency_ms = (time.time() * 1000) - (\n                metrics.timestamp.timestamp() * 1000 + metrics.detection_latency_ms\n            )\n            metrics.total_latency_ms = metrics.detection_latency_ms + metrics.cancel_latency_ms\n\n            self._state.barge_in_history.append(metrics)\n            self._barge_in_pending_metrics = None\n\n            logger.info(\n                f\"[PreemptiveSTT] Barge-in completed: \"\n                f\"detection={metrics.detection_latency_ms:.0f}ms, \"\n                f\"cancel={metrics.cancel_latency_ms:.0f}ms, \"\n                f\"total={metrics.total_latency_ms:.0f}ms\"\n            )\n\n            return metrics\n\n        return None\n\n    def get_barge_in_statistics(self) -> dict:\n        \"\"\"Get barge-in statistics.\"\"\"\n        history = self._state.barge_in_history\n\n        if not history:\n            return {\n                \"count\": 0,\n                \"avg_detection_latency_ms\": 0.0,\n                \"avg_total_latency_ms\": 0.0,\n                \"preemptive_count\": 0,\n                \"target_met_count\": 0,\n            }\n\n        preemptive = [m for m in history if m.was_preemptive]\n        target_met = [m for m in history if m.total_latency_ms <= self.config.target_barge_in_latency_ms]\n\n        return {\n            \"count\": len(history),\n            \"avg_detection_latency_ms\": sum(m.detection_latency_ms for m in history) / len(history),\n            \"avg_total_latency_ms\": sum(m.total_latency_ms for m in history) / len(history),\n            \"preemptive_count\": len(preemptive),\n            \"target_met_count\": len(target_met),\n            \"target_met_percentage\": (len(target_met) / len(history)) * 100 if history else 0,\n        }\n\n    # ==========================================================================\n    # Internal Handlers\n    # ==========================================================================\n\n    async def _handle_partial(self, text: str, confidence: float) -> None:\n        \"\"\"Handle partial transcript from Deepgram.\"\"\"\n        now = time.time()\n\n        if self._state.mode == PreemptiveMode.PREEMPTIVE:\n            # Track transcript accumulation\n            self._state.preemptive_transcript = text\n\n            # Check if this should trigger barge-in\n            if self._should_trigger_barge_in(text, confidence):\n                await self._trigger_barge_in(text, confidence)\n            else:\n                # Still emit partial for UI feedback (optional)\n                await self._on_partial(text, confidence)\n        else:\n            # Active mode - forward directly\n            await self._on_partial(text, confidence)\n\n    async def _handle_final(self, text: str) -> None:\n        \"\"\"Handle final transcript from Deepgram.\"\"\"\n        await self._on_final(text)\n\n    async def _handle_endpoint(self) -> None:\n        \"\"\"Handle speech endpoint from Deepgram.\"\"\"\n        await self._on_endpoint()\n\n    async def _handle_speech_start(self) -> None:\n        \"\"\"Handle speech start detection from Deepgram.\"\"\"\n        now = time.time()\n\n        if self._state.mode == PreemptiveMode.PREEMPTIVE:\n            # Track when speech was first detected during AI playback\n            if self._state.speech_detected_at is None:\n                self._state.speech_detected_at = now\n                logger.debug(f\"[PreemptiveSTT] Speech detected during AI playback\")\n\n        if self._on_speech_start:\n            await self._on_speech_start()\n\n    def _should_trigger_barge_in(self, text: str, confidence: float) -> bool:\n        \"\"\"Determine if the transcript should trigger barge-in.\"\"\"\n        # Must be in preemptive mode\n        if self._state.mode != PreemptiveMode.PREEMPTIVE:\n            return False\n\n        # Check confidence threshold\n        if confidence < self.config.preemptive_confidence_threshold:\n            return False\n\n        # Check if we have enough speech duration\n        if self._state.speech_detected_at:\n            duration_ms = (time.time() - self._state.speech_detected_at) * 1000\n            if duration_ms < self.config.min_speech_duration_ms:\n                return False\n            self._state.speech_duration_ms = duration_ms\n\n        # Check if transcript is substantial (not just noise)\n        text_stripped = text.strip().lower()\n\n        # Filter noise patterns\n        noise_patterns = {\"um\", \"uh\", \"hmm\", \"mm\", \"ah\", \"oh\", \"er\", \"huh\"}\n        if text_stripped in noise_patterns:\n            return False\n\n        # Need at least 2 characters\n        if len(text_stripped) < 2:\n            return False\n\n        return True\n\n    async def _trigger_barge_in(self, text: str, confidence: float) -> None:\n        \"\"\"Trigger barge-in and record metrics.\"\"\"\n        now = time.time()\n\n        # Calculate detection latency\n        detection_latency_ms = 0.0\n        if self._state.speech_detected_at:\n            detection_latency_ms = (now - self._state.speech_detected_at) * 1000\n\n        # Create metrics\n        metrics = BargeInMetrics(\n            detection_latency_ms=detection_latency_ms,\n            was_preemptive=True,\n            trigger_transcript=text,\n            confidence=confidence,\n            timestamp=datetime.now(timezone.utc),\n        )\n\n        self._barge_in_pending_metrics = metrics\n\n        logger.info(\n            f\"[PreemptiveSTT] Barge-in triggered: '{text}' \"\n            f\"(conf={confidence:.2f}, latency={detection_latency_ms:.0f}ms)\"\n        )\n\n        # Notify callback\n        await self._on_barge_in(metrics)\n\n    def _calculate_energy_db(self, audio_data: bytes) -> float:\n        \"\"\"Calculate energy level of audio in dB.\"\"\"\n        import math\n        import struct\n\n        # Parse as 16-bit PCM\n        try:\n            samples = struct.unpack(f'<{len(audio_data) // 2}h', audio_data)\n            if not samples:\n                return -100.0\n\n            # Calculate RMS\n            rms = (sum(s * s for s in samples) / len(samples)) ** 0.5\n\n            # Convert to dB (reference: max 16-bit value)\n            if rms < 1:\n                return -100.0\n\n            db = 20 * math.log10(rms / 32768.0) if rms > 0 else -100.0\n            return max(-100.0, min(0.0, db))\n        except Exception:\n            return -100.0\n\n    def _track_energy(self, energy_db: float) -> None:\n        \"\"\"Track recent energy levels for adaptive thresholding.\"\"\"\n        self._state.recent_energy_db.append(energy_db)\n\n        # Keep last 50 samples (~1 second at 20ms chunks)\n        if len(self._state.recent_energy_db) > 50:\n            self._state.recent_energy_db.pop(0)\n\n\n# ==============================================================================\n# Pre-emptive STT Service\n# ==============================================================================\n\n\nclass PreemptiveSTTService:\n    \"\"\"\n    Factory service for creating pre-emptive STT sessions.\n\n    Usage:\n        service = PreemptiveSTTService()\n\n        session = await service.create_session(\n            session_id=\"voice-123\",\n            on_partial=handle_partial,\n            on_final=handle_final,\n            on_endpoint=handle_endpoint,\n            on_barge_in=handle_barge_in,\n        )\n\n        await session.start()\n\n        # During AI speech:\n        session.notify_ai_speaking_started()\n        await session.send_audio(audio_chunk)\n\n        # User interrupts -> on_barge_in is called with metrics\n\n        session.notify_ai_speaking_stopped()\n    \"\"\"\n\n    def __init__(self, stt_service: Optional[StreamingSTTService] = None):\n        self._stt_service = stt_service or streaming_stt_service\n        self._sessions: dict[str, PreemptiveSTTSession] = {}\n\n        logger.info(\"PreemptiveSTTService initialized\")\n\n    def is_available(self) -> bool:\n        \"\"\"Check if pre-emptive STT is available.\"\"\"\n        return self._stt_service.is_streaming_available()\n\n    async def create_session(\n        self,\n        session_id: str,\n        on_partial: Callable[[str, float], Awaitable[None]],\n        on_final: Callable[[str], Awaitable[None]],\n        on_endpoint: Callable[[], Awaitable[None]],\n        on_barge_in: Callable[[BargeInMetrics], Awaitable[None]],\n        on_speech_start: Optional[Callable[[], Awaitable[None]]] = None,\n        on_words: Optional[Callable[[list], Awaitable[None]]] = None,\n        config: Optional[PreemptiveConfig] = None,\n        stt_config: Optional[STTSessionConfig] = None,\n    ) -> PreemptiveSTTSession:\n        \"\"\"\n        Create a new pre-emptive STT session.\n\n        Args:\n            session_id: Unique session identifier\n            on_partial: Callback for partial transcripts\n            on_final: Callback for final transcripts\n            on_endpoint: Callback for speech endpoints\n            on_barge_in: Callback when barge-in is detected\n            on_speech_start: Optional callback for speech start\n            on_words: Optional callback for word-level data\n            config: Pre-emptive configuration\n            stt_config: STT configuration\n\n        Returns:\n            PreemptiveSTTSession instance\n        \"\"\"\n        session = PreemptiveSTTSession(\n            session_id=session_id,\n            stt_service=self._stt_service,\n            config=config or PreemptiveConfig(),\n            stt_config=stt_config or STTSessionConfig(),\n            on_partial=on_partial,\n            on_final=on_final,\n            on_endpoint=on_endpoint,\n            on_barge_in=on_barge_in,\n            on_speech_start=on_speech_start,\n            on_words=on_words,\n        )\n\n        self._sessions[session_id] = session\n        return session\n\n    def get_session(self, session_id: str) -> Optional[PreemptiveSTTSession]:\n        \"\"\"Get an existing session by ID.\"\"\"\n        return self._sessions.get(session_id)\n\n    async def remove_session(self, session_id: str) -> None:\n        \"\"\"Remove and stop a session.\"\"\"\n        session = self._sessions.pop(session_id, None)\n        if session:\n            await session.stop()\n\n    def get_all_statistics(self) -> dict:\n        \"\"\"Get statistics for all sessions.\"\"\"\n        return {\n            session_id: session.get_barge_in_statistics()\n            for session_id, session in self._sessions.items()\n        }\n\n\n# Global service instance\npreemptive_stt_service = PreemptiveSTTService()\n"
}
