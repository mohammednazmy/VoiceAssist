{
  "path": "services/api-gateway/app/services/voice_activity_detector.py",
  "language": "python",
  "size": 13153,
  "last_modified": "2025-12-04T11:27:01.863Z",
  "lines": 378,
  "content": "\"\"\"\nVoice Activity Detection (VAD) Service\n\nProvides both server-side and client-side VAD support for voice sessions.\nUses WebRTC VAD algorithm for reliable speech detection.\n\nFeatures:\n- Energy-based speech detection\n- Frame-by-frame processing\n- Configurable sensitivity thresholds\n- Speech state tracking with debouncing\n\"\"\"\n\nimport struct\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Callable, List, Optional\n\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass SpeechState(Enum):\n    \"\"\"Current speech detection state\"\"\"\n\n    SILENCE = \"silence\"\n    SPEECH_START = \"speech_start\"\n    SPEAKING = \"speaking\"\n    SPEECH_END = \"speech_end\"\n\n\n@dataclass\nclass VADConfig:\n    \"\"\"Configuration for Voice Activity Detection\"\"\"\n\n    # Sensitivity threshold (0.0-1.0)\n    # Lower = more sensitive (picks up quieter sounds)\n    # Higher = less sensitive (requires louder sounds)\n    threshold: float = 0.5\n\n    # Sample rate in Hz (default: 16000 for WebRTC VAD)\n    sample_rate: int = 16000\n\n    # Frame duration in milliseconds (WebRTC VAD supports 10, 20, 30ms)\n    frame_duration_ms: int = 30\n\n    # Number of consecutive speech frames to trigger speech start\n    speech_start_frames: int = 3\n\n    # Number of consecutive silence frames to trigger speech end\n    silence_end_frames: int = 10\n\n    # Prefix padding in milliseconds (audio to keep before speech start)\n    prefix_padding_ms: int = 300\n\n    # Suffix padding in milliseconds (audio to keep after speech end)\n    suffix_padding_ms: int = 500\n\n    # Minimum speech duration in milliseconds\n    min_speech_duration_ms: int = 200\n\n    # Maximum speech duration in milliseconds (0 = unlimited)\n    max_speech_duration_ms: int = 60000\n\n\n@dataclass\nclass VADState:\n    \"\"\"Internal state for VAD processing\"\"\"\n\n    current_state: SpeechState = SpeechState.SILENCE\n    speech_frame_count: int = 0\n    silence_frame_count: int = 0\n    speech_start_time_ms: int = 0\n    speech_duration_ms: int = 0\n    total_frames_processed: int = 0\n    # Buffer for prefix padding\n    prefix_buffer: List[bytes] = field(default_factory=list)\n    # Maximum prefix buffer frames\n    max_prefix_frames: int = 10\n\n\nclass VoiceActivityDetector:\n    \"\"\"\n    Voice Activity Detector using energy-based detection.\n\n    This implementation uses signal energy analysis to detect speech.\n    It provides a simpler, dependency-free alternative to WebRTC VAD\n    while maintaining good accuracy for typical voice applications.\n    \"\"\"\n\n    def __init__(self, config: Optional[VADConfig] = None):\n        self.config = config or VADConfig()\n        self.state = VADState()\n\n        # Calculate frame size in samples\n        self.frame_size = int(self.config.sample_rate * self.config.frame_duration_ms / 1000)\n\n        # Calculate max prefix frames based on prefix padding\n        self.state.max_prefix_frames = int(self.config.prefix_padding_ms / self.config.frame_duration_ms)\n\n        # Energy threshold calibration\n        # These values are tuned for typical speech characteristics\n        self._energy_floor = 1e-10  # Minimum energy to avoid log(0)\n        self._speech_energy_ratio = 3.0  # Speech should be 3x silence energy\n\n        # Running noise estimate for adaptive thresholding\n        self._noise_energy = 0.0\n        self._noise_alpha = 0.1  # Noise estimation smoothing factor\n\n        logger.debug(\n            \"VAD initialized\",\n            extra={\n                \"sample_rate\": self.config.sample_rate,\n                \"frame_duration_ms\": self.config.frame_duration_ms,\n                \"frame_size\": self.frame_size,\n                \"threshold\": self.config.threshold,\n            },\n        )\n\n    def reset(self) -> None:\n        \"\"\"Reset VAD state for new session\"\"\"\n        self.state = VADState()\n        self.state.max_prefix_frames = int(self.config.prefix_padding_ms / self.config.frame_duration_ms)\n        self._noise_energy = 0.0\n        logger.debug(\"VAD state reset\")\n\n    def set_threshold(self, threshold: float) -> None:\n        \"\"\"Update sensitivity threshold (0.0-1.0)\"\"\"\n        self.config.threshold = max(0.0, min(1.0, threshold))\n        logger.debug(f\"VAD threshold updated to {self.config.threshold}\")\n\n    def _calculate_frame_energy(self, frame: bytes) -> float:\n        \"\"\"Calculate normalized energy of an audio frame\"\"\"\n        try:\n            # Convert bytes to 16-bit PCM samples\n            n_samples = len(frame) // 2\n            if n_samples == 0:\n                return 0.0\n\n            samples = struct.unpack(f\"<{n_samples}h\", frame)\n\n            # Calculate RMS energy\n            sum_squares = sum(s * s for s in samples)\n            rms = (sum_squares / n_samples) ** 0.5\n\n            # Normalize to 0-1 range (16-bit audio max is 32767)\n            normalized_energy = rms / 32767.0\n\n            return max(normalized_energy, self._energy_floor)\n\n        except Exception as e:\n            logger.warning(f\"Error calculating frame energy: {e}\")\n            return 0.0\n\n    def _is_speech_frame(self, energy: float) -> bool:\n        \"\"\"\n        Determine if frame contains speech based on energy.\n\n        Uses adaptive thresholding with noise estimation.\n        \"\"\"\n        # Update noise estimate during silence\n        if self.state.current_state == SpeechState.SILENCE:\n            self._noise_energy = self._noise_alpha * energy + (1 - self._noise_alpha) * self._noise_energy\n\n        # Calculate speech threshold based on noise floor\n        # Higher config threshold = requires more energy above noise\n        speech_threshold = self._noise_energy * (1 + self._speech_energy_ratio * (1 - self.config.threshold))\n\n        # Minimum absolute threshold to avoid false positives\n        min_threshold = 0.01 * (1 - self.config.threshold)\n        speech_threshold = max(speech_threshold, min_threshold)\n\n        return energy > speech_threshold\n\n    def process_frame(\n        self,\n        frame: bytes,\n        on_speech_start: Optional[Callable[[], None]] = None,\n        on_speech_end: Optional[Callable[[int], None]] = None,\n    ) -> SpeechState:\n        \"\"\"\n        Process a single audio frame and update VAD state.\n\n        Args:\n            frame: Raw PCM audio frame (16-bit, mono)\n            on_speech_start: Callback when speech starts\n            on_speech_end: Callback when speech ends (receives duration in ms)\n\n        Returns:\n            Current SpeechState after processing\n        \"\"\"\n        self.state.total_frames_processed += 1\n        frame_time_ms = self.state.total_frames_processed * self.config.frame_duration_ms\n\n        # Calculate frame energy\n        energy = self._calculate_frame_energy(frame)\n        is_speech = self._is_speech_frame(energy)\n\n        # State machine for speech detection\n        # previous_state preserved for potential future logging/debugging\n\n        if is_speech:\n            self.state.silence_frame_count = 0\n            self.state.speech_frame_count += 1\n\n            if self.state.current_state == SpeechState.SILENCE:\n                # Potential speech start\n                if self.state.speech_frame_count >= self.config.speech_start_frames:\n                    self.state.current_state = SpeechState.SPEECH_START\n                    self.state.speech_start_time_ms = frame_time_ms - self.config.prefix_padding_ms\n                    if on_speech_start:\n                        on_speech_start()\n\n            elif self.state.current_state == SpeechState.SPEECH_START:\n                self.state.current_state = SpeechState.SPEAKING\n\n            elif self.state.current_state == SpeechState.SPEECH_END:\n                # Speech resumed before timeout\n                self.state.current_state = SpeechState.SPEAKING\n\n        else:\n            self.state.speech_frame_count = 0\n            self.state.silence_frame_count += 1\n\n            if self.state.current_state in (\n                SpeechState.SPEAKING,\n                SpeechState.SPEECH_START,\n            ):\n                if self.state.silence_frame_count >= self.config.silence_end_frames:\n                    self.state.current_state = SpeechState.SPEECH_END\n                    self.state.speech_duration_ms = frame_time_ms - self.state.speech_start_time_ms\n\n                    if on_speech_end:\n                        on_speech_end(self.state.speech_duration_ms)\n\n                    # Reset to silence after emitting speech_end\n                    self.state.current_state = SpeechState.SILENCE\n                    self.state.speech_start_time_ms = 0\n\n        # Manage prefix buffer\n        if self.state.current_state == SpeechState.SILENCE:\n            self.state.prefix_buffer.append(frame)\n            if len(self.state.prefix_buffer) > self.state.max_prefix_frames:\n                self.state.prefix_buffer.pop(0)\n\n        return self.state.current_state\n\n    def process_audio(\n        self,\n        audio_data: bytes,\n        on_speech_start: Optional[Callable[[], None]] = None,\n        on_speech_end: Optional[Callable[[int], None]] = None,\n    ) -> List[SpeechState]:\n        \"\"\"\n        Process a chunk of audio data (multiple frames).\n\n        Args:\n            audio_data: Raw PCM audio data (16-bit, mono)\n            on_speech_start: Callback when speech starts\n            on_speech_end: Callback when speech ends\n\n        Returns:\n            List of SpeechState for each frame\n        \"\"\"\n        states = []\n        frame_bytes = self.frame_size * 2  # 16-bit = 2 bytes per sample\n\n        for i in range(0, len(audio_data), frame_bytes):\n            frame = audio_data[i : i + frame_bytes]\n            if len(frame) == frame_bytes:\n                state = self.process_frame(frame, on_speech_start, on_speech_end)\n                states.append(state)\n\n        return states\n\n    def get_prefix_audio(self) -> bytes:\n        \"\"\"Get buffered prefix audio for speech segment\"\"\"\n        return b\"\".join(self.state.prefix_buffer)\n\n    def is_speaking(self) -> bool:\n        \"\"\"Check if currently detecting speech\"\"\"\n        return self.state.current_state in (\n            SpeechState.SPEECH_START,\n            SpeechState.SPEAKING,\n        )\n\n    def get_stats(self) -> dict:\n        \"\"\"Get VAD statistics\"\"\"\n        return {\n            \"current_state\": self.state.current_state.value,\n            \"total_frames\": self.state.total_frames_processed,\n            \"speech_duration_ms\": self.state.speech_duration_ms,\n            \"noise_energy\": self._noise_energy,\n            \"threshold\": self.config.threshold,\n        }\n\n\nclass StreamingVAD:\n    \"\"\"\n    Streaming VAD wrapper for WebSocket voice sessions.\n\n    Provides async-friendly interface for real-time audio processing\n    with speech event callbacks.\n    \"\"\"\n\n    def __init__(self, config: Optional[VADConfig] = None):\n        self.vad = VoiceActivityDetector(config)\n        self._speech_callbacks: List[Callable[[], None]] = []\n        self._end_callbacks: List[Callable[[int], None]] = []\n        self._audio_buffer: bytes = b\"\"\n\n    def on_speech_start(self, callback: Callable[[], None]) -> None:\n        \"\"\"Register callback for speech start events\"\"\"\n        self._speech_callbacks.append(callback)\n\n    def on_speech_end(self, callback: Callable[[int], None]) -> None:\n        \"\"\"Register callback for speech end events\"\"\"\n        self._end_callbacks.append(callback)\n\n    def _emit_speech_start(self) -> None:\n        \"\"\"Emit speech start event to all listeners\"\"\"\n        for callback in self._speech_callbacks:\n            try:\n                callback()\n            except Exception as e:\n                logger.error(f\"Speech start callback error: {e}\")\n\n    def _emit_speech_end(self, duration_ms: int) -> None:\n        \"\"\"Emit speech end event to all listeners\"\"\"\n        for callback in self._end_callbacks:\n            try:\n                callback(duration_ms)\n            except Exception as e:\n                logger.error(f\"Speech end callback error: {e}\")\n\n    async def process_chunk(self, audio_chunk: bytes) -> SpeechState:\n        \"\"\"\n        Process an audio chunk asynchronously.\n\n        Args:\n            audio_chunk: Raw PCM audio data\n\n        Returns:\n            Current SpeechState\n        \"\"\"\n        # Append to buffer\n        self._audio_buffer += audio_chunk\n\n        # Process complete frames\n        frame_bytes = self.vad.frame_size * 2\n        current_state = self.vad.state.current_state\n\n        while len(self._audio_buffer) >= frame_bytes:\n            frame = self._audio_buffer[:frame_bytes]\n            self._audio_buffer = self._audio_buffer[frame_bytes:]\n\n            current_state = self.vad.process_frame(\n                frame,\n                on_speech_start=self._emit_speech_start,\n                on_speech_end=self._emit_speech_end,\n            )\n\n        return current_state\n\n    def reset(self) -> None:\n        \"\"\"Reset VAD state\"\"\"\n        self.vad.reset()\n        self._audio_buffer = b\"\"\n\n    def get_prefix_audio(self) -> bytes:\n        \"\"\"Get prefix audio buffer\"\"\"\n        return self.vad.get_prefix_audio()\n\n    def is_speaking(self) -> bool:\n        \"\"\"Check if currently speaking\"\"\"\n        return self.vad.is_speaking()\n"
}
