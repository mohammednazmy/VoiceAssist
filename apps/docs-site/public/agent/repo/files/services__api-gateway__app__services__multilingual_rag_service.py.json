{
  "path": "services/api-gateway/app/services/multilingual_rag_service.py",
  "language": "python",
  "size": 16292,
  "last_modified": "2025-12-04T18:47:50.955Z",
  "lines": 459,
  "content": "\"\"\"\nMultilingual RAG Service\nExtends RAG capabilities with translation layer for non-English queries.\n\nPart of Voice Mode Enhancement Plan v4.1\nReference: /home/asimo/.claude/plans/noble-bubbling-trinket.md#workstream-b-multilingual--pronunciation\n\"\"\"\n\nimport logging\nimport time\nfrom dataclasses import dataclass, field\nfrom typing import Dict, List, Optional\n\nfrom app.services.translation_service import TranslationService, get_translation_service\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\n\nclass LanguageSegment(BaseModel):\n    \"\"\"A segment of text with detected language.\"\"\"\n\n    text: str\n    language: str\n    confidence: float\n    start_idx: int\n    end_idx: int\n\n\nclass MultilingualQueryResult(BaseModel):\n    \"\"\"Result of a multilingual query operation.\"\"\"\n\n    original_query: str\n    detected_language: str\n    english_query: str\n    translation_used: bool = False\n    translation_cached: bool = False\n    translation_warning: Optional[str] = None\n\n\n@dataclass\nclass RAGSource:\n    \"\"\"A source document from RAG retrieval.\"\"\"\n\n    id: str\n    title: str\n    content: str\n    score: float\n    source_type: str = \"textbook\"\n    metadata: Dict = field(default_factory=dict)\n\n\nclass MultilingualRAGResponse(BaseModel):\n    \"\"\"Response from multilingual RAG retrieval.\"\"\"\n\n    answer: str\n    language: str\n    sources: List[Dict] = Field(default_factory=list)\n    original_query: str\n    translated_query: Optional[str] = None\n    translation_warning: Optional[str] = None\n    latency_ms: float = 0.0\n    degradation_applied: List[str] = Field(default_factory=list)\n\n\nclass LanguageDetectionService:\n    \"\"\"\n    Word/phrase-level language detection for code-switching.\n\n    Supports detecting language switches within a single utterance,\n    common in multilingual medical contexts (e.g., \"My abuela has diabetes\").\n    \"\"\"\n\n    # Common code-switching patterns by language pair\n    CODE_SWITCH_PATTERNS = {\n        (\"en\", \"es\"): [\"mi\", \"su\", \"el\", \"la\", \"los\", \"las\", \"que\", \"por\"],\n        (\"en\", \"ar\"): [\"والله\", \"يعني\", \"الحمد لله\"],\n        (\"en\", \"hi\"): [\"मेरा\", \"मेरी\", \"है\", \"हैं\"],\n    }\n\n    def __init__(self, translation_service: Optional[TranslationService] = None):\n        self.translation_service = translation_service\n\n    async def detect(self, text: str) -> str:\n        \"\"\"\n        Detect the primary language of a text.\n\n        Args:\n            text: Input text to analyze\n\n        Returns:\n            ISO 639-1 language code\n        \"\"\"\n        if not text or len(text.strip()) < 3:\n            return \"en\"\n\n        # Use translation service's detection if available\n        if self.translation_service:\n            try:\n                return await self.translation_service.detect_language(text)\n            except Exception as e:\n                logger.warning(f\"Language detection failed: {e}\")\n\n        # Fallback: simple heuristics\n        return self._detect_heuristic(text)\n\n    def _detect_heuristic(self, text: str) -> str:\n        \"\"\"Simple heuristic-based language detection.\"\"\"\n        # Check for Arabic script\n        if any(\"\\u0600\" <= c <= \"\\u06FF\" for c in text):\n            return \"ar\"\n\n        # Check for Chinese characters\n        if any(\"\\u4e00\" <= c <= \"\\u9fff\" for c in text):\n            return \"zh\"\n\n        # Check for Devanagari (Hindi)\n        if any(\"\\u0900\" <= c <= \"\\u097F\" for c in text):\n            return \"hi\"\n\n        # Check for Urdu (Nastaliq)\n        if any(\"\\u0600\" <= c <= \"\\u06FF\" for c in text) and \"ے\" in text:\n            return \"ur\"\n\n        # Default to English\n        return \"en\"\n\n    async def detect_segments(self, text: str) -> List[LanguageSegment]:\n        \"\"\"\n        Detect language at word/phrase level for code-switching.\n\n        Useful for handling mid-sentence language switches common in\n        multilingual speakers.\n\n        Args:\n            text: Input text to segment\n\n        Returns:\n            List of language segments with detected languages\n        \"\"\"\n        segments = []\n        words = text.split()\n        window_size = 4\n        current_segment_start = 0\n        current_lang = None\n\n        for i in range(0, len(words), window_size):\n            window = \" \".join(words[i : i + window_size])\n            detected = await self.detect(window)\n\n            if current_lang is None:\n                current_lang = detected\n            elif detected != current_lang:\n                # Language switch detected\n                segments.append(\n                    LanguageSegment(\n                        text=\" \".join(words[current_segment_start:i]),\n                        language=current_lang,\n                        confidence=0.85,  # Window-based detection has moderate confidence\n                        start_idx=current_segment_start,\n                        end_idx=i,\n                    )\n                )\n                current_segment_start = i\n                current_lang = detected\n\n        # Add final segment\n        if current_segment_start < len(words):\n            segments.append(\n                LanguageSegment(\n                    text=\" \".join(words[current_segment_start:]),\n                    language=current_lang or \"en\",\n                    confidence=0.9,\n                    start_idx=current_segment_start,\n                    end_idx=len(words),\n                )\n            )\n\n        return segments\n\n    async def detect_from_audio_features(self, prosody_features: Dict, transcript_hint: Optional[str] = None) -> str:\n        \"\"\"\n        Detect language from audio prosody features.\n\n        Can be used when audio features are available before full transcription.\n\n        Args:\n            prosody_features: Dict with pitch, rhythm, stress patterns\n            transcript_hint: Optional partial transcript for validation\n\n        Returns:\n            ISO 639-1 language code\n        \"\"\"\n        # TODO: Implement prosody-based language detection\n        # For now, fall back to transcript-based detection\n        if transcript_hint:\n            return await self.detect(transcript_hint)\n        return \"en\"\n\n\nclass MultilingualRAGService:\n    \"\"\"\n    Multilingual RAG service with translation layer.\n\n    Translates non-English queries to English for retrieval,\n    then generates responses in the user's preferred language.\n\n    Features:\n    - Automatic language detection\n    - Query translation with caching\n    - Code-switching support\n    - Graceful degradation on translation failure\n    - Metrics tracking\n    \"\"\"\n\n    # Language names for LLM prompting\n    LANGUAGE_NAMES = {\n        \"en\": \"English\",\n        \"es\": \"Spanish\",\n        \"fr\": \"French\",\n        \"de\": \"German\",\n        \"it\": \"Italian\",\n        \"pt\": \"Portuguese\",\n        \"ar\": \"Arabic\",\n        \"zh\": \"Mandarin Chinese\",\n        \"hi\": \"Hindi\",\n        \"ur\": \"Urdu\",\n    }\n\n    def __init__(\n        self,\n        translation_service: Optional[TranslationService] = None,\n        language_detector: Optional[LanguageDetectionService] = None,\n        rag_service=None,  # RAGService or QueryOrchestrator\n        llm_service=None,  # LLMClient\n    ):\n        self.translator = translation_service\n        self.language_detector = language_detector or LanguageDetectionService(translation_service)\n        self.rag_service = rag_service\n        self.llm = llm_service\n        self._initialized = False\n\n    async def _ensure_initialized(self):\n        \"\"\"Lazy initialization of services.\"\"\"\n        if self._initialized:\n            return\n\n        if self.translator is None:\n            self.translator = await get_translation_service()\n            self.language_detector = LanguageDetectionService(self.translator)\n\n        # Import RAG service lazily to avoid circular imports\n        if self.rag_service is None:\n            from app.services.search_aggregator import SearchAggregator\n\n            self.rag_service = SearchAggregator()\n\n        if self.llm is None:\n            from app.services.llm_client import LLMClient\n\n            self.llm = LLMClient()\n\n        self._initialized = True\n\n    async def retrieve_and_respond(\n        self,\n        query: str,\n        user_language: Optional[str] = None,\n        session_id: Optional[str] = None,\n        clinical_context_id: Optional[str] = None,\n    ) -> MultilingualRAGResponse:\n        \"\"\"\n        Retrieve relevant documents and generate response in user's language.\n\n        Process:\n        1. Detect query language\n        2. Translate to English if needed (with fallback)\n        3. Retrieve from English knowledge base\n        4. Generate response in user's preferred language\n\n        Args:\n            query: User's query (any supported language)\n            user_language: Preferred response language (auto-detect if None)\n            session_id: Optional session ID for context\n            clinical_context_id: Optional clinical context ID\n\n        Returns:\n            MultilingualRAGResponse with answer, sources, and metadata\n        \"\"\"\n        await self._ensure_initialized()\n\n        start_time = time.monotonic()\n        degradation_applied = []\n\n        # 1. Detect query language\n        query_lang = await self.language_detector.detect(query)\n        target_lang = user_language or query_lang\n\n        logger.info(f\"Query language detected: {query_lang}, target: {target_lang}\")\n\n        # 2. Translate to English if needed\n        english_query = query\n        translated_query = None\n        translation_warning = None\n\n        if query_lang != \"en\":\n            translation_result = await self.translator.translate_with_fallback(query, source=query_lang, target=\"en\")\n\n            if translation_result.failed:\n                # Fall back to original query\n                # LLM can often handle multilingual queries\n                logger.warning(\n                    f\"Translation failed, using original query. \" f\"Error: {translation_result.error_message}\"\n                )\n                degradation_applied.append(\"translation_failed\")\n                translation_warning = translation_result.error_message\n            else:\n                english_query = translation_result.text\n                translated_query = english_query\n                if translation_result.used_fallback:\n                    degradation_applied.append(\"translation_used_fallback\")\n\n        # 3. Retrieve from knowledge base\n        try:\n            results = await self.rag_service.search(query=english_query, top_k=5, min_score=0.3)\n        except Exception as e:\n            logger.error(f\"RAG retrieval failed: {e}\")\n            results = []\n            degradation_applied.append(\"rag_retrieval_failed\")\n\n        # 4. Generate response in user's language\n        language_name = self.LANGUAGE_NAMES.get(target_lang, \"English\")\n\n        # Build context from results\n        context_texts = []\n        sources = []\n        for i, result in enumerate(results[:5]):\n            if hasattr(result, \"content\"):\n                context_texts.append(f\"[{i+1}] {result.content}\")\n                sources.append(\n                    {\n                        \"id\": getattr(result, \"id\", f\"source_{i}\"),\n                        \"title\": getattr(result, \"title\", \"Unknown\"),\n                        \"score\": getattr(result, \"score\", 0.0),\n                        \"source_type\": getattr(result, \"source_type\", \"textbook\"),\n                    }\n                )\n\n        context = \"\\n\\n\".join(context_texts) if context_texts else \"No relevant sources found.\"\n\n        # Generate response with language instruction\n        system_prompt = f\"\"\"You are a helpful medical assistant.\nRespond to the user's question using the provided context.\nIMPORTANT: Respond entirely in {language_name}.\nDo not mix languages unless the user's query contains specific terms\nthat should remain in their original language (e.g., medication names).\nBe accurate, helpful, and cite your sources when providing information.\"\"\"\n\n        user_prompt = f\"\"\"Context:\n{context}\n\nUser's question: {query}\n\nPlease provide a helpful response in {language_name}.\"\"\"\n\n        try:\n            from app.services.llm_client import LLMRequest\n\n            llm_response = await self.llm.generate(\n                LLMRequest(\n                    messages=[\n                        {\"role\": \"system\", \"content\": system_prompt},\n                        {\"role\": \"user\", \"content\": user_prompt},\n                    ],\n                    max_tokens=1024,\n                    temperature=0.7,\n                )\n            )\n            answer = llm_response.content\n        except Exception as e:\n            logger.error(f\"LLM generation failed: {e}\")\n            answer = self._generate_fallback_response(target_lang)\n            degradation_applied.append(\"llm_generation_failed\")\n\n        latency_ms = (time.monotonic() - start_time) * 1000\n\n        return MultilingualRAGResponse(\n            answer=answer,\n            language=target_lang,\n            sources=sources,\n            original_query=query,\n            translated_query=translated_query,\n            translation_warning=translation_warning,\n            latency_ms=latency_ms,\n            degradation_applied=degradation_applied,\n        )\n\n    def _generate_fallback_response(self, language: str) -> str:\n        \"\"\"Generate a fallback response when LLM fails.\"\"\"\n        fallback_messages = {\n            \"en\": \"I apologize, but I'm unable to process your request. Please try again.\",\n            \"es\": \"Lo siento, no puedo procesar su solicitud. Por favor, inténtelo de nuevo.\",\n            \"fr\": \"Je m'excuse, je ne peux pas traiter votre demande. Veuillez réessayer.\",\n            \"de\": \"Es tut mir leid, ich kann Ihre Anfrage nicht bearbeiten. Bitte versuchen Sie es erneut.\",\n            \"ar\": \"عذراً، لا أستطيع معالجة طلبك. يرجى المحاولة مرة أخرى.\",\n            \"zh\": \"抱歉，我目前无法处理您的请求。请重试。\",\n            \"hi\": \"क्षमा करें, मैं आपके अनुरोध को संसाधित करने में असमर्थ हूं। कृपया पुनः प्रयास करें।\",\n            \"ur\": \"معذرت، میں آپ کی درخواست پر کارروائی نہیں کر سکتا۔ براہ کرم دوبارہ کوشش کریں۔\",\n        }\n        return fallback_messages.get(language, fallback_messages[\"en\"])\n\n    async def prepare_multilingual_query(\n        self, query: str, target_language: Optional[str] = None\n    ) -> MultilingualQueryResult:\n        \"\"\"\n        Prepare a query for multilingual RAG processing.\n\n        This is a lighter-weight method for when you just need\n        the translated query without full RAG retrieval.\n\n        Args:\n            query: Input query in any supported language\n            target_language: Override for response language\n\n        Returns:\n            MultilingualQueryResult with translation info\n        \"\"\"\n        await self._ensure_initialized()\n\n        detected_lang = await self.language_detector.detect(query)\n\n        if detected_lang == \"en\":\n            return MultilingualQueryResult(\n                original_query=query, detected_language=\"en\", english_query=query, translation_used=False\n            )\n\n        translation_result = await self.translator.translate_with_fallback(query, source=detected_lang, target=\"en\")\n\n        return MultilingualQueryResult(\n            original_query=query,\n            detected_language=detected_lang,\n            english_query=translation_result.text if not translation_result.failed else query,\n            translation_used=not translation_result.failed,\n            translation_cached=translation_result.from_cache,\n            translation_warning=translation_result.error_message if translation_result.failed else None,\n        )\n\n\n# Singleton instance\n_multilingual_rag_service: Optional[MultilingualRAGService] = None\n\n\nasync def get_multilingual_rag_service() -> MultilingualRAGService:\n    \"\"\"Get or create multilingual RAG service instance.\"\"\"\n    global _multilingual_rag_service\n    if _multilingual_rag_service is None:\n        _multilingual_rag_service = MultilingualRAGService()\n    return _multilingual_rag_service\n"
}
