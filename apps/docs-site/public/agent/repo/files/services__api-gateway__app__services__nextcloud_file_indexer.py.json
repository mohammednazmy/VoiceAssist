{
  "path": "services/api-gateway/app/services/nextcloud_file_indexer.py",
  "language": "python",
  "size": 12101,
  "last_modified": "2025-12-04T11:26:58.355Z",
  "lines": 357,
  "content": "\"\"\"\nNextcloud File Auto-Indexer (Phase 6)\n\nMonitors Nextcloud files via WebDAV and automatically indexes medical documents\ninto the VoiceAssist knowledge base. Provides seamless integration between\nNextcloud storage and the RAG system.\n\nMVP Implementation:\n- WebDAV connection to Nextcloud\n- File discovery in specified directories\n- Automatic document ingestion for supported file types\n- Indexed file tracking to prevent re-indexing\n- Manual trigger API for selective indexing\n\nFuture enhancements:\n- Real-time file watching with webhooks\n- Incremental sync and update detection\n- Metadata extraction from Nextcloud tags/comments\n- Multi-user file permissions and filtering\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Optional, Set\n\n# Import KB indexer from Phase 5\nfrom app.services.kb_indexer import IndexingResult, KBIndexer\nfrom webdav3.client import Client as WebDAVClient\nfrom webdav3.exceptions import WebDavException\n\nlogger = logging.getLogger(__name__)\n\n\n@dataclass\nclass NextcloudFile:\n    \"\"\"Represents a file in Nextcloud.\"\"\"\n\n    path: str\n    name: str\n    size: int\n    modified: datetime\n    content_type: Optional[str] = None\n    is_directory: bool = False\n\n\nclass NextcloudFileIndexer:\n    \"\"\"\n    Nextcloud file auto-indexer service.\n\n    Discovers medical documents in Nextcloud and automatically indexes them\n    into the knowledge base using the KBIndexer from Phase 5.\n    \"\"\"\n\n    # Supported file extensions for indexing\n    SUPPORTED_EXTENSIONS = {\".pdf\", \".txt\", \".md\"}\n\n    def __init__(\n        self,\n        webdav_url: str,\n        username: str,\n        password: str,\n        qdrant_url: str = \"http://qdrant:6333\",\n        collection_name: str = \"medical_kb\",\n        watch_directories: Optional[List[str]] = None,\n    ):\n        \"\"\"\n        Initialize Nextcloud file indexer.\n\n        Args:\n            webdav_url: Nextcloud WebDAV endpoint (e.g., https://nextcloud.local/remote.php/dav/files/username/)\n            username: Nextcloud username\n            password: Nextcloud password\n            qdrant_url: Qdrant vector database URL\n            collection_name: Qdrant collection for indexed documents\n            watch_directories: List of directories to monitor (e.g., ['Medical Documents', 'Guidelines'])\n        \"\"\"\n        self.webdav_url = webdav_url\n        self.username = username\n        self.password = password\n\n        # WebDAV client\n        self.webdav_client = WebDAVClient(\n            {\n                \"webdav_hostname\": webdav_url,\n                \"webdav_login\": username,\n                \"webdav_password\": password,\n                \"webdav_timeout\": 30,\n            }\n        )\n\n        # KB Indexer from Phase 5\n        self.kb_indexer = KBIndexer(qdrant_url=qdrant_url, collection_name=collection_name)\n\n        # Directories to watch for new files\n        self.watch_directories = watch_directories or [\"Medical Documents\"]\n\n        # Track indexed files to prevent re-indexing\n        self.indexed_files: Set[str] = set()\n\n    def connect(self) -> bool:\n        \"\"\"\n        Test connection to Nextcloud WebDAV.\n\n        Returns:\n            True if connection successful, False otherwise\n        \"\"\"\n        try:\n            # Test connection by listing root\n            self.webdav_client.list()\n            logger.info(f\"Successfully connected to Nextcloud WebDAV: {self.webdav_url}\")\n            return True\n\n        except WebDavException as e:\n            logger.error(f\"Failed to connect to Nextcloud WebDAV: {e}\", exc_info=True)\n            return False\n\n    def list_files(self, directory: str = \"/\", recursive: bool = True) -> List[NextcloudFile]:\n        \"\"\"\n        List files in a Nextcloud directory.\n\n        Args:\n            directory: Directory path to list\n            recursive: Whether to recurse into subdirectories\n\n        Returns:\n            List of NextcloudFile objects\n        \"\"\"\n        try:\n            files = []\n\n            # Get directory listing\n            items = self.webdav_client.list(directory, get_info=True)\n\n            for item in items:\n                # Skip self-reference\n                if item[\"path\"] == directory:\n                    continue\n\n                # Parse item info\n                is_dir = item.get(\"isdir\", False)\n                file_path = item[\"path\"]\n\n                if is_dir:\n                    # Recurse into subdirectory if requested\n                    if recursive:\n                        subfiles = self.list_files(file_path, recursive=True)\n                        files.extend(subfiles)\n                else:\n                    # Add file to list\n                    nextcloud_file = NextcloudFile(\n                        path=file_path,\n                        name=Path(file_path).name,\n                        size=item.get(\"size\", 0),\n                        modified=datetime.fromisoformat(item.get(\"modified\", datetime.now().isoformat())),\n                        content_type=item.get(\"content_type\"),\n                        is_directory=False,\n                    )\n                    files.append(nextcloud_file)\n\n            logger.info(f\"Found {len(files)} files in {directory}\")\n            return files\n\n        except WebDavException as e:\n            logger.error(f\"Error listing files in {directory}: {e}\", exc_info=True)\n            return []\n\n    def should_index_file(self, file: NextcloudFile) -> bool:\n        \"\"\"\n        Determine if a file should be indexed.\n\n        Args:\n            file: NextcloudFile to check\n\n        Returns:\n            True if file should be indexed, False otherwise\n        \"\"\"\n        # Skip if already indexed\n        if file.path in self.indexed_files:\n            logger.debug(f\"File already indexed: {file.path}\")\n            return False\n\n        # Check file extension\n        file_ext = Path(file.name).suffix.lower()\n        if file_ext not in self.SUPPORTED_EXTENSIONS:\n            logger.debug(f\"Unsupported file type: {file.name} ({file_ext})\")\n            return False\n\n        # Check file size (skip very large files > 50MB)\n        max_size = 50 * 1024 * 1024  # 50MB\n        if file.size > max_size:\n            logger.warning(f\"File too large to index: {file.name} ({file.size} bytes)\")\n            return False\n\n        return True\n\n    async def index_file(self, file: NextcloudFile, source_type: str = \"note\") -> Optional[IndexingResult]:\n        \"\"\"\n        Index a single file into the knowledge base.\n\n        Args:\n            file: NextcloudFile to index\n            source_type: Document source type (textbook, journal, guideline, note)\n\n        Returns:\n            IndexingResult if successful, None otherwise\n        \"\"\"\n        try:\n            # Download file content\n            logger.info(f\"Downloading file for indexing: {file.name}\")\n            file_bytes = self.webdav_client.resource(file.path).read()\n\n            # Determine file type and index appropriately\n            file_ext = Path(file.name).suffix.lower()\n\n            if file_ext == \".pdf\":\n                # Index PDF\n                result = await self.kb_indexer.index_pdf_document(\n                    pdf_bytes=file_bytes,\n                    document_id=f\"nextcloud-{file.path}\",\n                    title=file.name,\n                    source_type=source_type,\n                    metadata={\n                        \"nextcloud_path\": file.path,\n                        \"nextcloud_size\": file.size,\n                        \"nextcloud_modified\": file.modified.isoformat(),\n                        \"indexed_at\": datetime.now(timezone.utc).isoformat(),\n                    },\n                )\n\n            elif file_ext in {\".txt\", \".md\"}:\n                # Index text file\n                content = file_bytes.decode(\"utf-8\", errors=\"ignore\")\n                result = await self.kb_indexer.index_document(\n                    content=content,\n                    document_id=f\"nextcloud-{file.path}\",\n                    title=file.name,\n                    source_type=source_type,\n                    metadata={\n                        \"nextcloud_path\": file.path,\n                        \"nextcloud_size\": file.size,\n                        \"nextcloud_modified\": file.modified.isoformat(),\n                        \"indexed_at\": datetime.now(timezone.utc).isoformat(),\n                    },\n                )\n\n            else:\n                logger.warning(f\"Unsupported file type: {file.name}\")\n                return None\n\n            if result and result.success:\n                # Mark as indexed\n                self.indexed_files.add(file.path)\n                logger.info(\n                    f\"Successfully indexed {file.name}: \"\n                    f\"{result.chunks_indexed} chunks in {result.processing_time_ms:.2f}ms\"\n                )\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Error indexing file {file.name}: {e}\", exc_info=True)\n            return None\n\n    async def scan_and_index(self, source_type: str = \"note\", force_reindex: bool = False) -> Dict[str, Any]:\n        \"\"\"\n        Scan watch directories and index all supported files.\n\n        Args:\n            source_type: Default source type for indexed documents\n            force_reindex: If True, re-index files even if already indexed\n\n        Returns:\n            Summary dictionary with indexing statistics\n        \"\"\"\n        logger.info(\"Starting Nextcloud file scan and indexing\")\n\n        total_files = 0\n        indexed_files = 0\n        skipped_files = 0\n        failed_files = 0\n\n        if force_reindex:\n            self.indexed_files.clear()\n            logger.info(\"Force re-index enabled: clearing indexed file cache\")\n\n        # Scan each watch directory\n        for watch_dir in self.watch_directories:\n            logger.info(f\"Scanning directory: {watch_dir}\")\n\n            # List files in directory\n            files = self.list_files(watch_dir, recursive=True)\n            total_files += len(files)\n\n            # Index each file\n            for file in files:\n                if not self.should_index_file(file):\n                    skipped_files += 1\n                    continue\n\n                result = await self.index_file(file, source_type=source_type)\n\n                if result and result.success:\n                    indexed_files += 1\n                else:\n                    failed_files += 1\n\n        summary = {\n            \"scan_completed\": datetime.now(timezone.utc).isoformat(),\n            \"watch_directories\": self.watch_directories,\n            \"total_files_found\": total_files,\n            \"files_indexed\": indexed_files,\n            \"files_skipped\": skipped_files,\n            \"files_failed\": failed_files,\n        }\n\n        logger.info(\n            f\"Indexing complete: {indexed_files}/{total_files} files indexed, \"\n            f\"{skipped_files} skipped, {failed_files} failed\"\n        )\n\n        return summary\n\n    async def index_specific_file(self, file_path: str, source_type: str = \"note\") -> Optional[IndexingResult]:\n        \"\"\"\n        Index a specific file by path.\n\n        Args:\n            file_path: Nextcloud file path\n            source_type: Document source type\n\n        Returns:\n            IndexingResult if successful, None otherwise\n        \"\"\"\n        try:\n            # Get file info\n            info = self.webdav_client.info(file_path)\n\n            file = NextcloudFile(\n                path=file_path,\n                name=Path(file_path).name,\n                size=info.get(\"size\", 0),\n                modified=datetime.fromisoformat(info.get(\"modified\", datetime.now().isoformat())),\n                content_type=info.get(\"content_type\"),\n                is_directory=False,\n            )\n\n            # Index the file\n            return await self.index_file(file, source_type=source_type)\n\n        except WebDavException as e:\n            logger.error(f\"Error indexing specific file {file_path}: {e}\", exc_info=True)\n            return None\n"
}
