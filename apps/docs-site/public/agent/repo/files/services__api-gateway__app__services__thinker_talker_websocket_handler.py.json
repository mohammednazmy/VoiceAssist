{
  "path": "services/api-gateway/app/services/thinker_talker_websocket_handler.py",
  "language": "python",
  "size": 22153,
  "last_modified": "2025-12-04T11:27:01.015Z",
  "lines": 599,
  "content": "\"\"\"\nThinker/Talker WebSocket Handler\n\nWebSocket handler for the Thinker/Talker voice pipeline.\nProvides the same interface as VoiceWebSocketHandler but uses the local\nSTT → LLM → TTS pipeline instead of OpenAI Realtime API.\n\nBenefits over Realtime API:\n- Unified conversation context with chat mode\n- Full tool/RAG support in voice\n- Custom TTS (ElevenLabs) with better voice quality\n- Lower cost per interaction\n\nPhase: Thinker/Talker Voice Pipeline Migration\n\"\"\"\n\nimport asyncio\nimport json\nimport time\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Any, Dict, Optional\n\nfrom app.core.logging import get_logger\nfrom app.services.voice_pipeline_service import (\n    PipelineConfig,\n    PipelineMessage,\n    PipelineState,\n    VoicePipelineService,\n    VoicePipelineSession,\n    voice_pipeline_service,\n)\nfrom starlette.websockets import WebSocket, WebSocketDisconnect\n\nlogger = get_logger(__name__)\n\n\n# ==============================================================================\n# Data Classes\n# ==============================================================================\n\n\nclass TTConnectionState(str, Enum):\n    \"\"\"Connection states for T/T handler.\"\"\"\n\n    DISCONNECTED = \"disconnected\"\n    CONNECTING = \"connecting\"\n    CONNECTED = \"connected\"\n    READY = \"ready\"\n    ERROR = \"error\"\n\n\n@dataclass\nclass TTSessionConfig:\n    \"\"\"Configuration for a Thinker/Talker session.\"\"\"\n\n    user_id: str\n    session_id: str\n    conversation_id: Optional[str] = None\n\n    # Voice settings\n    voice_id: str = \"TxGEqnHWrfWFTfGW9XjX\"  # Josh (premium male voice)\n    tts_model: str = \"eleven_flash_v2_5\"  # Better quality + low latency\n    language: str = \"en\"\n\n    # STT settings\n    stt_sample_rate: int = 16000\n    stt_endpointing_ms: int = 800  # Was 200 - allow natural pauses (Phase 7 fix)\n    stt_utterance_end_ms: int = 1500  # Wait 1.5s before finalizing\n\n    # Barge-in\n    barge_in_enabled: bool = True\n\n    # Timeouts\n    connection_timeout_sec: float = 10.0\n    idle_timeout_sec: float = 300.0\n\n    # Phase 7: Multilingual settings\n    accent_profile_id: Optional[str] = None\n    auto_language_detection: bool = True\n    language_switch_confidence: float = 0.75\n\n    # Phase 8: Personalization settings\n    vad_sensitivity: float = 0.5  # 0-1 scale\n    personalized_vad_threshold: Optional[float] = None\n    enable_behavior_learning: bool = True\n\n    # Phase 9: Offline/fallback settings\n    enable_offline_fallback: bool = True\n    tts_cache_enabled: bool = True\n\n    # Phase 10: Conversation management settings\n    enable_sentiment_tracking: bool = True\n    enable_discourse_analysis: bool = True\n    enable_response_recommendations: bool = True\n\n\n@dataclass\nclass TTSessionMetrics:\n    \"\"\"Metrics for a T/T session.\"\"\"\n\n    connection_start_time: float = 0.0\n    first_audio_latency_ms: float = 0.0\n    total_user_speech_ms: float = 0.0\n    total_ai_speech_ms: float = 0.0\n    user_utterance_count: int = 0\n    ai_response_count: int = 0\n    barge_in_count: int = 0\n    error_count: int = 0\n    messages_sent: int = 0\n    messages_received: int = 0\n\n\n# ==============================================================================\n# WebSocket Handler\n# ==============================================================================\n\n\nclass ThinkerTalkerWebSocketHandler:\n    \"\"\"\n    WebSocket handler for Thinker/Talker voice pipeline.\n\n    Handles bidirectional communication between client and the local\n    STT → Thinker → Talker pipeline.\n\n    Protocol Messages (Client → Server):\n    - audio.input: Base64 PCM16 audio\n    - audio.input.complete: Signal end of speech\n    - message: Text message (fallback)\n    - barge_in: Interrupt AI response\n    - voice.mode: Activate/deactivate voice mode\n\n    Protocol Messages (Server → Client):\n    - transcript.delta: Partial/final transcript\n    - transcript.complete: Complete user transcript\n    - response.delta: LLM response token\n    - response.complete: Complete AI response\n    - audio.output: TTS audio chunk\n    - tool.call: Tool being called\n    - tool.result: Tool result\n    - voice.state: Pipeline state update\n    - error: Error message\n    \"\"\"\n\n    def __init__(\n        self,\n        websocket: WebSocket,\n        config: TTSessionConfig,\n        pipeline_service: Optional[VoicePipelineService] = None,\n    ):\n        self.websocket = websocket\n        self.config = config\n        self._pipeline_service = pipeline_service or voice_pipeline_service\n\n        # State\n        self._connection_state = TTConnectionState.DISCONNECTED\n        self._pipeline_session: Optional[VoicePipelineSession] = None\n        self._running = False\n        self._metrics = TTSessionMetrics()\n\n        # Tasks\n        self._receive_task: Optional[asyncio.Task] = None\n        self._heartbeat_task: Optional[asyncio.Task] = None\n\n    @property\n    def connection_state(self) -> TTConnectionState:\n        \"\"\"Get current connection state.\"\"\"\n        return self._connection_state\n\n    async def start(self) -> bool:\n        \"\"\"\n        Start the WebSocket handler.\n\n        Returns:\n            True if started successfully\n        \"\"\"\n        if self._running:\n            logger.warning(\"Handler already running\")\n            return True\n\n        self._running = True\n        self._metrics.connection_start_time = time.time()\n        self._connection_state = TTConnectionState.CONNECTING\n\n        try:\n            # Accept WebSocket connection\n            await self.websocket.accept()\n            self._connection_state = TTConnectionState.CONNECTED\n\n            # Create pipeline session\n            pipeline_config = PipelineConfig(\n                stt_language=self.config.language,\n                stt_sample_rate=self.config.stt_sample_rate,\n                stt_endpointing_ms=self.config.stt_endpointing_ms,\n                stt_utterance_end_ms=self.config.stt_utterance_end_ms,\n                voice_id=self.config.voice_id,\n                tts_model=self.config.tts_model,\n                barge_in_enabled=self.config.barge_in_enabled,\n            )\n\n            self._pipeline_session = await self._pipeline_service.create_session(\n                conversation_id=self.config.conversation_id or self.config.session_id,\n                on_message=self._handle_pipeline_message,\n                config=pipeline_config,\n                user_id=self.config.user_id,\n            )\n\n            # Start pipeline\n            if not await self._pipeline_session.start():\n                raise RuntimeError(\"Failed to start pipeline session\")\n\n            self._connection_state = TTConnectionState.READY\n\n            # Send ready message to client\n            await self._send_message(\n                {\n                    \"type\": \"session.ready\",\n                    \"session_id\": self.config.session_id,\n                    \"pipeline_mode\": \"thinker_talker\",\n                }\n            )\n\n            # Start receive loop\n            self._receive_task = asyncio.create_task(self._receive_loop())\n            self._heartbeat_task = asyncio.create_task(self._heartbeat_loop())\n\n            logger.info(\n                f\"T/T WebSocket handler started: {self.config.session_id}\",\n                extra={\"user_id\": self.config.user_id},\n            )\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to start T/T handler: {e}\")\n            self._connection_state = TTConnectionState.ERROR\n            await self._send_error(\"connection_failed\", str(e))\n            return False\n\n    async def stop(self) -> TTSessionMetrics:\n        \"\"\"\n        Stop the handler and cleanup.\n\n        Returns:\n            Session metrics\n        \"\"\"\n        if not self._running:\n            return self._metrics\n\n        self._running = False\n\n        # Cancel tasks\n        if self._receive_task:\n            self._receive_task.cancel()\n            try:\n                await self._receive_task\n            except asyncio.CancelledError:\n                pass\n\n        if self._heartbeat_task:\n            self._heartbeat_task.cancel()\n            try:\n                await self._heartbeat_task\n            except asyncio.CancelledError:\n                pass\n\n        # Stop pipeline session\n        if self._pipeline_session:\n            await self._pipeline_session.stop()\n\n        # Close WebSocket\n        try:\n            await self.websocket.close()\n        except Exception:\n            pass\n\n        self._connection_state = TTConnectionState.DISCONNECTED\n\n        logger.info(\n            f\"T/T WebSocket handler stopped: {self.config.session_id}\",\n            extra={\"metrics\": self._get_metrics_dict()},\n        )\n\n        return self._metrics\n\n    async def _receive_loop(self) -> None:\n        \"\"\"Receive and process messages from client.\"\"\"\n        logger.debug(f\"[WS] Starting receive loop for {self.config.session_id}\")\n        try:\n            while self._running:\n                try:\n                    message = await self.websocket.receive_json()\n                    self._metrics.messages_received += 1\n                    await self._handle_client_message(message)\n                except WebSocketDisconnect:\n                    logger.info(f\"WebSocket disconnected: {self.config.session_id}\")\n                    break\n                except json.JSONDecodeError as e:\n                    logger.warning(f\"Invalid JSON in message: {e}\")\n                    await self._send_error(\"invalid_json\", \"Invalid JSON message\")\n                except Exception as e:\n                    logger.error(f\"Error receiving message: {e}\", exc_info=True)\n                    self._metrics.error_count += 1\n\n        except asyncio.CancelledError:\n            logger.debug(f\"[WS] Receive loop cancelled for {self.config.session_id}\")\n        except Exception as e:\n            logger.error(f\"Receive loop error: {e}\", exc_info=True)\n        finally:\n            logger.info(\n                f\"[WS] Receive loop ended: {self.config.session_id}, total_messages={self._metrics.messages_received}\"\n            )\n            self._running = False\n\n    async def _handle_client_message(self, message: Dict[str, Any]) -> None:\n        \"\"\"Handle a message from the client.\"\"\"\n        msg_type = message.get(\"type\", \"\")\n\n        # Debug: Log every message type (except audio.input for performance)\n        if msg_type != \"audio.input\":\n            logger.debug(f\"[WS] Received message type: {msg_type}\")\n\n        if msg_type == \"session.init\":\n            # Session initialization from client (optional config updates)\n            voice_settings = message.get(\"voice_settings\", {})\n            conversation_id = message.get(\"conversation_id\")\n            advanced_settings = message.get(\"advanced_settings\", {})\n            logger.info(\n                f\"Session init received: conv_id={conversation_id}, \"\n                f\"settings={voice_settings}, advanced={advanced_settings}\"\n            )\n\n            # Apply voice settings to the pipeline config\n            if self._pipeline_session and voice_settings:\n                if \"voice_id\" in voice_settings:\n                    self._pipeline_session.config.voice_id = voice_settings[\"voice_id\"]\n                    logger.info(f\"Updated pipeline voice_id to: {voice_settings['voice_id']}\")\n                if \"language\" in voice_settings:\n                    self._pipeline_session.config.stt_language = voice_settings[\"language\"]\n                if \"barge_in_enabled\" in voice_settings:\n                    self._pipeline_session.config.barge_in_enabled = voice_settings[\"barge_in_enabled\"]\n                if \"vad_sensitivity\" in voice_settings:\n                    # Convert to int (0-100 scale)\n                    vad_sens = int(voice_settings[\"vad_sensitivity\"])\n                    self._pipeline_session.config.vad_sensitivity = max(0, min(100, vad_sens))\n                    logger.info(f\"Updated pipeline vad_sensitivity to: {self._pipeline_session.config.vad_sensitivity}\")\n\n            # Apply Phase 7-10 advanced settings to session config\n            if advanced_settings:\n                # Phase 7: Multilingual\n                if \"accent_profile_id\" in advanced_settings:\n                    self.config.accent_profile_id = advanced_settings[\"accent_profile_id\"]\n                if \"auto_language_detection\" in advanced_settings:\n                    self.config.auto_language_detection = advanced_settings[\"auto_language_detection\"]\n                if \"language_switch_confidence\" in advanced_settings:\n                    self.config.language_switch_confidence = advanced_settings[\"language_switch_confidence\"]\n\n                # Phase 8: Personalization\n                if \"vad_sensitivity\" in advanced_settings:\n                    self.config.vad_sensitivity = advanced_settings[\"vad_sensitivity\"]\n                if \"personalized_vad_threshold\" in advanced_settings:\n                    self.config.personalized_vad_threshold = advanced_settings[\"personalized_vad_threshold\"]\n                if \"enable_behavior_learning\" in advanced_settings:\n                    self.config.enable_behavior_learning = advanced_settings[\"enable_behavior_learning\"]\n\n                # Phase 9: Offline\n                if \"enable_offline_fallback\" in advanced_settings:\n                    self.config.enable_offline_fallback = advanced_settings[\"enable_offline_fallback\"]\n                if \"tts_cache_enabled\" in advanced_settings:\n                    self.config.tts_cache_enabled = advanced_settings[\"tts_cache_enabled\"]\n\n                # Phase 10: Conversation management\n                if \"enable_sentiment_tracking\" in advanced_settings:\n                    self.config.enable_sentiment_tracking = advanced_settings[\"enable_sentiment_tracking\"]\n                if \"enable_discourse_analysis\" in advanced_settings:\n                    self.config.enable_discourse_analysis = advanced_settings[\"enable_discourse_analysis\"]\n                if \"enable_response_recommendations\" in advanced_settings:\n                    self.config.enable_response_recommendations = advanced_settings[\"enable_response_recommendations\"]\n\n                logger.info(f\"Applied advanced settings: {advanced_settings}\")\n\n            # Acknowledge the init\n            await self._send_message({\"type\": \"session.init.ack\"})\n\n        elif msg_type == \"audio.input\":\n            # Audio chunk from client\n            audio_b64 = message.get(\"audio\", \"\")\n            if audio_b64 and self._pipeline_session:\n                # Log every 100th chunk\n                if self._metrics.messages_received % 100 == 0:\n                    logger.debug(f\"[WS] Audio chunk #{self._metrics.messages_received}, {len(audio_b64)} bytes b64\")\n                await self._pipeline_session.send_audio_base64(audio_b64)\n            elif not audio_b64:\n                logger.warning(\"Received audio.input with empty audio data\")\n            elif not self._pipeline_session:\n                logger.warning(\"Received audio.input but no pipeline session\")\n\n        elif msg_type == \"audio.input.complete\":\n            # User finished speaking (manual commit)\n            if self._pipeline_session:\n                await self._pipeline_session.commit_audio()\n\n        elif msg_type == \"message\":\n            # Text message (fallback mode)\n            text = message.get(\"content\", \"\")\n            if text and self._pipeline_session:\n                # Process text through Thinker directly\n                # For now, we'll send it as if it were transcribed\n                await self._handle_text_input(text)\n\n        elif msg_type == \"barge_in\":\n            # User wants to interrupt AI\n            if self._pipeline_session:\n                await self._pipeline_session.barge_in()\n                self._metrics.barge_in_count += 1\n\n        elif msg_type == \"voice.mode\":\n            # Voice mode control\n            mode = message.get(\"mode\", \"\")\n            if mode == \"activate\":\n                await self._activate_voice_mode(message.get(\"config\", {}))\n            elif mode == \"deactivate\":\n                await self._deactivate_voice_mode()\n\n        elif msg_type == \"ping\":\n            # Heartbeat response\n            await self._send_message({\"type\": \"pong\"})\n\n        else:\n            logger.warning(f\"Unknown message type: {msg_type}\")\n\n    async def _handle_text_input(self, text: str) -> None:\n        \"\"\"Handle text input (fallback when not using voice).\"\"\"\n        # Send as if it were a transcript\n        await self._send_message(\n            {\n                \"type\": \"transcript.complete\",\n                \"text\": text,\n                \"message_id\": f\"text-{time.time()}\",\n            }\n        )\n\n        # Process through thinker (this would need integration with thinker_service)\n        # For now, the pipeline handles voice input; text would go through chat endpoint\n\n    async def _activate_voice_mode(self, config: Dict) -> None:\n        \"\"\"Activate voice mode with optional config.\"\"\"\n        if self._pipeline_session and self._pipeline_session.state == PipelineState.IDLE:\n            await self._pipeline_session.start()\n\n        await self._send_message(\n            {\n                \"type\": \"voice.mode.activated\",\n            }\n        )\n\n    async def _deactivate_voice_mode(self) -> None:\n        \"\"\"Deactivate voice mode.\"\"\"\n        if self._pipeline_session:\n            await self._pipeline_session.stop()\n\n        await self._send_message(\n            {\n                \"type\": \"voice.mode.deactivated\",\n            }\n        )\n\n    async def _handle_pipeline_message(self, message: PipelineMessage) -> None:\n        \"\"\"Handle a message from the voice pipeline.\"\"\"\n        # Forward pipeline messages to client\n        await self._send_message(\n            {\n                \"type\": message.type,\n                **message.data,\n            }\n        )\n\n        # Track metrics\n        if message.type == \"transcript.complete\":\n            self._metrics.user_utterance_count += 1\n        elif message.type == \"response.complete\":\n            self._metrics.ai_response_count += 1\n        elif message.type == \"audio.output\" and message.data.get(\"audio\"):\n            # Track first audio latency\n            if self._metrics.first_audio_latency_ms == 0:\n                self._metrics.first_audio_latency_ms = (time.time() - self._metrics.connection_start_time) * 1000\n\n    async def _heartbeat_loop(self) -> None:\n        \"\"\"Send periodic heartbeats.\"\"\"\n        try:\n            while self._running:\n                await asyncio.sleep(30)  # Every 30 seconds\n                if self._running:\n                    await self._send_message({\"type\": \"heartbeat\"})\n        except asyncio.CancelledError:\n            pass\n\n    async def _send_message(self, message: Dict[str, Any]) -> None:\n        \"\"\"Send a message to the client.\"\"\"\n        try:\n            await self.websocket.send_json(message)\n            self._metrics.messages_sent += 1\n        except Exception as e:\n            logger.error(f\"Error sending message: {e}\")\n            self._metrics.error_count += 1\n\n    async def _send_error(self, code: str, message: str, recoverable: bool = True) -> None:\n        \"\"\"Send an error message to the client.\"\"\"\n        await self._send_message(\n            {\n                \"type\": \"error\",\n                \"code\": code,\n                \"message\": message,\n                \"recoverable\": recoverable,\n            }\n        )\n\n    def _get_metrics_dict(self) -> Dict[str, Any]:\n        \"\"\"Get metrics as dictionary.\"\"\"\n        return {\n            \"first_audio_latency_ms\": self._metrics.first_audio_latency_ms,\n            \"user_utterance_count\": self._metrics.user_utterance_count,\n            \"ai_response_count\": self._metrics.ai_response_count,\n            \"barge_in_count\": self._metrics.barge_in_count,\n            \"error_count\": self._metrics.error_count,\n            \"messages_sent\": self._metrics.messages_sent,\n            \"messages_received\": self._metrics.messages_received,\n        }\n\n    def get_metrics(self) -> TTSessionMetrics:\n        \"\"\"Get current session metrics.\"\"\"\n        return self._metrics\n\n\n# ==============================================================================\n# Session Manager\n# ==============================================================================\n\n\nclass ThinkerTalkerSessionManager:\n    \"\"\"\n    Manager for Thinker/Talker WebSocket sessions.\n\n    Handles session lifecycle and provides both T/T and Realtime API modes.\n    \"\"\"\n\n    def __init__(self, max_sessions: int = 100):\n        self.max_sessions = max_sessions\n        self._sessions: Dict[str, ThinkerTalkerWebSocketHandler] = {}\n        self._lock = asyncio.Lock()\n\n    async def create_session(\n        self,\n        websocket: WebSocket,\n        config: TTSessionConfig,\n    ) -> ThinkerTalkerWebSocketHandler:\n        \"\"\"\n        Create a new T/T session.\n\n        Args:\n            websocket: Starlette WebSocket instance\n            config: Session configuration\n\n        Returns:\n            ThinkerTalkerWebSocketHandler instance\n\n        Raises:\n            ValueError: If max sessions reached\n        \"\"\"\n        async with self._lock:\n            if len(self._sessions) >= self.max_sessions:\n                raise ValueError(\"Maximum concurrent sessions reached\")\n\n            handler = ThinkerTalkerWebSocketHandler(\n                websocket=websocket,\n                config=config,\n            )\n\n            self._sessions[config.session_id] = handler\n            return handler\n\n    async def get_session(self, session_id: str) -> Optional[ThinkerTalkerWebSocketHandler]:\n        \"\"\"Get a session by ID.\"\"\"\n        return self._sessions.get(session_id)\n\n    async def remove_session(self, session_id: str) -> None:\n        \"\"\"Remove a session.\"\"\"\n        async with self._lock:\n            if session_id in self._sessions:\n                handler = self._sessions.pop(session_id)\n                await handler.stop()\n\n    def get_active_session_count(self) -> int:\n        \"\"\"Get count of active sessions.\"\"\"\n        return len(self._sessions)\n\n\n# Global session manager\nthinker_talker_session_manager = ThinkerTalkerSessionManager()\n"
}
