{
  "path": "apps/web-app/src/components/voice/FrequencySpectrum.tsx",
  "language": "typescript",
  "size": 5543,
  "last_modified": "2025-11-27T06:53:16.478Z",
  "lines": 195,
  "content": "/**\n * Frequency Spectrum Visualizer Component\n * Displays real-time audio frequency analysis\n *\n * Phase 9.3: Enhanced Voice Features\n */\n\nimport { useEffect, useRef, useCallback } from \"react\";\n\ninterface FrequencySpectrumProps {\n  /** Audio stream to visualize */\n  stream: MediaStream | null;\n  /** Width of the canvas */\n  width?: number;\n  /** Height of the canvas */\n  height?: number;\n  /** Bar color */\n  barColor?: string;\n  /** Background color */\n  backgroundColor?: string;\n  /** Number of frequency bars */\n  barCount?: number;\n  /** Gap between bars (px) */\n  barGap?: number;\n  /** Border radius for bars */\n  barRadius?: number;\n  /** Whether visualization is active */\n  active?: boolean;\n  /** Custom class name */\n  className?: string;\n}\n\nexport function FrequencySpectrum({\n  stream,\n  width = 300,\n  height = 60,\n  barColor = \"#3b82f6\",\n  backgroundColor = \"transparent\",\n  barCount = 32,\n  barGap = 2,\n  barRadius = 2,\n  active = true,\n  className = \"\",\n}: FrequencySpectrumProps) {\n  const canvasRef = useRef<HTMLCanvasElement>(null);\n  const animationRef = useRef<number | null>(null);\n  const audioContextRef = useRef<AudioContext | null>(null);\n  const analyserRef = useRef<AnalyserNode | null>(null);\n  const dataArrayRef = useRef<Uint8Array<ArrayBuffer> | null>(null);\n\n  const draw = useCallback(() => {\n    const canvas = canvasRef.current;\n    const analyser = analyserRef.current;\n    const dataArray = dataArrayRef.current;\n\n    if (!canvas || !analyser || !dataArray || !active) return;\n\n    const ctx = canvas.getContext(\"2d\");\n    if (!ctx) return;\n\n    // Get frequency data\n    analyser.getByteFrequencyData(dataArray);\n\n    // Clear canvas\n    ctx.fillStyle = backgroundColor;\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n\n    // Calculate bar dimensions\n    const totalGaps = (barCount - 1) * barGap;\n    const barWidth = (canvas.width - totalGaps) / barCount;\n    const frequencyBinCount = analyser.frequencyBinCount;\n    const binSize = Math.floor(frequencyBinCount / barCount);\n\n    // Draw frequency bars\n    for (let i = 0; i < barCount; i++) {\n      // Average frequency values for this bar\n      let sum = 0;\n      for (let j = 0; j < binSize; j++) {\n        sum += dataArray[i * binSize + j];\n      }\n      const average = sum / binSize;\n\n      // Calculate bar height (normalized to 0-1, then scaled to canvas height)\n      const normalizedHeight = average / 255;\n      const barHeight = Math.max(\n        normalizedHeight * canvas.height * 0.9,\n        barRadius * 2,\n      );\n\n      const x = i * (barWidth + barGap);\n      const y = canvas.height - barHeight;\n\n      // Draw rounded bar\n      ctx.beginPath();\n      ctx.fillStyle = barColor;\n      ctx.roundRect(x, y, barWidth, barHeight, barRadius);\n      ctx.fill();\n    }\n\n    // Continue animation\n    animationRef.current = requestAnimationFrame(draw);\n  }, [active, backgroundColor, barColor, barCount, barGap, barRadius]);\n\n  // Connect to stream and start visualization\n  useEffect(() => {\n    if (!stream || !active) return;\n\n    const setupAudio = async () => {\n      try {\n        // Create audio context\n        audioContextRef.current = new AudioContext();\n        const source = audioContextRef.current.createMediaStreamSource(stream);\n\n        // Create analyser\n        analyserRef.current = audioContextRef.current.createAnalyser();\n        analyserRef.current.fftSize = 256; // Must be power of 2\n        analyserRef.current.smoothingTimeConstant = 0.8;\n\n        // Connect source to analyser\n        source.connect(analyserRef.current);\n\n        // Create data array\n        const bufferLength = analyserRef.current.frequencyBinCount;\n        dataArrayRef.current = new Uint8Array(new ArrayBuffer(bufferLength));\n\n        // Start drawing\n        draw();\n      } catch (err) {\n        console.error(\"[FrequencySpectrum] Failed to setup audio:\", err);\n      }\n    };\n\n    setupAudio();\n\n    return () => {\n      // Cleanup\n      if (animationRef.current) {\n        cancelAnimationFrame(animationRef.current);\n        animationRef.current = null;\n      }\n      if (\n        audioContextRef.current &&\n        audioContextRef.current.state !== \"closed\"\n      ) {\n        audioContextRef.current.close();\n        audioContextRef.current = null;\n      }\n      analyserRef.current = null;\n      dataArrayRef.current = null;\n    };\n  }, [stream, active, draw]);\n\n  // Draw inactive state when no stream\n  useEffect(() => {\n    if (stream && active) return;\n\n    const canvas = canvasRef.current;\n    if (!canvas) return;\n\n    const ctx = canvas.getContext(\"2d\");\n    if (!ctx) return;\n\n    // Clear canvas\n    ctx.fillStyle = backgroundColor;\n    ctx.fillRect(0, 0, canvas.width, canvas.height);\n\n    // Draw placeholder bars\n    const totalGaps = (barCount - 1) * barGap;\n    const barWidth = (canvas.width - totalGaps) / barCount;\n    const minHeight = barRadius * 2;\n\n    for (let i = 0; i < barCount; i++) {\n      const x = i * (barWidth + barGap);\n      const y = canvas.height - minHeight;\n\n      ctx.beginPath();\n      ctx.fillStyle = `${barColor}33`; // 20% opacity\n      ctx.roundRect(x, y, barWidth, minHeight, barRadius);\n      ctx.fill();\n    }\n  }, [stream, active, backgroundColor, barColor, barCount, barGap, barRadius]);\n\n  return (\n    <canvas\n      ref={canvasRef}\n      width={width}\n      height={height}\n      className={`rounded ${className}`}\n      style={{ width: \"100%\", height: \"auto\", maxWidth: width }}\n      aria-label=\"Audio frequency spectrum visualization\"\n      role=\"img\"\n    />\n  );\n}\n"
}
