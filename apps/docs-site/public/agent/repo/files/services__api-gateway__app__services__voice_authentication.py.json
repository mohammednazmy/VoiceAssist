{
  "path": "services/api-gateway/app/services/voice_authentication.py",
  "language": "python",
  "size": 29507,
  "last_modified": "2025-12-04T11:27:02.747Z",
  "lines": 846,
  "content": "\"\"\"\nVoice Authentication Service\n\nProvides voice biometric authentication for voice sessions:\n- Speaker enrollment (voice print creation)\n- Speaker verification (voice print matching)\n- Anti-spoofing detection\n- Secure voice print storage\n\nUses MFCC-based voice features with cosine similarity matching.\nThis implementation is suitable for basic speaker verification.\nFor production use with high security requirements, consider\ndedicated biometric services (Azure Speaker Recognition, AWS Voice ID).\n\"\"\"\n\nimport base64\nimport hashlib\nimport hmac\nimport json\nimport math\nimport struct\nimport time\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom app.core.config import settings\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass VoiceAuthStatus(Enum):\n    \"\"\"Voice authentication status\"\"\"\n\n    NOT_ENROLLED = \"not_enrolled\"\n    ENROLLED = \"enrolled\"\n    VERIFIED = \"verified\"\n    FAILED = \"failed\"\n    SPOOF_DETECTED = \"spoof_detected\"\n\n\nclass EnrollmentStatus(Enum):\n    \"\"\"Voice enrollment status\"\"\"\n\n    NOT_STARTED = \"not_started\"\n    IN_PROGRESS = \"in_progress\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass VoicePrintConfig:\n    \"\"\"Configuration for voice print extraction\"\"\"\n\n    # Audio parameters\n    sample_rate: int = 16000\n    frame_size_ms: int = 25\n    frame_step_ms: int = 10\n\n    # MFCC parameters\n    num_mfcc_coeffs: int = 13\n    num_mel_filters: int = 26\n    fft_size: int = 512\n\n    # Enrollment parameters\n    min_enrollment_samples: int = 3\n    max_enrollment_samples: int = 10\n    min_audio_duration_sec: float = 2.0\n    max_audio_duration_sec: float = 10.0\n\n    # Verification parameters\n    similarity_threshold: float = 0.75\n    spoof_detection_enabled: bool = True\n    spoof_threshold: float = 0.3\n\n\n@dataclass\nclass VoicePrint:\n    \"\"\"Voice print (voice biometric template)\"\"\"\n\n    user_id: str\n    created_at: float\n    updated_at: float\n    sample_count: int\n    mfcc_mean: List[float]\n    mfcc_std: List[float]\n    pitch_mean: float\n    pitch_std: float\n    energy_mean: float\n    energy_std: float\n    checksum: str  # For integrity verification\n\n\n@dataclass\nclass EnrollmentSession:\n    \"\"\"Active enrollment session\"\"\"\n\n    user_id: str\n    status: EnrollmentStatus\n    samples: List[bytes] = field(default_factory=list)\n    mfcc_samples: List[List[float]] = field(default_factory=list)\n    pitch_samples: List[float] = field(default_factory=list)\n    energy_samples: List[float] = field(default_factory=list)\n    started_at: float = 0.0\n    error_message: Optional[str] = None\n\n\n@dataclass\nclass VerificationResult:\n    \"\"\"Result of voice verification\"\"\"\n\n    verified: bool\n    confidence: float\n    status: VoiceAuthStatus\n    details: Dict[str, Any] = field(default_factory=dict)\n\n\nclass VoiceFeatureExtractor:\n    \"\"\"\n    Extract voice features for biometric matching.\n\n    Uses MFCC (Mel-frequency cepstral coefficients) as the primary\n    voice characteristic, along with pitch and energy features.\n    \"\"\"\n\n    def __init__(self, config: VoicePrintConfig):\n        self.config = config\n        self._init_mel_filterbank()\n\n    def _init_mel_filterbank(self) -> None:\n        \"\"\"Initialize Mel filterbank for MFCC computation.\"\"\"\n\n        # Mel scale conversion\n        def hz_to_mel(hz: float) -> float:\n            return 2595 * math.log10(1 + hz / 700)\n\n        def mel_to_hz(mel: float) -> float:\n            return 700 * (10 ** (mel / 2595) - 1)\n\n        # Create Mel filterbank\n        low_freq = 0\n        high_freq = self.config.sample_rate / 2\n        low_mel = hz_to_mel(low_freq)\n        high_mel = hz_to_mel(high_freq)\n\n        # Mel points evenly spaced\n        mel_points = [\n            low_mel + i * (high_mel - low_mel) / (self.config.num_mel_filters + 1)\n            for i in range(self.config.num_mel_filters + 2)\n        ]\n        hz_points = [mel_to_hz(m) for m in mel_points]\n\n        # Convert to FFT bin indices\n        bin_points = [int((self.config.fft_size + 1) * hz / self.config.sample_rate) for hz in hz_points]\n\n        # Create triangular filters\n        self._mel_filterbank = []\n        for i in range(1, self.config.num_mel_filters + 1):\n            filter_bank = [0.0] * (self.config.fft_size // 2 + 1)\n            for j in range(bin_points[i - 1], bin_points[i]):\n                if bin_points[i] != bin_points[i - 1]:\n                    filter_bank[j] = (j - bin_points[i - 1]) / (bin_points[i] - bin_points[i - 1])\n            for j in range(bin_points[i], bin_points[i + 1]):\n                if bin_points[i + 1] != bin_points[i]:\n                    filter_bank[j] = (bin_points[i + 1] - j) / (bin_points[i + 1] - bin_points[i])\n            self._mel_filterbank.append(filter_bank)\n\n    def extract_features(self, audio_data: bytes) -> Dict[str, Any]:\n        \"\"\"\n        Extract voice features from audio data.\n\n        Args:\n            audio_data: PCM16 audio data\n\n        Returns:\n            Dictionary with extracted features\n        \"\"\"\n        # Convert to samples\n        samples = self._bytes_to_samples(audio_data)\n        if len(samples) < self.config.fft_size:\n            return {\"error\": \"Audio too short\"}\n\n        # Pre-emphasis filter\n        samples = self._preemphasis(samples)\n\n        # Frame the signal\n        frames = self._frame_signal(samples)\n        if not frames:\n            return {\"error\": \"No complete frames\"}\n\n        # Extract MFCC for each frame\n        mfcc_features = []\n        energy_features = []\n\n        for frame in frames:\n            # Apply Hamming window\n            windowed = self._apply_window(frame)\n\n            # Compute FFT\n            spectrum = self._compute_fft(windowed)\n\n            # Apply Mel filterbank\n            mel_energies = self._apply_mel_filterbank(spectrum)\n\n            # Compute MFCCs using DCT\n            mfcc = self._compute_dct(mel_energies)\n            mfcc_features.append(mfcc)\n\n            # Compute frame energy\n            energy = sum(s * s for s in frame) / len(frame)\n            energy_features.append(energy)\n\n        # Compute pitch (fundamental frequency) estimate\n        pitch = self._estimate_pitch(samples)\n\n        # Aggregate features across frames\n        return {\n            \"mfcc_mean\": self._compute_mean(mfcc_features),\n            \"mfcc_std\": self._compute_std(mfcc_features),\n            \"energy_mean\": sum(energy_features) / len(energy_features),\n            \"energy_std\": self._std(energy_features),\n            \"pitch\": pitch,\n            \"frame_count\": len(frames),\n        }\n\n    def _bytes_to_samples(self, audio_bytes: bytes) -> List[float]:\n        \"\"\"Convert PCM16 bytes to normalized samples.\"\"\"\n        n_samples = len(audio_bytes) // 2\n        samples = struct.unpack(f\"<{n_samples}h\", audio_bytes)\n        return [s / 32768.0 for s in samples]\n\n    def _preemphasis(self, samples: List[float], coeff: float = 0.97) -> List[float]:\n        \"\"\"Apply pre-emphasis filter.\"\"\"\n        return [samples[0]] + [samples[i] - coeff * samples[i - 1] for i in range(1, len(samples))]\n\n    def _frame_signal(self, samples: List[float]) -> List[List[float]]:\n        \"\"\"Frame the signal into overlapping windows.\"\"\"\n        frame_size = int(self.config.sample_rate * self.config.frame_size_ms / 1000)\n        frame_step = int(self.config.sample_rate * self.config.frame_step_ms / 1000)\n\n        frames = []\n        for start in range(0, len(samples) - frame_size + 1, frame_step):\n            frames.append(samples[start : start + frame_size])\n\n        return frames\n\n    def _apply_window(self, frame: List[float]) -> List[float]:\n        \"\"\"Apply Hamming window to frame.\"\"\"\n        n = len(frame)\n        return [sample * (0.54 - 0.46 * math.cos(2 * math.pi * i / (n - 1))) for i, sample in enumerate(frame)]\n\n    def _compute_fft(self, signal: List[float]) -> List[float]:\n        \"\"\"Compute FFT magnitude spectrum using DFT (simplified).\"\"\"\n        # Pad to FFT size\n        padded = signal + [0.0] * (self.config.fft_size - len(signal))\n        n = len(padded)\n\n        # Compute DFT (simplified - for production use numpy.fft)\n        spectrum = []\n        for k in range(n // 2 + 1):\n            real = sum(padded[t] * math.cos(2 * math.pi * k * t / n) for t in range(n))\n            imag = sum(padded[t] * math.sin(2 * math.pi * k * t / n) for t in range(n))\n            magnitude = math.sqrt(real * real + imag * imag)\n            spectrum.append(magnitude)\n\n        return spectrum\n\n    def _apply_mel_filterbank(self, spectrum: List[float]) -> List[float]:\n        \"\"\"Apply Mel filterbank to spectrum.\"\"\"\n        mel_energies = []\n        for filter_bank in self._mel_filterbank:\n            energy = sum(s * f for s, f in zip(spectrum, filter_bank))\n            # Log compression (with floor to avoid log(0))\n            mel_energies.append(math.log(max(energy, 1e-10)))\n        return mel_energies\n\n    def _compute_dct(self, mel_energies: List[float]) -> List[float]:\n        \"\"\"Compute DCT to get MFCCs.\"\"\"\n        n = len(mel_energies)\n        mfcc = []\n        for k in range(self.config.num_mfcc_coeffs):\n            coeff = sum(mel_energies[i] * math.cos(math.pi * k * (2 * i + 1) / (2 * n)) for i in range(n))\n            mfcc.append(coeff)\n        return mfcc\n\n    def _estimate_pitch(self, samples: List[float]) -> float:\n        \"\"\"Estimate fundamental frequency using autocorrelation.\"\"\"\n        # Simple autocorrelation-based pitch detection\n        min_lag = int(self.config.sample_rate / 500)  # Max 500Hz\n        max_lag = int(self.config.sample_rate / 50)  # Min 50Hz\n\n        if len(samples) < max_lag * 2:\n            return 0.0\n\n        # Compute autocorrelation for each lag\n        best_lag = min_lag\n        best_correlation = 0.0\n\n        for lag in range(min_lag, min(max_lag, len(samples) // 2)):\n            correlation = sum(samples[i] * samples[i + lag] for i in range(len(samples) - lag))\n            if correlation > best_correlation:\n                best_correlation = correlation\n                best_lag = lag\n\n        # Convert lag to frequency\n        if best_lag > 0:\n            return self.config.sample_rate / best_lag\n        return 0.0\n\n    def _compute_mean(self, feature_list: List[List[float]]) -> List[float]:\n        \"\"\"Compute mean across frames for each coefficient.\"\"\"\n        if not feature_list:\n            return []\n        n_coeffs = len(feature_list[0])\n        return [sum(f[i] for f in feature_list) / len(feature_list) for i in range(n_coeffs)]\n\n    def _compute_std(self, feature_list: List[List[float]]) -> List[float]:\n        \"\"\"Compute standard deviation across frames.\"\"\"\n        if not feature_list:\n            return []\n        means = self._compute_mean(feature_list)\n        n_coeffs = len(feature_list[0])\n        n_frames = len(feature_list)\n        return [math.sqrt(sum((f[i] - means[i]) ** 2 for f in feature_list) / n_frames) for i in range(n_coeffs)]\n\n    def _std(self, values: List[float]) -> float:\n        \"\"\"Compute standard deviation.\"\"\"\n        if not values:\n            return 0.0\n        mean = sum(values) / len(values)\n        variance = sum((v - mean) ** 2 for v in values) / len(values)\n        return math.sqrt(variance)\n\n\nclass VoiceAuthenticationService:\n    \"\"\"\n    Voice authentication service for speaker verification.\n\n    Provides enrollment and verification capabilities using\n    voice biometric features.\n    \"\"\"\n\n    def __init__(self, config: Optional[VoicePrintConfig] = None):\n        self.config = config or VoicePrintConfig()\n        self._feature_extractor = VoiceFeatureExtractor(self.config)\n        self._voice_prints: Dict[str, VoicePrint] = {}\n        self._enrollment_sessions: Dict[str, EnrollmentSession] = {}\n\n        logger.debug(\"VoiceAuthenticationService initialized\")\n\n    def start_enrollment(self, user_id: str) -> EnrollmentSession:\n        \"\"\"\n        Start a voice enrollment session.\n\n        Args:\n            user_id: User ID to enroll\n\n        Returns:\n            EnrollmentSession instance\n        \"\"\"\n        session = EnrollmentSession(\n            user_id=user_id,\n            status=EnrollmentStatus.IN_PROGRESS,\n            started_at=time.time(),\n        )\n        self._enrollment_sessions[user_id] = session\n\n        logger.info(\n            f\"Started voice enrollment for user {user_id}\",\n            extra={\"user_id\": user_id},\n        )\n\n        return session\n\n    def add_enrollment_sample(self, user_id: str, audio_data: bytes) -> Tuple[bool, str]:\n        \"\"\"\n        Add an audio sample to the enrollment session.\n\n        Args:\n            user_id: User ID\n            audio_data: PCM16 audio data\n\n        Returns:\n            Tuple of (success, message)\n        \"\"\"\n        session = self._enrollment_sessions.get(user_id)\n        if not session:\n            return False, \"No active enrollment session\"\n\n        if session.status != EnrollmentStatus.IN_PROGRESS:\n            return False, f\"Enrollment is {session.status.value}\"\n\n        # Validate audio duration\n        duration = len(audio_data) / 2 / self.config.sample_rate\n        if duration < self.config.min_audio_duration_sec:\n            return False, f\"Audio too short (min {self.config.min_audio_duration_sec}s)\"\n        if duration > self.config.max_audio_duration_sec:\n            return False, f\"Audio too long (max {self.config.max_audio_duration_sec}s)\"\n\n        # Extract features\n        features = self._feature_extractor.extract_features(audio_data)\n        if \"error\" in features:\n            return False, features[\"error\"]\n\n        # Store sample data\n        session.samples.append(audio_data)\n        session.mfcc_samples.append(features[\"mfcc_mean\"])\n        session.pitch_samples.append(features[\"pitch\"])\n        session.energy_samples.append(features[\"energy_mean\"])\n\n        sample_count = len(session.samples)\n        logger.info(\n            f\"Added enrollment sample {sample_count} for user {user_id}\",\n            extra={\"user_id\": user_id, \"sample_count\": sample_count},\n        )\n\n        return True, f\"Sample {sample_count} added\"\n\n    def complete_enrollment(self, user_id: str) -> Tuple[bool, str]:\n        \"\"\"\n        Complete the enrollment process and create voice print.\n\n        Args:\n            user_id: User ID\n\n        Returns:\n            Tuple of (success, message)\n        \"\"\"\n        session = self._enrollment_sessions.get(user_id)\n        if not session:\n            return False, \"No active enrollment session\"\n\n        if len(session.samples) < self.config.min_enrollment_samples:\n            return (\n                False,\n                f\"Need at least {self.config.min_enrollment_samples} samples\",\n            )\n\n        # Compute aggregated voice print\n        mfcc_mean = self._compute_list_mean(session.mfcc_samples)\n        mfcc_std = self._compute_list_std(session.mfcc_samples)\n        pitch_mean = sum(session.pitch_samples) / len(session.pitch_samples)\n        pitch_std = self._std(session.pitch_samples)\n        energy_mean = sum(session.energy_samples) / len(session.energy_samples)\n        energy_std = self._std(session.energy_samples)\n\n        # Create voice print\n        now = time.time()\n        voice_print = VoicePrint(\n            user_id=user_id,\n            created_at=now,\n            updated_at=now,\n            sample_count=len(session.samples),\n            mfcc_mean=mfcc_mean,\n            mfcc_std=mfcc_std,\n            pitch_mean=pitch_mean,\n            pitch_std=pitch_std,\n            energy_mean=energy_mean,\n            energy_std=energy_std,\n            checksum=self._compute_checksum(mfcc_mean, pitch_mean, energy_mean),\n        )\n\n        self._voice_prints[user_id] = voice_print\n        session.status = EnrollmentStatus.COMPLETED\n        del self._enrollment_sessions[user_id]\n\n        logger.info(\n            f\"Voice enrollment completed for user {user_id}\",\n            extra={\n                \"user_id\": user_id,\n                \"sample_count\": voice_print.sample_count,\n            },\n        )\n\n        return True, \"Enrollment completed successfully\"\n\n    def verify(self, user_id: str, audio_data: bytes) -> VerificationResult:\n        \"\"\"\n        Verify a voice sample against the stored voice print.\n\n        Args:\n            user_id: User ID to verify\n            audio_data: PCM16 audio data\n\n        Returns:\n            VerificationResult\n        \"\"\"\n        voice_print = self._voice_prints.get(user_id)\n        if not voice_print:\n            return VerificationResult(\n                verified=False,\n                confidence=0.0,\n                status=VoiceAuthStatus.NOT_ENROLLED,\n                details={\"error\": \"User not enrolled\"},\n            )\n\n        # Verify checksum\n        expected_checksum = self._compute_checksum(\n            voice_print.mfcc_mean,\n            voice_print.pitch_mean,\n            voice_print.energy_mean,\n        )\n        if voice_print.checksum != expected_checksum:\n            logger.warning(f\"Voice print checksum mismatch for user {user_id}\")\n            return VerificationResult(\n                verified=False,\n                confidence=0.0,\n                status=VoiceAuthStatus.FAILED,\n                details={\"error\": \"Voice print corrupted\"},\n            )\n\n        # Extract features from verification sample\n        features = self._feature_extractor.extract_features(audio_data)\n        if \"error\" in features:\n            return VerificationResult(\n                verified=False,\n                confidence=0.0,\n                status=VoiceAuthStatus.FAILED,\n                details={\"error\": features[\"error\"]},\n            )\n\n        # Check for spoofing\n        if self.config.spoof_detection_enabled:\n            spoof_score = self._detect_spoof(audio_data)\n            if spoof_score > self.config.spoof_threshold:\n                logger.warning(\n                    f\"Possible spoofing detected for user {user_id}\",\n                    extra={\"spoof_score\": spoof_score},\n                )\n                return VerificationResult(\n                    verified=False,\n                    confidence=0.0,\n                    status=VoiceAuthStatus.SPOOF_DETECTED,\n                    details={\"spoof_score\": spoof_score},\n                )\n\n        # Compute similarity scores\n        mfcc_similarity = self._cosine_similarity(voice_print.mfcc_mean, features[\"mfcc_mean\"])\n\n        pitch_diff = abs(voice_print.pitch_mean - features[\"pitch\"])\n        pitch_tolerance = voice_print.pitch_std * 2 + 10  # Allow some variation\n        pitch_score = max(0, 1 - pitch_diff / pitch_tolerance)\n\n        energy_diff = abs(voice_print.energy_mean - features[\"energy_mean\"])\n        energy_tolerance = voice_print.energy_std * 2 + 0.1\n        energy_score = max(0, 1 - energy_diff / energy_tolerance)\n\n        # Weighted combination\n        confidence = 0.7 * mfcc_similarity + 0.2 * pitch_score + 0.1 * energy_score\n\n        verified = confidence >= self.config.similarity_threshold\n        status = VoiceAuthStatus.VERIFIED if verified else VoiceAuthStatus.FAILED\n\n        logger.info(\n            f\"Voice verification for user {user_id}: {status.value}\",\n            extra={\n                \"user_id\": user_id,\n                \"confidence\": confidence,\n                \"verified\": verified,\n            },\n        )\n\n        return VerificationResult(\n            verified=verified,\n            confidence=confidence,\n            status=status,\n            details={\n                \"mfcc_similarity\": mfcc_similarity,\n                \"pitch_score\": pitch_score,\n                \"energy_score\": energy_score,\n            },\n        )\n\n    def is_enrolled(self, user_id: str) -> bool:\n        \"\"\"Check if a user is enrolled.\"\"\"\n        return user_id in self._voice_prints\n\n    def delete_voice_print(self, user_id: str) -> bool:\n        \"\"\"Delete a user's voice print.\"\"\"\n        if user_id in self._voice_prints:\n            del self._voice_prints[user_id]\n            logger.info(f\"Deleted voice print for user {user_id}\")\n            return True\n        return False\n\n    def issue_session_token(self, user_id: str, session_id: str) -> str:\n        \"\"\"Create a signed token binding a user to a voice session.\"\"\"\n\n        payload = {\n            \"user_id\": user_id,\n            \"session_id\": session_id,\n            \"issued_at\": int(time.time()),\n        }\n        payload_json = json.dumps(payload, separators=(\",\", \":\"), sort_keys=True)\n        payload_b64 = base64.urlsafe_b64encode(payload_json.encode()).decode()\n\n        signature = hmac.new(settings.JWT_SECRET.encode(), payload_b64.encode(), hashlib.sha256).digest()\n        signature_b64 = base64.urlsafe_b64encode(signature).decode()\n        return f\"{payload_b64}.{signature_b64}\"\n\n    def validate_session_token(self, token: str) -> dict:\n        \"\"\"Validate and decode a voice session token.\"\"\"\n\n        if not token or \".\" not in token:\n            raise ValueError(\"Malformed voice session token\")\n\n        payload_b64, signature_b64 = token.split(\".\", 1)\n        expected_sig = hmac.new(settings.JWT_SECRET.encode(), payload_b64.encode(), hashlib.sha256).digest()\n        expected_sig_b64 = base64.urlsafe_b64encode(expected_sig).decode()\n\n        if not hmac.compare_digest(signature_b64, expected_sig_b64):\n            raise ValueError(\"Voice session signature mismatch\")\n\n        payload_json = base64.urlsafe_b64decode(payload_b64).decode()\n        payload = json.loads(payload_json)\n        return payload\n\n    def get_enrollment_status(self, user_id: str) -> Dict[str, Any]:\n        \"\"\"Get enrollment status for a user.\"\"\"\n        if user_id in self._voice_prints:\n            vp = self._voice_prints[user_id]\n            return {\n                \"status\": \"enrolled\",\n                \"sample_count\": vp.sample_count,\n                \"created_at\": vp.created_at,\n                \"updated_at\": vp.updated_at,\n            }\n        elif user_id in self._enrollment_sessions:\n            session = self._enrollment_sessions[user_id]\n            return {\n                \"status\": \"in_progress\",\n                \"sample_count\": len(session.samples),\n                \"started_at\": session.started_at,\n            }\n        else:\n            return {\"status\": \"not_enrolled\"}\n\n    def export_voice_print(self, user_id: str) -> Optional[str]:\n        \"\"\"\n        Export voice print as encrypted JSON.\n\n        Args:\n            user_id: User ID\n\n        Returns:\n            Base64-encoded encrypted voice print, or None if not found\n        \"\"\"\n        voice_print = self._voice_prints.get(user_id)\n        if not voice_print:\n            return None\n\n        # Serialize to JSON\n        data = {\n            \"user_id\": voice_print.user_id,\n            \"created_at\": voice_print.created_at,\n            \"updated_at\": voice_print.updated_at,\n            \"sample_count\": voice_print.sample_count,\n            \"mfcc_mean\": voice_print.mfcc_mean,\n            \"mfcc_std\": voice_print.mfcc_std,\n            \"pitch_mean\": voice_print.pitch_mean,\n            \"pitch_std\": voice_print.pitch_std,\n            \"energy_mean\": voice_print.energy_mean,\n            \"energy_std\": voice_print.energy_std,\n            \"checksum\": voice_print.checksum,\n        }\n\n        json_data = json.dumps(data, separators=(\",\", \":\"))\n\n        # Sign the data\n        signature = hmac.new(\n            settings.JWT_SECRET.encode(),\n            json_data.encode(),\n            hashlib.sha256,\n        ).digest()\n\n        # Combine and encode\n        combined = json_data.encode() + b\".\" + signature\n        return base64.urlsafe_b64encode(combined).decode()\n\n    def import_voice_print(self, user_id: str, encoded_data: str) -> bool:\n        \"\"\"\n        Import voice print from encrypted JSON.\n\n        Args:\n            user_id: User ID\n            encoded_data: Base64-encoded encrypted voice print\n\n        Returns:\n            True if import successful\n        \"\"\"\n        try:\n            # Decode\n            combined = base64.urlsafe_b64decode(encoded_data)\n            parts = combined.rsplit(b\".\", 1)\n            if len(parts) != 2:\n                return False\n\n            json_data, signature = parts\n\n            # Verify signature\n            expected_signature = hmac.new(\n                settings.JWT_SECRET.encode(),\n                json_data,\n                hashlib.sha256,\n            ).digest()\n\n            if not hmac.compare_digest(signature, expected_signature):\n                logger.warning(f\"Invalid voice print signature for user {user_id}\")\n                return False\n\n            # Parse JSON\n            data = json.loads(json_data.decode())\n\n            # Verify user ID matches\n            if data[\"user_id\"] != user_id:\n                logger.warning(\"Voice print user ID mismatch\")\n                return False\n\n            # Create voice print\n            voice_print = VoicePrint(\n                user_id=data[\"user_id\"],\n                created_at=data[\"created_at\"],\n                updated_at=data[\"updated_at\"],\n                sample_count=data[\"sample_count\"],\n                mfcc_mean=data[\"mfcc_mean\"],\n                mfcc_std=data[\"mfcc_std\"],\n                pitch_mean=data[\"pitch_mean\"],\n                pitch_std=data[\"pitch_std\"],\n                energy_mean=data[\"energy_mean\"],\n                energy_std=data[\"energy_std\"],\n                checksum=data[\"checksum\"],\n            )\n\n            # Verify checksum\n            expected_checksum = self._compute_checksum(\n                voice_print.mfcc_mean,\n                voice_print.pitch_mean,\n                voice_print.energy_mean,\n            )\n            if voice_print.checksum != expected_checksum:\n                logger.warning(\"Voice print checksum mismatch during import\")\n                return False\n\n            self._voice_prints[user_id] = voice_print\n            logger.info(f\"Imported voice print for user {user_id}\")\n            return True\n\n        except Exception as e:\n            logger.error(f\"Failed to import voice print: {e}\")\n            return False\n\n    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:\n        \"\"\"Compute cosine similarity between two vectors.\"\"\"\n        if len(vec1) != len(vec2):\n            return 0.0\n\n        dot_product = sum(a * b for a, b in zip(vec1, vec2))\n        norm1 = math.sqrt(sum(a * a for a in vec1))\n        norm2 = math.sqrt(sum(b * b for b in vec2))\n\n        if norm1 == 0 or norm2 == 0:\n            return 0.0\n\n        return dot_product / (norm1 * norm2)\n\n    def _detect_spoof(self, audio_data: bytes) -> float:\n        \"\"\"\n        Simple anti-spoofing detection.\n\n        Checks for characteristics of recorded/synthetic audio:\n        - Unnaturally constant energy\n        - Missing high-frequency content\n        - Repetitive patterns\n\n        Returns:\n            Spoof score (0-1, higher = more likely spoof)\n        \"\"\"\n        samples = [s / 32768.0 for s in struct.unpack(f\"<{len(audio_data) // 2}h\", audio_data)]\n\n        if len(samples) < 1000:\n            return 0.0\n\n        # Check energy variance (real speech has more variation)\n        frame_size = 160  # 10ms at 16kHz\n        energies = []\n        for i in range(0, len(samples) - frame_size, frame_size):\n            frame = samples[i : i + frame_size]\n            energy = sum(s * s for s in frame) / frame_size\n            energies.append(energy)\n\n        if len(energies) < 10:\n            return 0.0\n\n        mean_energy = sum(energies) / len(energies)\n        energy_variance = sum((e - mean_energy) ** 2 for e in energies) / len(energies)\n\n        # Low variance suggests playback (threshold is empirical)\n        energy_score = 1.0 if energy_variance < 0.0001 else 0.0\n\n        # Check for clipping (common in recordings)\n        clipped_count = sum(1 for s in samples if abs(s) > 0.99)\n        clip_ratio = clipped_count / len(samples)\n        clip_score = min(1.0, clip_ratio * 10)\n\n        # Combined score\n        return energy_score * 0.5 + clip_score * 0.5\n\n    def _compute_checksum(self, mfcc: List[float], pitch: float, energy: float) -> str:\n        \"\"\"Compute checksum for voice print integrity.\"\"\"\n        data = json.dumps(\n            {\"mfcc\": mfcc, \"pitch\": pitch, \"energy\": energy},\n            separators=(\",\", \":\"),\n            sort_keys=True,\n        )\n        return hashlib.sha256(data.encode()).hexdigest()[:16]\n\n    def _compute_list_mean(self, list_of_lists: List[List[float]]) -> List[float]:\n        \"\"\"Compute element-wise mean of list of lists.\"\"\"\n        if not list_of_lists:\n            return []\n        n = len(list_of_lists)\n        length = len(list_of_lists[0])\n        return [sum(lst[i] for lst in list_of_lists) / n for i in range(length)]\n\n    def _compute_list_std(self, list_of_lists: List[List[float]]) -> List[float]:\n        \"\"\"Compute element-wise std of list of lists.\"\"\"\n        if not list_of_lists:\n            return []\n        means = self._compute_list_mean(list_of_lists)\n        n = len(list_of_lists)\n        length = len(list_of_lists[0])\n        return [math.sqrt(sum((lst[i] - means[i]) ** 2 for lst in list_of_lists) / n) for i in range(length)]\n\n    def _std(self, values: List[float]) -> float:\n        \"\"\"Compute standard deviation.\"\"\"\n        if not values:\n            return 0.0\n        mean = sum(values) / len(values)\n        variance = sum((v - mean) ** 2 for v in values) / len(values)\n        return math.sqrt(variance)\n\n\n# Global service instance\nvoice_auth_service = VoiceAuthenticationService()\n"
}
