{
  "path": "services/api-gateway/app/api/advanced_search.py",
  "language": "python",
  "size": 17946,
  "last_modified": "2025-12-04T11:26:46.662Z",
  "lines": 568,
  "content": "\"\"\"\nAdvanced Search API Endpoints (Phase 5 - Advanced RAG)\n\nProvides API endpoints for advanced search features:\n- Hybrid search (BM25 + Vector)\n- Re-ranking\n- Query expansion\n- Search analytics\n\"\"\"\n\nfrom __future__ import annotations\n\nimport logging\nfrom typing import Any, Dict, List, Optional\n\nfrom app.core.api_envelope import ErrorCodes, error_response, success_response\nfrom app.core.dependencies import get_current_user\nfrom app.services.advanced_search import AdvancedSearchResult, SearchMetrics, SearchMode, get_advanced_search\nfrom app.services.query_expansion import ExpansionMethod, QueryExpansionService\nfrom app.services.reranking_service import RerankerType\nfrom fastapi import APIRouter, Depends, Query\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter(prefix=\"/api/search\", tags=[\"search\"])\n\n\n# ===================================\n# Request/Response Models\n# ===================================\n\n\nclass SearchRequest(BaseModel):\n    \"\"\"Advanced search request.\"\"\"\n\n    query: str = Field(..., description=\"Search query\", min_length=1, max_length=1000)\n    top_k: int = Field(10, ge=1, le=50, description=\"Number of results\")\n    mode: Optional[str] = Field(None, description=\"Search mode: fast, balanced, precise, comprehensive\")\n    filters: Optional[Dict[str, Any]] = Field(None, description=\"Metadata filters (e.g., source_type, date_range)\")\n    include_metrics: bool = Field(False, description=\"Include search metrics in response\")\n\n\nclass MultiQuerySearchRequest(BaseModel):\n    \"\"\"Multi-query search request.\"\"\"\n\n    queries: List[str] = Field(..., description=\"List of queries to search\", min_items=1, max_items=5)\n    top_k_per_query: int = Field(3, ge=1, le=10, description=\"Results per query\")\n    deduplicate: bool = Field(True, description=\"Remove duplicate results\")\n\n\nclass QueryExpansionRequest(BaseModel):\n    \"\"\"Query expansion request.\"\"\"\n\n    query: str = Field(..., description=\"Query to expand\")\n    methods: Optional[List[str]] = Field(\n        None, description=\"Expansion methods: abbreviation, synonym, llm_reformulation\"\n    )\n\n\nclass RerankerRequest(BaseModel):\n    \"\"\"Re-ranking request.\"\"\"\n\n    query: str = Field(..., description=\"Original query\")\n    documents: List[str] = Field(..., description=\"Documents to re-rank\", min_items=1, max_items=100)\n    top_n: int = Field(10, ge=1, le=50, description=\"Number of results after re-ranking\")\n    reranker: Optional[str] = Field(None, description=\"Reranker type: cohere, openai, cross_encoder\")\n\n\nclass SearchResultResponse(BaseModel):\n    \"\"\"Search result in API response.\"\"\"\n\n    chunk_id: str\n    document_id: str\n    content: str\n    score: float\n    title: Optional[str] = None\n    source_type: Optional[str] = None\n    url: Optional[str] = None\n    source_tag: Optional[str] = None\n    metadata: Dict[str, Any] = {}\n\n\nclass SearchMetricsResponse(BaseModel):\n    \"\"\"Search metrics in API response.\"\"\"\n\n    total_time_ms: float\n    embedding_time_ms: float\n    search_time_ms: float\n    rerank_time_ms: float\n    expansion_time_ms: float\n    results_found: int\n    results_after_rerank: int\n    query_expanded: bool\n    reranking_applied: bool\n\n\n# ===================================\n# Helper Functions\n# ===================================\n\n\ndef result_to_response(result: AdvancedSearchResult) -> Dict[str, Any]:\n    \"\"\"Convert internal result to API response format.\"\"\"\n    source_tag = (result.source_type or result.metadata.get(\"source_type\") or \"unknown\").upper()\n    return {\n        \"chunk_id\": result.chunk_id,\n        \"document_id\": result.document_id,\n        \"content\": result.content,\n        \"score\": result.score,\n        \"title\": result.title,\n        \"source_type\": result.source_type,\n        \"url\": result.url,\n        \"source_tag\": source_tag,\n        \"metadata\": result.metadata,\n        \"search_method\": result.search_method,\n    }\n\n\ndef metrics_to_response(metrics: SearchMetrics) -> Dict[str, Any]:\n    \"\"\"Convert internal metrics to API response format.\"\"\"\n    return {\n        \"total_time_ms\": round(metrics.total_time_ms, 2),\n        \"embedding_time_ms\": round(metrics.embedding_time_ms, 2),\n        \"search_time_ms\": round(metrics.search_time_ms, 2),\n        \"rerank_time_ms\": round(metrics.rerank_time_ms, 2),\n        \"expansion_time_ms\": round(metrics.expansion_time_ms, 2),\n        \"results_found\": metrics.results_found,\n        \"results_after_rerank\": metrics.results_after_rerank,\n        \"query_expanded\": metrics.query_expanded,\n        \"reranking_applied\": metrics.reranking_applied,\n    }\n\n\n# ===================================\n# Search Endpoints\n# ===================================\n\n\n@router.post(\"/advanced\")\nasync def advanced_search(\n    request: SearchRequest,\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Perform advanced search with hybrid retrieval and optional re-ranking.\n\n    Search modes:\n    - fast: Quick vector search only\n    - balanced: Hybrid search (BM25 + vector) with query expansion\n    - precise: Adds re-ranking for higher precision\n    - comprehensive: Maximum recall with diversity filtering\n    \"\"\"\n    try:\n        search = get_advanced_search()\n\n        # Parse search mode\n        mode = SearchMode.BALANCED\n        if request.mode:\n            try:\n                mode = SearchMode(request.mode.lower())\n            except ValueError:\n                return error_response(\n                    code=ErrorCodes.VALIDATION_ERROR,\n                    message=f\"Invalid search mode: {request.mode}. \"\n                    f\"Valid modes: fast, balanced, precise, comprehensive\",\n                )\n\n        # Perform search\n        results, metrics = await search.search(\n            query=request.query,\n            top_k=request.top_k,\n            mode=mode,\n            filters=request.filters,\n        )\n\n        response_data = {\n            \"query\": request.query,\n            \"mode\": mode.value,\n            \"results\": [result_to_response(r) for r in results],\n            \"total_results\": len(results),\n        }\n\n        if request.filters:\n            response_data[\"applied_filters\"] = request.filters\n\n        if request.include_metrics:\n            response_data[\"metrics\"] = metrics_to_response(metrics)\n\n        return success_response(data=response_data)\n\n    except Exception as e:\n        logger.error(f\"Advanced search error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Search failed\",\n        )\n\n\n@router.get(\"/\")\nasync def simple_search(\n    q: str = Query(..., description=\"Search query\", min_length=1),\n    top_k: int = Query(10, ge=1, le=50, description=\"Number of results\"),\n    source_types: Optional[List[str]] = Query(\n        None,\n        description=\"Optional source_type filters (e.g., pubmed, guideline)\",\n    ),\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Simple search endpoint (GET).\n\n    Uses balanced mode by default.\n    \"\"\"\n    try:\n        search = get_advanced_search()\n\n        filters = {\"source_type\": source_types} if source_types else None\n\n        results, metrics = await search.search(\n            query=q,\n            top_k=top_k,\n            mode=SearchMode.BALANCED,\n            filters=filters,\n        )\n\n        return success_response(\n            data={\n                \"query\": q,\n                \"results\": [result_to_response(r) for r in results],\n                \"total_results\": len(results),\n                \"time_ms\": round(metrics.total_time_ms, 2),\n                \"applied_filters\": filters or {},\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"Simple search error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Search failed\",\n        )\n\n\n@router.post(\"/multi\")\nasync def multi_query_search(\n    request: MultiQuerySearchRequest,\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Search with multiple queries and merge results.\n\n    Useful for:\n    - Searching different aspects of a topic\n    - Fallback queries\n    - Query decomposition results\n    \"\"\"\n    try:\n        search = get_advanced_search()\n\n        results = await search.multi_query_search(\n            queries=request.queries,\n            top_k_per_query=request.top_k_per_query,\n            deduplicate=request.deduplicate,\n        )\n\n        return success_response(\n            data={\n                \"queries\": request.queries,\n                \"results\": [result_to_response(r) for r in results],\n                \"total_results\": len(results),\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"Multi-query search error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Multi-query search failed\",\n        )\n\n\n# ===================================\n# Query Expansion Endpoints\n# ===================================\n\n\n@router.post(\"/expand\")\nasync def expand_query(\n    request: QueryExpansionRequest,\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Expand a query with related terms.\n\n    Expansion methods:\n    - abbreviation: Expand medical abbreviations\n    - synonym: Add medical synonyms\n    - llm_reformulation: Use LLM to suggest alternatives\n    \"\"\"\n    try:\n        expander = QueryExpansionService()\n\n        # Parse expansion methods\n        methods = None\n        if request.methods:\n            methods = []\n            for m in request.methods:\n                try:\n                    methods.append(ExpansionMethod(m.lower()))\n                except ValueError:\n                    return error_response(\n                        code=ErrorCodes.VALIDATION_ERROR,\n                        message=f\"Invalid expansion method: {m}\",\n                    )\n\n        result = await expander.expand(request.query, methods=methods)\n\n        return success_response(\n            data={\n                \"original_query\": result.original_query,\n                \"expanded_query\": result.expanded_query,\n                \"expansion_terms\": result.expansion_terms,\n                \"method\": result.method,\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"Query expansion error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Query expansion failed\",\n        )\n\n\n@router.post(\"/decompose\")\nasync def decompose_query(\n    query: str = Query(..., description=\"Complex query to decompose\"),\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Decompose a complex query into simpler sub-queries.\n\n    Useful for multi-aspect questions like:\n    \"What are the symptoms, causes, and treatment of diabetes?\"\n    \"\"\"\n    try:\n        expander = QueryExpansionService()\n        sub_queries = await expander.decompose(query)\n\n        return success_response(\n            data={\n                \"original_query\": query,\n                \"sub_queries\": sub_queries,\n                \"count\": len(sub_queries),\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"Query decomposition error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Query decomposition failed\",\n        )\n\n\n# ===================================\n# Re-ranking Endpoints\n# ===================================\n\n\n@router.post(\"/rerank\")\nasync def rerank_documents(\n    request: RerankerRequest,\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Re-rank a list of documents by relevance to a query.\n\n    Available rerankers:\n    - cohere: Cohere Rerank API (high quality)\n    - openai: OpenAI embedding similarity\n    - cross_encoder: Local cross-encoder model\n    \"\"\"\n    try:\n        from app.services.reranking_service import RerankerConfig, RerankingService\n\n        # Parse reranker type\n        reranker_type = RerankerType.COHERE\n        if request.reranker:\n            try:\n                reranker_type = RerankerType(request.reranker.lower())\n            except ValueError:\n                return error_response(\n                    code=ErrorCodes.VALIDATION_ERROR,\n                    message=f\"Invalid reranker: {request.reranker}\",\n                )\n\n        reranker = RerankingService(\n            config=RerankerConfig(\n                reranker_type=reranker_type,\n                top_n=request.top_n,\n            )\n        )\n\n        # Convert documents to expected format\n        results_dicts = [{\"content\": doc, \"chunk_id\": str(i), \"score\": 1.0} for i, doc in enumerate(request.documents)]\n\n        reranked = await reranker.rerank(\n            query=request.query,\n            results=results_dicts,\n        )\n\n        return success_response(\n            data={\n                \"query\": request.query,\n                \"reranker\": reranker_type.value,\n                \"results\": [\n                    {\n                        \"index\": int(r.chunk_id),\n                        \"content\": (r.content[:200] + \"...\" if len(r.content) > 200 else r.content),\n                        \"score\": round(r.final_score, 4),\n                        \"rerank_score\": round(r.rerank_score, 4),\n                    }\n                    for r in reranked\n                ],\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"Re-ranking error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Re-ranking failed\",\n        )\n\n\n# ===================================\n# RAG Context Endpoints\n# ===================================\n\n\n@router.post(\"/context\")\nasync def get_rag_context(\n    query: str = Query(..., description=\"Query for context retrieval\"),\n    top_k: int = Query(5, ge=1, le=20, description=\"Number of context chunks\"),\n    max_tokens: int = Query(4000, ge=500, le=8000, description=\"Max context tokens\"),\n    current_user: dict = Depends(get_current_user),\n):\n    \"\"\"\n    Get formatted RAG context for a query.\n\n    Returns search results formatted for LLM consumption\n    with source citations.\n    \"\"\"\n    try:\n        search = get_advanced_search()\n\n        results, metrics = await search.search(\n            query=query,\n            top_k=top_k,\n            mode=SearchMode.PRECISE,\n        )\n\n        formatted_context = search.format_context_for_rag(results, max_tokens=max_tokens)\n\n        return success_response(\n            data={\n                \"query\": query,\n                \"context\": formatted_context,\n                \"sources\": [\n                    {\n                        \"title\": r.title,\n                        \"source_type\": r.source_type,\n                        \"score\": round(r.score, 3),\n                    }\n                    for r in results\n                ],\n                \"num_sources\": len(results),\n                \"time_ms\": round(metrics.total_time_ms, 2),\n            }\n        )\n\n    except Exception as e:\n        logger.error(f\"RAG context error: {e}\", exc_info=True)\n        return error_response(\n            code=ErrorCodes.INTERNAL_ERROR,\n            message=\"Failed to get RAG context\",\n        )\n\n\n# ===================================\n# Search Analytics Endpoints\n# ===================================\n\n\n@router.get(\"/modes\")\nasync def list_search_modes():\n    \"\"\"List available search modes and their descriptions.\"\"\"\n    return success_response(\n        data={\n            \"modes\": [\n                {\n                    \"name\": \"fast\",\n                    \"description\": \"Quick vector search only. Best for simple queries.\",\n                    \"features\": [\"vector_search\"],\n                },\n                {\n                    \"name\": \"balanced\",\n                    \"description\": \"Hybrid search with query expansion. Good balance of speed and quality.\",\n                    \"features\": [\"vector_search\", \"bm25_search\", \"query_expansion\"],\n                },\n                {\n                    \"name\": \"precise\",\n                    \"description\": \"Adds re-ranking for higher precision. Best for important queries.\",\n                    \"features\": [\n                        \"vector_search\",\n                        \"bm25_search\",\n                        \"query_expansion\",\n                        \"reranking\",\n                    ],\n                },\n                {\n                    \"name\": \"comprehensive\",\n                    \"description\": \"Maximum recall with diversity filtering. Best for research queries.\",\n                    \"features\": [\n                        \"vector_search\",\n                        \"bm25_search\",\n                        \"query_expansion\",\n                        \"reranking\",\n                        \"diversity\",\n                    ],\n                },\n            ]\n        }\n    )\n\n\n@router.get(\"/rerankers\")\nasync def list_rerankers():\n    \"\"\"List available re-rankers and their descriptions.\"\"\"\n    return success_response(\n        data={\n            \"rerankers\": [\n                {\n                    \"name\": \"cohere\",\n                    \"description\": \"Cohere Rerank API. High quality, requires API key.\",\n                    \"requires_api_key\": True,\n                },\n                {\n                    \"name\": \"openai\",\n                    \"description\": \"OpenAI embedding similarity. Uses existing API.\",\n                    \"requires_api_key\": True,\n                },\n                {\n                    \"name\": \"cross_encoder\",\n                    \"description\": \"Local cross-encoder model. No API needed, requires GPU for speed.\",\n                    \"requires_api_key\": False,\n                },\n                {\n                    \"name\": \"llm_based\",\n                    \"description\": \"LLM-based scoring. Most expensive but can reason.\",\n                    \"requires_api_key\": True,\n                },\n            ]\n        }\n    )\n"
}
