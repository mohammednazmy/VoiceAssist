{
  "path": "services/api-gateway/app/services/audio_processor.py",
  "language": "python",
  "size": 16894,
  "last_modified": "2025-12-04T11:26:55.484Z",
  "lines": 498,
  "content": "\"\"\"\nAudio Processing Service\n\nProvides audio enhancement features for voice sessions:\n- Echo cancellation\n- Noise suppression\n- Audio normalization\n- Gain control\n\nUses DSP algorithms for real-time audio processing without external dependencies.\n\"\"\"\n\nimport struct\nfrom collections import deque\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Deque, List, Optional\n\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass AudioFormat(Enum):\n    \"\"\"Supported audio formats\"\"\"\n\n    PCM_16 = \"pcm16\"  # 16-bit PCM (default for WebRTC)\n    PCM_32 = \"pcm32\"  # 32-bit PCM\n    FLOAT_32 = \"float32\"  # 32-bit float\n\n\n@dataclass\nclass AudioProcessorConfig:\n    \"\"\"Configuration for audio processing\"\"\"\n\n    # Sample rate in Hz\n    sample_rate: int = 16000\n\n    # Number of channels (1 = mono, 2 = stereo)\n    channels: int = 1\n\n    # Audio format\n    format: AudioFormat = AudioFormat.PCM_16\n\n    # Echo cancellation settings\n    echo_enabled: bool = True\n    echo_filter_length: int = 256  # NLMS filter length in samples\n    echo_step_size: float = 0.1  # NLMS adaptation step size\n    echo_delay_samples: int = 160  # Expected echo delay (10ms at 16kHz)\n\n    # Noise suppression settings\n    noise_enabled: bool = True\n    noise_threshold: float = 0.02  # Noise floor threshold (0-1)\n    noise_reduction_db: float = 12.0  # Noise reduction in dB\n    noise_smoothing: float = 0.95  # Smoothing factor for noise estimation\n\n    # Automatic gain control settings\n    agc_enabled: bool = True\n    agc_target_level: float = 0.5  # Target RMS level (0-1)\n    agc_max_gain_db: float = 20.0  # Maximum gain in dB\n    agc_attack_time: float = 0.01  # Attack time in seconds\n    agc_release_time: float = 0.1  # Release time in seconds\n\n    # High-pass filter settings (removes DC offset and low-frequency noise)\n    highpass_enabled: bool = True\n    highpass_cutoff_hz: float = 80.0  # Cutoff frequency in Hz\n\n\n@dataclass\nclass ProcessingState:\n    \"\"\"Internal state for audio processing\"\"\"\n\n    # Echo cancellation state\n    echo_filter: List[float] = field(default_factory=list)\n    echo_buffer: Deque[float] = field(default_factory=deque)\n\n    # Noise estimation state\n    noise_estimate: float = 0.0\n    noise_power_history: Deque[float] = field(default_factory=deque)\n\n    # AGC state\n    current_gain: float = 1.0\n    rms_history: Deque[float] = field(default_factory=deque)\n\n    # High-pass filter state\n    highpass_z1: float = 0.0\n    highpass_z2: float = 0.0\n\n    # Statistics\n    frames_processed: int = 0\n    total_samples_processed: int = 0\n\n\nclass AudioProcessor:\n    \"\"\"\n    Real-time audio processor with echo cancellation, noise suppression,\n    and automatic gain control.\n\n    This implementation uses lightweight DSP algorithms suitable for\n    real-time processing on typical hardware.\n    \"\"\"\n\n    def __init__(self, config: Optional[AudioProcessorConfig] = None):\n        self.config = config or AudioProcessorConfig()\n        self.state = ProcessingState()\n        self._init_filters()\n\n        logger.debug(\n            \"AudioProcessor initialized\",\n            extra={\n                \"sample_rate\": self.config.sample_rate,\n                \"echo_enabled\": self.config.echo_enabled,\n                \"noise_enabled\": self.config.noise_enabled,\n                \"agc_enabled\": self.config.agc_enabled,\n            },\n        )\n\n    def _init_filters(self) -> None:\n        \"\"\"Initialize filter coefficients and state\"\"\"\n        # Initialize echo cancellation filter (NLMS adaptive filter)\n        self.state.echo_filter = [0.0] * self.config.echo_filter_length\n        self.state.echo_buffer = deque(\n            [0.0] * (self.config.echo_filter_length + self.config.echo_delay_samples),\n            maxlen=self.config.echo_filter_length + self.config.echo_delay_samples,\n        )\n\n        # Initialize noise estimation buffer\n        self.state.noise_power_history = deque(maxlen=50)\n\n        # Initialize AGC history buffer\n        self.state.rms_history = deque(maxlen=20)\n\n        # Calculate high-pass filter coefficients (2nd order Butterworth)\n        if self.config.highpass_enabled:\n            self._calc_highpass_coeffs()\n\n    def _calc_highpass_coeffs(self) -> None:\n        \"\"\"Calculate high-pass filter coefficients\"\"\"\n        import math\n\n        fc = self.config.highpass_cutoff_hz / self.config.sample_rate\n        w0 = 2 * math.pi * fc\n        alpha = math.sin(w0) / (2 * 0.707)  # Q = 0.707 for Butterworth\n\n        b0 = (1 + math.cos(w0)) / 2\n        b1 = -(1 + math.cos(w0))\n        b2 = (1 + math.cos(w0)) / 2\n        a0 = 1 + alpha\n        a1 = -2 * math.cos(w0)\n        a2 = 1 - alpha\n\n        # Normalize coefficients\n        self._hp_b = [b0 / a0, b1 / a0, b2 / a0]\n        self._hp_a = [1.0, a1 / a0, a2 / a0]\n\n    def reset(self) -> None:\n        \"\"\"Reset processing state for new session\"\"\"\n        self.state = ProcessingState()\n        self._init_filters()\n        logger.debug(\"AudioProcessor state reset\")\n\n    def process_frame(\n        self,\n        input_audio: bytes,\n        reference_audio: Optional[bytes] = None,\n    ) -> bytes:\n        \"\"\"\n        Process a single audio frame.\n\n        Args:\n            input_audio: Microphone input audio (PCM16)\n            reference_audio: Speaker output audio for echo cancellation (PCM16)\n\n        Returns:\n            Processed audio frame (PCM16)\n        \"\"\"\n        self.state.frames_processed += 1\n\n        # Convert bytes to samples\n        samples = self._bytes_to_samples(input_audio)\n        self.state.total_samples_processed += len(samples)\n\n        # Apply high-pass filter to remove DC offset\n        if self.config.highpass_enabled:\n            samples = self._apply_highpass(samples)\n\n        # Apply echo cancellation if reference audio is provided\n        if self.config.echo_enabled and reference_audio:\n            reference_samples = self._bytes_to_samples(reference_audio)\n            samples = self._apply_echo_cancellation(samples, reference_samples)\n\n        # Apply noise suppression\n        if self.config.noise_enabled:\n            samples = self._apply_noise_suppression(samples)\n\n        # Apply automatic gain control\n        if self.config.agc_enabled:\n            samples = self._apply_agc(samples)\n\n        # Convert samples back to bytes\n        return self._samples_to_bytes(samples)\n\n    def _bytes_to_samples(self, audio_bytes: bytes) -> List[float]:\n        \"\"\"Convert PCM16 bytes to normalized float samples (-1.0 to 1.0)\"\"\"\n        n_samples = len(audio_bytes) // 2\n        samples = struct.unpack(f\"<{n_samples}h\", audio_bytes)\n        return [s / 32768.0 for s in samples]\n\n    def _samples_to_bytes(self, samples: List[float]) -> bytes:\n        \"\"\"Convert normalized float samples to PCM16 bytes\"\"\"\n        # Clip to valid range\n        clipped = [max(-1.0, min(1.0, s)) for s in samples]\n        # Convert to 16-bit integers\n        int_samples = [int(s * 32767) for s in clipped]\n        return struct.pack(f\"<{len(int_samples)}h\", *int_samples)\n\n    def _apply_highpass(self, samples: List[float]) -> List[float]:\n        \"\"\"Apply high-pass filter to remove DC offset and low frequencies\"\"\"\n        output = []\n        z1, z2 = self.state.highpass_z1, self.state.highpass_z2\n\n        for sample in samples:\n            # Direct Form II transposed\n            y = self._hp_b[0] * sample + z1\n            z1 = self._hp_b[1] * sample - self._hp_a[1] * y + z2\n            z2 = self._hp_b[2] * sample - self._hp_a[2] * y\n            output.append(y)\n\n        self.state.highpass_z1 = z1\n        self.state.highpass_z2 = z2\n        return output\n\n    def _apply_echo_cancellation(self, input_samples: List[float], reference_samples: List[float]) -> List[float]:\n        \"\"\"\n        Apply NLMS (Normalized Least Mean Squares) echo cancellation.\n\n        This removes the acoustic echo of the speaker output from the\n        microphone input.\n        \"\"\"\n        output = []\n\n        for i, (inp, ref) in enumerate(zip(input_samples, reference_samples)):\n            # Add reference sample to buffer (with delay)\n            self.state.echo_buffer.append(ref)\n\n            # Get reference buffer as list for filter convolution\n            ref_buffer = list(self.state.echo_buffer)[-self.config.echo_filter_length :]\n\n            # Compute estimated echo (convolution with filter)\n            estimated_echo = sum(f * r for f, r in zip(self.state.echo_filter, ref_buffer))\n\n            # Error signal (echo-cancelled output)\n            error = inp - estimated_echo\n            output.append(error)\n\n            # Compute normalization factor to prevent divergence\n            ref_power = sum(r * r for r in ref_buffer) + 1e-8\n\n            # Update filter coefficients (NLMS adaptation)\n            step = self.config.echo_step_size / ref_power\n            for j in range(len(self.state.echo_filter)):\n                self.state.echo_filter[j] += step * error * ref_buffer[j]\n\n        return output\n\n    def _apply_noise_suppression(self, samples: List[float]) -> List[float]:\n        \"\"\"\n        Apply spectral subtraction-based noise suppression.\n\n        Uses a simple time-domain approach suitable for real-time processing.\n        \"\"\"\n        # Calculate frame power\n        frame_power = sum(s * s for s in samples) / len(samples) if samples else 0.0\n        self.state.noise_power_history.append(frame_power)\n\n        # Estimate noise floor (minimum power over recent history)\n        if len(self.state.noise_power_history) > 0:\n            min_power = min(self.state.noise_power_history)\n            # Smooth the noise estimate\n            self.state.noise_estimate = (\n                self.config.noise_smoothing * self.state.noise_estimate + (1 - self.config.noise_smoothing) * min_power\n            )\n\n        # Calculate noise reduction gain\n        # If signal power is close to noise floor, reduce gain\n        if frame_power > 0:\n            snr = (frame_power - self.state.noise_estimate) / (frame_power + 1e-10)\n            snr = max(0.0, min(1.0, snr))\n\n            # Apply soft knee compression for smooth transition\n            noise_db = self.config.noise_reduction_db\n            gain = snr + (1 - snr) * (10 ** (-noise_db / 20))\n        else:\n            gain = 1.0\n\n        # Apply gain to samples\n        return [s * gain for s in samples]\n\n    def _apply_agc(self, samples: List[float]) -> List[float]:\n        \"\"\"\n        Apply automatic gain control to normalize audio level.\n\n        Uses a simple envelope follower with attack/release dynamics.\n        \"\"\"\n        if not samples:\n            return samples\n\n        # Calculate RMS level of frame\n        rms = (sum(s * s for s in samples) / len(samples)) ** 0.5\n        self.state.rms_history.append(rms)\n\n        # Get average RMS over recent history\n        avg_rms = sum(self.state.rms_history) / len(self.state.rms_history)\n\n        if avg_rms > 1e-6:  # Avoid division by zero\n            # Calculate desired gain\n            desired_gain = self.config.agc_target_level / avg_rms\n\n            # Limit maximum gain\n            max_gain = 10 ** (self.config.agc_max_gain_db / 20)\n            desired_gain = min(desired_gain, max_gain)\n\n            # Apply attack/release dynamics\n            if desired_gain < self.state.current_gain:\n                # Attack (gain decreasing - fast response to prevent clipping)\n                alpha = 1.0 - (0.5 ** (len(samples) / (self.config.sample_rate * self.config.agc_attack_time)))\n            else:\n                # Release (gain increasing - slow response)\n                alpha = 1.0 - (0.5 ** (len(samples) / (self.config.sample_rate * self.config.agc_release_time)))\n\n            self.state.current_gain = alpha * desired_gain + (1 - alpha) * self.state.current_gain\n\n        # Apply gain\n        return [s * self.state.current_gain for s in samples]\n\n    def get_stats(self) -> dict:\n        \"\"\"Get processing statistics\"\"\"\n        return {\n            \"frames_processed\": self.state.frames_processed,\n            \"total_samples_processed\": self.state.total_samples_processed,\n            \"current_gain_db\": (\n                20 * (self.state.current_gain + 1e-10).__log10__() if hasattr(float, \"__log10__\") else 0\n            ),\n            \"noise_estimate\": self.state.noise_estimate,\n            \"echo_filter_energy\": sum(f * f for f in self.state.echo_filter),\n        }\n\n\nclass EchoCanceller:\n    \"\"\"\n    Standalone echo cancellation processor.\n\n    For use when only echo cancellation is needed without full audio processing.\n    \"\"\"\n\n    def __init__(\n        self,\n        sample_rate: int = 16000,\n        filter_length: int = 256,\n        delay_samples: int = 160,\n    ):\n        config = AudioProcessorConfig(\n            sample_rate=sample_rate,\n            echo_enabled=True,\n            echo_filter_length=filter_length,\n            echo_delay_samples=delay_samples,\n            noise_enabled=False,\n            agc_enabled=False,\n            highpass_enabled=True,\n        )\n        self._processor = AudioProcessor(config)\n\n    def process(self, mic_audio: bytes, speaker_audio: bytes) -> bytes:\n        \"\"\"\n        Process microphone audio to remove speaker echo.\n\n        Args:\n            mic_audio: Microphone input (PCM16)\n            speaker_audio: Speaker output playing at same time (PCM16)\n\n        Returns:\n            Echo-cancelled audio (PCM16)\n        \"\"\"\n        return self._processor.process_frame(mic_audio, speaker_audio)\n\n    def reset(self) -> None:\n        \"\"\"Reset echo canceller state\"\"\"\n        self._processor.reset()\n\n\nclass NoiseSuppressor:\n    \"\"\"\n    Standalone noise suppression processor.\n\n    For use when only noise suppression is needed.\n    \"\"\"\n\n    def __init__(\n        self,\n        sample_rate: int = 16000,\n        noise_reduction_db: float = 12.0,\n        threshold: float = 0.02,\n    ):\n        config = AudioProcessorConfig(\n            sample_rate=sample_rate,\n            echo_enabled=False,\n            noise_enabled=True,\n            noise_reduction_db=noise_reduction_db,\n            noise_threshold=threshold,\n            agc_enabled=False,\n            highpass_enabled=True,\n        )\n        self._processor = AudioProcessor(config)\n\n    def process(self, audio: bytes) -> bytes:\n        \"\"\"\n        Process audio to suppress background noise.\n\n        Args:\n            audio: Input audio (PCM16)\n\n        Returns:\n            Noise-suppressed audio (PCM16)\n        \"\"\"\n        return self._processor.process_frame(audio)\n\n    def reset(self) -> None:\n        \"\"\"Reset noise suppressor state\"\"\"\n        self._processor.reset()\n\n\nclass StreamingAudioProcessor:\n    \"\"\"\n    Streaming audio processor for WebSocket voice sessions.\n\n    Provides an async-friendly interface for real-time audio processing\n    with automatic buffering and frame alignment.\n    \"\"\"\n\n    def __init__(self, config: Optional[AudioProcessorConfig] = None):\n        self.processor = AudioProcessor(config)\n        self._input_buffer: bytes = b\"\"\n        self._reference_buffer: bytes = b\"\"\n        self._frame_size = 320  # 20ms at 16kHz (320 samples * 2 bytes)\n\n    async def process_chunk(\n        self,\n        input_chunk: bytes,\n        reference_chunk: Optional[bytes] = None,\n    ) -> bytes:\n        \"\"\"\n        Process an audio chunk asynchronously.\n\n        Handles buffering and frame alignment for streaming audio.\n\n        Args:\n            input_chunk: Microphone input chunk\n            reference_chunk: Speaker reference chunk (for echo cancellation)\n\n        Returns:\n            Processed audio chunk\n        \"\"\"\n        self._input_buffer += input_chunk\n        if reference_chunk:\n            self._reference_buffer += reference_chunk\n\n        output = b\"\"\n\n        # Process complete frames\n        while len(self._input_buffer) >= self._frame_size:\n            input_frame = self._input_buffer[: self._frame_size]\n            self._input_buffer = self._input_buffer[self._frame_size :]\n\n            # Get corresponding reference frame if available\n            reference_frame = None\n            if len(self._reference_buffer) >= self._frame_size:\n                reference_frame = self._reference_buffer[: self._frame_size]\n                self._reference_buffer = self._reference_buffer[self._frame_size :]\n\n            # Process frame\n            processed = self.processor.process_frame(input_frame, reference_frame)\n            output += processed\n\n        return output\n\n    def reset(self) -> None:\n        \"\"\"Reset processor state\"\"\"\n        self.processor.reset()\n        self._input_buffer = b\"\"\n        self._reference_buffer = b\"\"\n\n    def get_stats(self) -> dict:\n        \"\"\"Get processing statistics\"\"\"\n        stats = self.processor.get_stats()\n        stats[\"input_buffer_size\"] = len(self._input_buffer)\n        stats[\"reference_buffer_size\"] = len(self._reference_buffer)\n        return stats\n"
}
