{
  "path": "services/api-gateway/app/services/prosody_analysis_service.py",
  "language": "python",
  "size": 24620,
  "last_modified": "2025-12-04T11:26:59.576Z",
  "lines": 741,
  "content": "\"\"\"\nProsody Analysis Service - Speech Rhythm and Dynamics\n\nAnalyzes speech patterns from Deepgram word-level data to extract:\n- Speech rate (words per minute)\n- Pause patterns (duration and frequency)\n- Emphasis detection (from word confidence)\n- Turn-taking signals\n\nThese features enhance conversational naturalness by:\n1. Adapting response timing to user's speech pace\n2. Detecting when user is thinking vs finished speaking\n3. Identifying emphasis for better understanding\n\nPhase: Voice Mode Intelligence Enhancement - Phase 3\n\"\"\"\n\nimport time\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Dict, List, Optional\n\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\n# ==============================================================================\n# Data Classes and Enums\n# ==============================================================================\n\n\nclass SpeechPace(str, Enum):\n    \"\"\"User's speech pace category.\"\"\"\n\n    SLOW = \"slow\"  # < 120 WPM\n    NORMAL = \"normal\"  # 120-160 WPM\n    FAST = \"fast\"  # > 160 WPM\n\n\nclass PauseType(str, Enum):\n    \"\"\"Classification of pause types in speech.\"\"\"\n\n    BREATH = \"breath\"  # < 200ms - normal breathing pause\n    WORD_BOUNDARY = \"word_boundary\"  # 200-500ms - between phrases\n    THINKING = \"thinking\"  # 500-1500ms - user is formulating thought\n    TURN_YIELD = \"turn_yield\"  # > 1500ms - user may be yielding turn\n\n\nclass TurnTakingState(str, Enum):\n    \"\"\"\n    Phase 5: User's turn-taking intent classification.\n\n    Used for adaptive endpointing - determining when the AI should respond.\n    \"\"\"\n\n    CONTINUING = \"continuing\"  # User is actively speaking, don't interrupt\n    PAUSING = \"pausing\"  # User is thinking, may continue - wait longer\n    YIELDING = \"yielding\"  # User has finished, AI should respond\n    UNCERTAIN = \"uncertain\"  # Not enough data to determine\n\n\n@dataclass\nclass WordTiming:\n    \"\"\"Timing information for a single word.\"\"\"\n\n    word: str\n    start: float  # Start time in seconds\n    end: float  # End time in seconds\n    confidence: float  # Word-level confidence\n\n    @property\n    def duration_ms(self) -> int:\n        \"\"\"Word duration in milliseconds.\"\"\"\n        return int((self.end - self.start) * 1000)\n\n\n@dataclass\nclass PauseInfo:\n    \"\"\"Information about a pause between words.\"\"\"\n\n    start: float  # Pause start time\n    end: float  # Pause end time\n    duration_ms: int  # Duration in milliseconds\n    pause_type: PauseType\n    before_word: str  # Word before pause\n    after_word: str  # Word after pause\n\n\n@dataclass\nclass TurnTakingPrediction:\n    \"\"\"\n    Phase 5: Prediction of user's turn-taking intent.\n\n    Provides confidence-weighted prediction to guide adaptive endpointing.\n    \"\"\"\n\n    state: TurnTakingState = TurnTakingState.UNCERTAIN\n    confidence: float = 0.0  # 0.0 to 1.0\n    recommended_wait_ms: int = 500  # How long to wait before responding\n\n    # Signals that contributed to prediction\n    has_falling_intonation: bool = False  # End-of-sentence signal\n    has_trailing_off: bool = False  # Decreasing confidence/volume\n    is_thinking_aloud: bool = False  # User seems to be processing, not asking\n    has_continuation_cue: bool = False  # \"and\", \"but\", \"so\" at end\n\n    def to_dict(self) -> Dict:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return {\n            \"state\": self.state.value,\n            \"confidence\": round(self.confidence, 2),\n            \"recommended_wait_ms\": self.recommended_wait_ms,\n            \"signals\": {\n                \"falling_intonation\": self.has_falling_intonation,\n                \"trailing_off\": self.has_trailing_off,\n                \"thinking_aloud\": self.is_thinking_aloud,\n                \"continuation_cue\": self.has_continuation_cue,\n            },\n        }\n\n\n@dataclass\nclass ProsodySnapshot:\n    \"\"\"Current prosody state for a speech segment.\"\"\"\n\n    # Speech rate\n    words_per_minute: float = 0.0\n    pace: SpeechPace = SpeechPace.NORMAL\n\n    # Pause analysis\n    pause_count: int = 0\n    avg_pause_ms: float = 0.0\n    max_pause_ms: int = 0\n    thinking_pause_count: int = 0\n\n    # Word analysis\n    word_count: int = 0\n    avg_word_duration_ms: float = 0.0\n    avg_confidence: float = 0.0\n\n    # Turn-taking signals\n    likely_finished: bool = False  # User probably done speaking\n    hesitation_detected: bool = False  # User seems uncertain\n\n    # Phase 5: Advanced turn-taking prediction\n    turn_prediction: Optional[TurnTakingPrediction] = None\n\n    # Timestamps\n    segment_start: float = 0.0\n    segment_end: float = 0.0\n    analysis_time: float = field(default_factory=time.time)\n\n    def to_dict(self) -> Dict:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        result = {\n            \"words_per_minute\": round(self.words_per_minute, 1),\n            \"pace\": self.pace.value,\n            \"pause_count\": self.pause_count,\n            \"avg_pause_ms\": round(self.avg_pause_ms, 1),\n            \"max_pause_ms\": self.max_pause_ms,\n            \"thinking_pause_count\": self.thinking_pause_count,\n            \"word_count\": self.word_count,\n            \"avg_confidence\": round(self.avg_confidence, 2),\n            \"likely_finished\": self.likely_finished,\n            \"hesitation_detected\": self.hesitation_detected,\n        }\n        if self.turn_prediction:\n            result[\"turn_prediction\"] = self.turn_prediction.to_dict()\n        return result\n\n\n@dataclass\nclass UserSpeechProfile:\n    \"\"\"Long-term speech profile for a user.\"\"\"\n\n    user_id: str\n    avg_wpm: float = 140.0  # Default average\n    wpm_std_dev: float = 20.0  # Standard deviation\n    avg_pause_ms: float = 300.0  # Average pause duration\n    typical_thinking_pause_ms: float = 800.0  # When user is thinking\n    samples_count: int = 0\n\n    def update(self, snapshot: ProsodySnapshot) -> None:\n        \"\"\"Update profile with new speech sample.\"\"\"\n        if snapshot.word_count < 5:\n            return  # Need minimum words for reliable stats\n\n        # Exponential moving average\n        alpha = 0.1 if self.samples_count > 10 else 0.3\n\n        self.avg_wpm = (1 - alpha) * self.avg_wpm + alpha * snapshot.words_per_minute\n        if snapshot.avg_pause_ms > 0:\n            self.avg_pause_ms = (1 - alpha) * self.avg_pause_ms + alpha * snapshot.avg_pause_ms\n        if snapshot.max_pause_ms > 500 and snapshot.thinking_pause_count > 0:\n            self.typical_thinking_pause_ms = (\n                1 - alpha\n            ) * self.typical_thinking_pause_ms + alpha * snapshot.max_pause_ms\n\n        self.samples_count += 1\n        logger.debug(\n            f\"Updated speech profile for {self.user_id}: \" f\"WPM={self.avg_wpm:.0f}, pause={self.avg_pause_ms:.0f}ms\"\n        )\n\n\n# ==============================================================================\n# Prosody Analysis Engine\n# ==============================================================================\n\n\nclass ProsodyAnalyzer:\n    \"\"\"\n    Analyzes speech prosody from Deepgram word-level data.\n\n    Usage:\n        analyzer = ProsodyAnalyzer()\n\n        # Feed word data from Deepgram\n        for word_data in deepgram_words:\n            analyzer.add_word(word_data)\n\n        # Get analysis\n        snapshot = analyzer.get_snapshot()\n        print(f\"Speech rate: {snapshot.words_per_minute} WPM\")\n\n        # Reset for next utterance\n        analyzer.reset()\n    \"\"\"\n\n    # Pause classification thresholds (ms)\n    BREATH_PAUSE_MAX = 200\n    WORD_BOUNDARY_MAX = 500\n    THINKING_PAUSE_MAX = 1500\n\n    # Speech rate thresholds (WPM)\n    SLOW_WPM = 120\n    FAST_WPM = 160\n\n    def __init__(self, user_profile: Optional[UserSpeechProfile] = None):\n        self._words: List[WordTiming] = []\n        self._pauses: List[PauseInfo] = []\n        self._user_profile = user_profile\n        self._segment_start: Optional[float] = None\n        self._segment_end: Optional[float] = None\n\n    def add_word(self, word_data: Dict) -> None:\n        \"\"\"\n        Add a word from Deepgram results.\n\n        Args:\n            word_data: Dict with 'word', 'start', 'end', 'confidence'\n        \"\"\"\n        word = WordTiming(\n            word=word_data.get(\"word\", \"\"),\n            start=word_data.get(\"start\", 0.0),\n            end=word_data.get(\"end\", 0.0),\n            confidence=word_data.get(\"confidence\", 0.0),\n        )\n\n        # Track segment boundaries\n        if self._segment_start is None:\n            self._segment_start = word.start\n        self._segment_end = word.end\n\n        # Detect pause before this word\n        if self._words:\n            prev_word = self._words[-1]\n            gap_ms = int((word.start - prev_word.end) * 1000)\n\n            if gap_ms > 50:  # Ignore tiny gaps (< 50ms)\n                pause_type = self._classify_pause(gap_ms)\n                pause = PauseInfo(\n                    start=prev_word.end,\n                    end=word.start,\n                    duration_ms=gap_ms,\n                    pause_type=pause_type,\n                    before_word=prev_word.word,\n                    after_word=word.word,\n                )\n                self._pauses.append(pause)\n\n        self._words.append(word)\n\n    def _classify_pause(self, duration_ms: int) -> PauseType:\n        \"\"\"Classify pause type based on duration.\"\"\"\n        if duration_ms <= self.BREATH_PAUSE_MAX:\n            return PauseType.BREATH\n        elif duration_ms <= self.WORD_BOUNDARY_MAX:\n            return PauseType.WORD_BOUNDARY\n        elif duration_ms <= self.THINKING_PAUSE_MAX:\n            return PauseType.THINKING\n        else:\n            return PauseType.TURN_YIELD\n\n    def get_snapshot(self) -> ProsodySnapshot:\n        \"\"\"Get current prosody analysis snapshot.\"\"\"\n        if not self._words:\n            return ProsodySnapshot()\n\n        # Calculate speech rate\n        duration_sec = (self._segment_end or 0) - (self._segment_start or 0)\n        wpm = (len(self._words) / duration_sec * 60) if duration_sec > 0 else 0\n\n        # Classify pace\n        if wpm < self.SLOW_WPM:\n            pace = SpeechPace.SLOW\n        elif wpm > self.FAST_WPM:\n            pace = SpeechPace.FAST\n        else:\n            pace = SpeechPace.NORMAL\n\n        # Pause analysis\n        pause_durations = [p.duration_ms for p in self._pauses]\n        avg_pause = sum(pause_durations) / len(pause_durations) if pause_durations else 0\n        max_pause = max(pause_durations) if pause_durations else 0\n        thinking_pauses = sum(1 for p in self._pauses if p.pause_type == PauseType.THINKING)\n\n        # Word analysis\n        word_durations = [w.duration_ms for w in self._words]\n        avg_word_duration = sum(word_durations) / len(word_durations) if word_durations else 0\n        avg_confidence = sum(w.confidence for w in self._words) / len(self._words)\n\n        # Turn-taking signals\n        likely_finished = self._detect_turn_yield()\n        hesitation_detected = self._detect_hesitation()\n\n        # Phase 5: Advanced turn-taking prediction\n        turn_prediction = self.predict_turn_taking()\n\n        return ProsodySnapshot(\n            words_per_minute=wpm,\n            pace=pace,\n            pause_count=len(self._pauses),\n            avg_pause_ms=avg_pause,\n            max_pause_ms=max_pause,\n            thinking_pause_count=thinking_pauses,\n            word_count=len(self._words),\n            avg_word_duration_ms=avg_word_duration,\n            avg_confidence=avg_confidence,\n            likely_finished=likely_finished,\n            hesitation_detected=hesitation_detected,\n            turn_prediction=turn_prediction,\n            segment_start=self._segment_start or 0,\n            segment_end=self._segment_end or 0,\n        )\n\n    def _detect_turn_yield(self) -> bool:\n        \"\"\"Detect if user is likely finished speaking.\"\"\"\n        if not self._pauses:\n            return False\n\n        # Check if last pause is long (> 1.5s)\n        last_pause = self._pauses[-1]\n        if last_pause.pause_type == PauseType.TURN_YIELD:\n            return True\n\n        # Check for falling confidence at end (trailing off)\n        if len(self._words) >= 3:\n            last_three = self._words[-3:]\n            if all(w.confidence < 0.8 for w in last_three):\n                return True\n\n        return False\n\n    def _detect_hesitation(self) -> bool:\n        \"\"\"Detect if user seems hesitant or uncertain.\"\"\"\n        if len(self._words) < 3:\n            return False\n\n        # Multiple thinking pauses in short utterance\n        if self._pauses:\n            thinking_ratio = sum(1 for p in self._pauses if p.pause_type == PauseType.THINKING) / len(self._pauses)\n            if thinking_ratio > 0.3:\n                return True\n\n        # Low average confidence\n        avg_confidence = sum(w.confidence for w in self._words) / len(self._words)\n        if avg_confidence < 0.7:\n            return True\n\n        return False\n\n    # Phase 5: Continuation cue words that suggest user will continue\n    CONTINUATION_CUES = {\n        \"and\",\n        \"but\",\n        \"so\",\n        \"because\",\n        \"however\",\n        \"although\",\n        \"if\",\n        \"when\",\n        \"or\",\n        \"also\",\n        \"then\",\n        \"well\",\n        \"like\",\n        \"um\",\n        \"uh\",\n        \"hmm\",\n    }\n\n    # Thinking aloud indicators\n    THINKING_ALOUD_CUES = {\n        \"let me think\",\n        \"i wonder\",\n        \"maybe\",\n        \"perhaps\",\n        \"i guess\",\n        \"i think\",\n        \"hmm\",\n        \"um\",\n        \"uh\",\n        \"wait\",\n        \"hold on\",\n    }\n\n    def predict_turn_taking(self) -> TurnTakingPrediction:\n        \"\"\"\n        Phase 5: Predict user's turn-taking intent.\n\n        Analyzes prosodic features to determine if user is:\n        - CONTINUING: Actively speaking, don't interrupt\n        - PAUSING: Thinking, may continue speaking\n        - YIELDING: Finished, AI should respond\n        - UNCERTAIN: Not enough data\n\n        Returns:\n            TurnTakingPrediction with state, confidence, and signals\n        \"\"\"\n        if len(self._words) < 3:\n            return TurnTakingPrediction(\n                state=TurnTakingState.UNCERTAIN,\n                confidence=0.0,\n                recommended_wait_ms=500,\n            )\n\n        signals = {\n            \"falling_intonation\": False,\n            \"trailing_off\": False,\n            \"thinking_aloud\": False,\n            \"continuation_cue\": False,\n        }\n        confidence_factors = []\n\n        # Check for continuation cues at end\n        last_word = self._words[-1].word.lower().strip(\".,!?\")\n        if last_word in self.CONTINUATION_CUES:\n            signals[\"continuation_cue\"] = True\n            confidence_factors.append((\"continuation_cue\", 0.8))\n\n        # Check for \"thinking aloud\" patterns\n        recent_text = \" \".join(w.word.lower() for w in self._words[-5:])\n        for cue in self.THINKING_ALOUD_CUES:\n            if cue in recent_text:\n                signals[\"thinking_aloud\"] = True\n                confidence_factors.append((\"thinking_aloud\", 0.7))\n                break\n\n        # Check for trailing off (decreasing confidence)\n        if len(self._words) >= 3:\n            last_three = self._words[-3:]\n            confidences = [w.confidence for w in last_three]\n            if confidences[0] > confidences[1] > confidences[2] and confidences[2] < 0.7:\n                signals[\"trailing_off\"] = True\n                confidence_factors.append((\"trailing_off\", 0.6))\n\n        # Check for falling intonation (approximated by final word confidence)\n        if self._words[-1].confidence > 0.85:\n            signals[\"falling_intonation\"] = True\n            confidence_factors.append((\"falling_intonation\", 0.5))\n\n        # Check pause patterns\n        has_long_pause = any(p.pause_type == PauseType.TURN_YIELD for p in self._pauses)\n        has_thinking_pause = (\n            any(p.pause_type == PauseType.THINKING for p in self._pauses[-2:]) if self._pauses else False\n        )\n\n        # Determine state based on signals\n        if signals[\"continuation_cue\"]:\n            state = TurnTakingState.CONTINUING\n            base_confidence = 0.8\n            wait_ms = 1500  # Wait longer, user likely to continue\n        elif signals[\"thinking_aloud\"]:\n            state = TurnTakingState.PAUSING\n            base_confidence = 0.7\n            wait_ms = 2000  # User is processing, give them time\n        elif has_long_pause:\n            state = TurnTakingState.YIELDING\n            base_confidence = 0.85\n            wait_ms = 200  # User has paused long, likely done\n        elif signals[\"trailing_off\"] and not has_thinking_pause:\n            state = TurnTakingState.YIELDING\n            base_confidence = 0.6\n            wait_ms = 400\n        elif has_thinking_pause:\n            state = TurnTakingState.PAUSING\n            base_confidence = 0.6\n            wait_ms = 1000  # User is thinking\n        elif signals[\"falling_intonation\"]:\n            state = TurnTakingState.YIELDING\n            base_confidence = 0.5\n            wait_ms = 300\n        else:\n            state = TurnTakingState.UNCERTAIN\n            base_confidence = 0.3\n            wait_ms = 500\n\n        # Adjust confidence based on accumulated signals\n        final_confidence = min(1.0, base_confidence + 0.1 * len(confidence_factors))\n\n        return TurnTakingPrediction(\n            state=state,\n            confidence=final_confidence,\n            recommended_wait_ms=wait_ms,\n            has_falling_intonation=signals[\"falling_intonation\"],\n            has_trailing_off=signals[\"trailing_off\"],\n            is_thinking_aloud=signals[\"thinking_aloud\"],\n            has_continuation_cue=signals[\"continuation_cue\"],\n        )\n\n    def reset(self) -> None:\n        \"\"\"Reset analyzer for new utterance.\"\"\"\n        self._words.clear()\n        self._pauses.clear()\n        self._segment_start = None\n        self._segment_end = None\n\n\n# ==============================================================================\n# Prosody Session Manager\n# ==============================================================================\n\n\nclass ProsodySession:\n    \"\"\"\n    Manages prosody analysis for a voice session.\n\n    Tracks speech patterns over time and provides recommendations\n    for response timing and turn-taking.\n    \"\"\"\n\n    def __init__(\n        self,\n        session_id: str,\n        user_profile: Optional[UserSpeechProfile] = None,\n    ):\n        self.session_id = session_id\n        self._user_profile = user_profile or UserSpeechProfile(user_id=\"default\")\n        self._analyzer = ProsodyAnalyzer(user_profile)\n        self._snapshots: List[ProsodySnapshot] = []\n        self._active = False\n\n    async def start(self) -> None:\n        \"\"\"Start the prosody session.\"\"\"\n        self._active = True\n        logger.info(f\"Prosody session started: {self.session_id}\")\n\n    async def stop(self) -> None:\n        \"\"\"Stop the session and finalize profile.\"\"\"\n        self._active = False\n\n        # Update user profile with session data\n        for snapshot in self._snapshots:\n            self._user_profile.update(snapshot)\n\n        logger.info(\n            f\"Prosody session stopped: {self.session_id}, \"\n            f\"utterances={len(self._snapshots)}, \"\n            f\"profile_wpm={self._user_profile.avg_wpm:.0f}\"\n        )\n\n    def add_words(self, words: List[Dict]) -> None:\n        \"\"\"Add words from Deepgram transcript.\"\"\"\n        if not self._active:\n            return\n\n        for word in words:\n            self._analyzer.add_word(word)\n\n    def finalize_utterance(self) -> ProsodySnapshot:\n        \"\"\"\n        Finalize current utterance and get analysis.\n\n        Call this when speech ends (utterance complete).\n        \"\"\"\n        snapshot = self._analyzer.get_snapshot()\n        if snapshot.word_count > 0:\n            self._snapshots.append(snapshot)\n\n        self._analyzer.reset()\n        return snapshot\n\n    def get_current_analysis(self) -> ProsodySnapshot:\n        \"\"\"Get analysis of current (in-progress) utterance.\"\"\"\n        return self._analyzer.get_snapshot()\n\n    def get_recommended_response_delay_ms(self) -> int:\n        \"\"\"\n        Get recommended delay before starting AI response.\n\n        Phase 5: Uses turn-taking prediction for adaptive timing.\n        Based on user's speech profile, current analysis, and turn-taking signals.\n        \"\"\"\n        current = self._analyzer.get_snapshot()\n\n        # Phase 5: Use turn prediction if available\n        if current.turn_prediction and current.word_count > 3:\n            prediction = current.turn_prediction\n\n            # High confidence prediction - use its recommended wait\n            if prediction.confidence > 0.6:\n                logger.debug(\n                    f\"Using turn prediction: state={prediction.state.value}, \"\n                    f\"conf={prediction.confidence:.2f}, wait={prediction.recommended_wait_ms}ms\"\n                )\n                return prediction.recommended_wait_ms\n\n        # Fallback to pace-based delay\n        base_delay = 200  # Minimum delay (ms)\n\n        # Adjust based on user's typical pace\n        pace_adjustment = {\n            SpeechPace.SLOW: 400,  # Slow speakers appreciate more time\n            SpeechPace.NORMAL: 200,\n            SpeechPace.FAST: 100,  # Fast speakers expect quick responses\n        }\n\n        pace = current.pace if current.word_count > 5 else SpeechPace.NORMAL\n\n        # If hesitation detected, add more delay\n        hesitation_adjustment = 300 if current.hesitation_detected else 0\n\n        return base_delay + pace_adjustment.get(pace, 200) + hesitation_adjustment\n\n    def get_turn_prediction(self) -> TurnTakingPrediction:\n        \"\"\"\n        Phase 5: Get current turn-taking prediction.\n\n        Returns prediction of whether user is continuing, pausing, or yielding turn.\n        \"\"\"\n        return self._analyzer.predict_turn_taking()\n\n    def should_wait_for_continuation(self) -> bool:\n        \"\"\"\n        Phase 5: Check if AI should wait for user to continue.\n\n        Returns True if prediction indicates user is likely to continue speaking.\n        \"\"\"\n        prediction = self.get_turn_prediction()\n        return prediction.state in (TurnTakingState.CONTINUING, TurnTakingState.PAUSING) and prediction.confidence > 0.5\n\n    def should_backchannel(self) -> bool:\n        \"\"\"\n        Check if this is a good moment for a backchannel.\n\n        Based on pause patterns and speech duration.\n        \"\"\"\n        current = self._analyzer.get_snapshot()\n\n        # Need minimum speech before backchanneling\n        if current.word_count < 10:\n            return False\n\n        # Check for thinking pauses\n        if current.thinking_pause_count > 0:\n            return True\n\n        # Long utterance without backchannel\n        if current.word_count > 30:\n            return True\n\n        return False\n\n\n# ==============================================================================\n# Prosody Service\n# ==============================================================================\n\n\nclass ProsodyService:\n    \"\"\"\n    Factory service for creating prosody analysis sessions.\n\n    Manages user profiles and session lifecycle.\n    \"\"\"\n\n    def __init__(self):\n        self._sessions: Dict[str, ProsodySession] = {}\n        self._user_profiles: Dict[str, UserSpeechProfile] = {}\n\n    async def create_session(\n        self,\n        session_id: str,\n        user_id: Optional[str] = None,\n    ) -> ProsodySession:\n        \"\"\"\n        Create a new prosody session.\n\n        Args:\n            session_id: Unique session identifier\n            user_id: Optional user ID for profile loading\n\n        Returns:\n            ProsodySession instance\n        \"\"\"\n        # Get or create user profile\n        profile = None\n        if user_id:\n            if user_id not in self._user_profiles:\n                self._user_profiles[user_id] = UserSpeechProfile(user_id=user_id)\n            profile = self._user_profiles[user_id]\n\n        session = ProsodySession(\n            session_id=session_id,\n            user_profile=profile,\n        )\n\n        self._sessions[session_id] = session\n        await session.start()\n\n        return session\n\n    async def remove_session(self, session_id: str) -> None:\n        \"\"\"Remove and cleanup a session.\"\"\"\n        session = self._sessions.pop(session_id, None)\n        if session:\n            await session.stop()\n\n    def get_session(self, session_id: str) -> Optional[ProsodySession]:\n        \"\"\"Get an active session by ID.\"\"\"\n        return self._sessions.get(session_id)\n\n    def get_user_profile(self, user_id: str) -> Optional[UserSpeechProfile]:\n        \"\"\"Get user's speech profile.\"\"\"\n        return self._user_profiles.get(user_id)\n\n\n# Global service instance\nprosody_service = ProsodyService()\n"
}
