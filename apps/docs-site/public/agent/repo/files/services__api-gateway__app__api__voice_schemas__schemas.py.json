{
  "path": "services/api-gateway/app/api/voice_schemas/schemas.py",
  "language": "python",
  "size": 8182,
  "last_modified": "2025-12-04T11:26:48.778Z",
  "lines": 274,
  "content": "\"\"\"Voice API Pydantic Schemas.\n\nDefines request and response models for voice-related endpoints:\n- Transcription\n- Speech synthesis\n- Realtime sessions\n- Voice metrics\n- VAD profiles\n- Voice authentication\n\"\"\"\n\nfrom pydantic import BaseModel\n\n# =============================================================================\n# Transcription & Synthesis Schemas\n# =============================================================================\n\n\nclass SynthesizeRequest(BaseModel):\n    \"\"\"Request model for speech synthesis\"\"\"\n\n    text: str\n    voiceId: str | None = None\n    # Phase 11: Provider selection (defaults to admin-configured default)\n    provider: str | None = None  # \"openai\" | \"elevenlabs\" | None (use default)\n    # ElevenLabs-specific options\n    model_id: str | None = None  # \"eleven_multilingual_v2\" | \"eleven_turbo_v2\"\n    stability: float | None = None  # 0-1, lower = more expressive\n    similarity_boost: float | None = None  # 0-1\n    style: float | None = None  # 0-1, emotion/style exaggeration\n\n\nclass TranscribeResponse(BaseModel):\n    \"\"\"Response model for audio transcription\"\"\"\n\n    text: str\n\n\n# =============================================================================\n# Realtime Session Schemas\n# =============================================================================\n\n\nclass RealtimeSessionRequest(BaseModel):\n    \"\"\"Request model for Realtime session configuration\"\"\"\n\n    conversation_id: str | None = None\n    # Optional Voice Mode settings from frontend\n    voice: str | None = None  # \"alloy\" | \"echo\" | \"fable\" | \"onyx\" | \"nova\" | \"shimmer\"\n    language: str | None = None  # \"en\" | \"es\" | \"fr\" | \"de\" | \"it\" | \"pt\"\n    vad_sensitivity: int | None = None  # 0-100 (maps to VAD threshold)\n    # Adaptive VAD settings\n    silence_duration_ms: int | None = None  # 200-800ms (default 500, adaptive mode auto-adjusts)\n    adaptive_vad: bool = True  # Enable adaptive VAD based on user speech patterns\n\n\nclass RealtimeAuthInfo(BaseModel):\n    \"\"\"Authentication information for Realtime API\"\"\"\n\n    type: str  # \"ephemeral_token\"\n    token: str  # HMAC-signed ephemeral token (NOT the raw OpenAI key)\n    expires_at: int  # Unix timestamp\n\n\nclass RealtimeSessionResponse(BaseModel):\n    \"\"\"Response model for Realtime session configuration\"\"\"\n\n    url: str\n    model: str\n    session_id: str\n    expires_at: int\n    conversation_id: str | None\n    auth: RealtimeAuthInfo  # Ephemeral token auth (secure, no raw API key)\n    voice_config: dict\n    audio_enhancements: dict | None = None\n\n\n# =============================================================================\n# Voice Relay Schemas\n# =============================================================================\n\n\nclass VoiceRelayRequest(BaseModel):\n    \"\"\"Request model for relaying a final voice transcript into RAG + persistence.\"\"\"\n\n    conversation_id: str\n    transcript: str\n    clinical_context_id: str | None = None\n\n\nclass VoiceRelayResponse(BaseModel):\n    \"\"\"Response model for relayed assistant answer and persisted message IDs.\"\"\"\n\n    user_message_id: str\n    assistant_message_id: str\n    answer: str\n    citations: list[dict] = []\n\n\n# =============================================================================\n# Voice Info Schemas\n# =============================================================================\n\n\nclass VoiceInfo(BaseModel):\n    \"\"\"Voice information for frontend display.\"\"\"\n\n    voice_id: str\n    name: str\n    provider: str  # \"openai\" | \"elevenlabs\"\n    category: str | None = None\n    preview_url: str | None = None\n    description: str | None = None\n    labels: dict | None = None\n\n\nclass VoiceListResponse(BaseModel):\n    \"\"\"Response model for voice listing.\"\"\"\n\n    voices: list[VoiceInfo]\n    default_voice_id: str | None = None\n    default_provider: str\n\n\n# =============================================================================\n# Voice Metrics Schemas\n# =============================================================================\n\n\nclass VoiceMetricsPayload(BaseModel):\n    \"\"\"Request model for voice session metrics (privacy-safe, no transcripts)\"\"\"\n\n    conversation_id: str | None = None\n    connection_time_ms: int | None = None\n    time_to_first_transcript_ms: int | None = None\n    last_stt_latency_ms: int | None = None\n    last_response_latency_ms: int | None = None\n    session_duration_ms: int | None = None\n    user_transcript_count: int = 0\n    ai_response_count: int = 0\n    reconnect_count: int = 0\n    session_started_at: int | None = None\n\n\nclass VoiceMetricsResponse(BaseModel):\n    \"\"\"Response model for voice metrics submission\"\"\"\n\n    status: str\n\n\n# =============================================================================\n# VAD (Voice Activity Detection) Schemas\n# =============================================================================\n\n\nclass VADSessionMetrics(BaseModel):\n    \"\"\"Metrics from a voice session for adaptive VAD learning.\"\"\"\n\n    pause_durations_ms: list[float] = []  # Duration of pauses between utterances\n    utterance_durations_ms: list[float] = []  # Duration of each utterance\n\n\nclass VADProfileResponse(BaseModel):\n    \"\"\"Response with updated VAD profile info.\"\"\"\n\n    status: str\n    optimal_silence_ms: int\n    is_adaptive: bool\n\n\n# =============================================================================\n# Voice Authentication Schemas\n# =============================================================================\n\n\nclass VoiceAuthStartResponse(BaseModel):\n    \"\"\"Response for starting voice enrollment\"\"\"\n\n    status: str\n    message: str\n    min_samples: int\n    max_samples: int\n\n\nclass VoiceAuthSampleResponse(BaseModel):\n    \"\"\"Response for adding enrollment sample\"\"\"\n\n    success: bool\n    message: str\n    samples_collected: int\n    samples_needed: int\n\n\nclass VoiceAuthCompleteResponse(BaseModel):\n    \"\"\"Response for completing enrollment\"\"\"\n\n    success: bool\n    message: str\n\n\nclass VoiceAuthVerifyResponse(BaseModel):\n    \"\"\"Response for voice verification\"\"\"\n\n    verified: bool\n    confidence: float\n    status: str\n    details: dict | None = None\n\n\nclass VoiceAuthStatusResponse(BaseModel):\n    \"\"\"Response for enrollment status\"\"\"\n\n    enrolled: bool\n    status: str\n    sample_count: int | None = None\n    created_at: float | None = None\n\n\n# =============================================================================\n# Voice Preferences Schemas\n# =============================================================================\n\n\nclass VoicePreferencesRequest(BaseModel):\n    \"\"\"Request model for updating voice preferences.\"\"\"\n\n    tts_provider: str | None = None  # \"openai\" | \"elevenlabs\"\n    openai_voice_id: str | None = None  # \"alloy\" | \"echo\" | \"fable\" | \"onyx\" | \"nova\" | \"shimmer\"\n    elevenlabs_voice_id: str | None = None  # Custom ElevenLabs voice ID\n    speech_rate: float | None = None  # 0.5-2.0\n    stability: float | None = None  # 0-1 (ElevenLabs)\n    similarity_boost: float | None = None  # 0-1 (ElevenLabs)\n    style: float | None = None  # 0-1 (ElevenLabs)\n    speaker_boost: bool | None = None  # ElevenLabs clarity enhancement\n    auto_play: bool | None = None  # Auto-play TTS responses\n    context_aware_style: bool | None = None  # Auto-adjust based on content\n    preferred_language: str | None = None  # \"en\", \"ar\", etc.\n\n\nclass VoicePreferencesResponse(BaseModel):\n    \"\"\"Response model for voice preferences.\"\"\"\n\n    id: str\n    user_id: str\n    tts_provider: str\n    openai_voice_id: str\n    elevenlabs_voice_id: str | None\n    speech_rate: float\n    stability: float\n    similarity_boost: float\n    style: float\n    speaker_boost: bool\n    auto_play: bool\n    context_aware_style: bool\n    preferred_language: str\n    created_at: str | None\n    updated_at: str | None\n\n\nclass VoiceStylePresetResponse(BaseModel):\n    \"\"\"Response model for a voice style preset.\"\"\"\n\n    context: str  # \"calm\" | \"urgent\" | \"empathetic\" | \"instructional\" | \"conversational\"\n    stability: float\n    similarity_boost: float\n    style: float\n    speech_rate: float\n\n\nclass VoiceStylePresetsListResponse(BaseModel):\n    \"\"\"Response model for listing all voice style presets.\"\"\"\n\n    presets: dict[str, VoiceStylePresetResponse]\n"
}
