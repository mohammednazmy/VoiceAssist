{
  "path": "services/api-gateway/app/services/log_stream_service.py",
  "language": "python",
  "size": 5074,
  "last_modified": "2025-12-04T11:26:57.075Z",
  "lines": 146,
  "content": "\"\"\"In-memory log streaming broker for WebSocket subscribers.\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nimport logging\nfrom collections import deque\nfrom datetime import datetime, timezone\nfrom typing import Any, Deque, Dict, Optional, Tuple\nfrom uuid import uuid4\n\n\nclass LogStreamBroker:\n    \"\"\"Publishes log records to registered async queues with filtering.\"\"\"\n\n    def __init__(self, buffer_size: int = 500, queue_size: int = 100):\n        self.buffer: Deque[Dict[str, Any]] = deque(maxlen=buffer_size)\n        self.queue_size = queue_size\n        self.listeners: Dict[str, Tuple[asyncio.Queue, Dict[str, Any]]] = {}\n\n    @staticmethod\n    def _matches_filters(entry: Dict[str, Any], filters: Dict[str, Any]) -> bool:\n        service = filters.get(\"service\")\n        level = filters.get(\"level\")\n        since: Optional[datetime] = filters.get(\"since\")\n\n        if service and entry.get(\"service\") != service:\n            return False\n        if level and entry.get(\"level\") != level:\n            return False\n        if since:\n            try:\n                entry_ts = datetime.fromisoformat(entry.get(\"timestamp\").replace(\"Z\", \"+00:00\"))\n                if entry_ts < since:\n                    return False\n            except Exception:\n                # If timestamp parsing fails, allow the entry through to avoid losing logs\n                pass\n        return True\n\n    def publish(self, entry: Dict[str, Any]):\n        \"\"\"Add entry to buffer and fan-out to listeners with backpressure handling.\"\"\"\n\n        self.buffer.append(entry)\n\n        for queue, filters in list(self.listeners.values()):\n            if not self._matches_filters(entry, filters):\n                continue\n\n            if queue.full():\n                try:\n                    _ = queue.get_nowait()\n                except asyncio.QueueEmpty:\n                    pass\n            try:\n                queue.put_nowait(entry)\n            except asyncio.QueueFull:\n                # If still full after dropping one, skip to avoid blocking logging path\n                continue\n\n    def register_listener(self, filters: Dict[str, Any]) -> Tuple[str, asyncio.Queue]:\n        listener_id = str(uuid4())\n        queue: asyncio.Queue = asyncio.Queue(maxsize=self.queue_size)\n        self.listeners[listener_id] = (queue, filters)\n        return listener_id, queue\n\n    def unregister_listener(self, listener_id: str):\n        self.listeners.pop(listener_id, None)\n\n    def get_buffered(self, filters: Dict[str, Any]) -> list[Dict[str, Any]]:\n        return [entry for entry in list(self.buffer) if self._matches_filters(entry, filters)]\n\n\nclass StreamingLogHandler(logging.Handler):\n    \"\"\"Logging handler that forwards records to the log stream broker.\"\"\"\n\n    def __init__(self, broker: LogStreamBroker):\n        super().__init__()\n        self.broker = broker\n\n    def emit(self, record: logging.LogRecord) -> None:\n        try:\n            timestamp = datetime.fromtimestamp(record.created, timezone.utc).isoformat().replace(\"+00:00\", \"Z\")\n            entry = {\n                \"timestamp\": timestamp,\n                \"level\": record.levelname.lower(),\n                \"message\": record.getMessage(),\n                \"logger\": record.name,\n                \"service\": getattr(record, \"service_name\", \"api-gateway\"),\n                \"request_id\": getattr(record, \"request_id\", None),\n                \"extra\": {\n                    key: value\n                    for key, value in record.__dict__.items()\n                    if key\n                    not in {\n                        \"args\",\n                        \"asctime\",\n                        \"created\",\n                        \"exc_info\",\n                        \"exc_text\",\n                        \"filename\",\n                        \"funcName\",\n                        \"levelname\",\n                        \"levelno\",\n                        \"lineno\",\n                        \"module\",\n                        \"msecs\",\n                        \"message\",\n                        \"msg\",\n                        \"name\",\n                        \"pathname\",\n                        \"process\",\n                        \"processName\",\n                        \"relativeCreated\",\n                        \"stack_info\",\n                        \"thread\",\n                        \"threadName\",\n                    }\n                },\n            }\n            loop = asyncio.get_event_loop()\n            loop.call_soon_threadsafe(self.broker.publish, entry)\n        except Exception:\n            # Avoid raising within logging path\n            pass\n\n\n_broker = LogStreamBroker()\n_handler = StreamingLogHandler(_broker)\n\n\ndef get_log_stream_handler() -> StreamingLogHandler:\n    return _handler\n\n\ndef register_log_listener(filters: Dict[str, Any]) -> Tuple[str, asyncio.Queue]:\n    return _broker.register_listener(filters)\n\n\ndef unregister_log_listener(listener_id: str):\n    _broker.unregister_listener(listener_id)\n\n\ndef get_buffered_logs(filters: Dict[str, Any]) -> list[Dict[str, Any]]:\n    return _broker.get_buffered(filters)\n"
}
