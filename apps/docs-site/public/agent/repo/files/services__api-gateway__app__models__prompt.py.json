{
  "path": "services/api-gateway/app/models/prompt.py",
  "language": "python",
  "size": 9702,
  "last_modified": "2025-12-04T11:26:54.818Z",
  "lines": 258,
  "content": "\"\"\"Prompt and PromptVersion Models.\n\nProvides dynamic AI prompt management with version history for controlled\nupdates to Chat and Voice mode system instructions.\n\nFeatures:\n- Support for intent-based prompts (diagnosis, treatment, etc.)\n- Support for named personas (friendly_teacher, voice_assistant, etc.)\n- Full version history with rollback capability\n- Draft/Published workflow for sandbox testing\n- Multi-level caching integration (L1/L2/L3)\n\"\"\"\n\nfrom __future__ import annotations\n\nimport uuid\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any\n\nfrom app.core.database import Base\nfrom sqlalchemy import Boolean, Column, DateTime, Float, ForeignKey, Integer, String, Text, UniqueConstraint\nfrom sqlalchemy.dialects.postgresql import JSONB, UUID\nfrom sqlalchemy.orm import relationship\n\n\nclass PromptType(str, Enum):\n    \"\"\"Prompt type classification.\"\"\"\n\n    CHAT = \"chat\"  # Chat API prompts (intent-based)\n    VOICE = \"voice\"  # Realtime API prompts\n    PERSONA = \"persona\"  # Named personas (can be used with either)\n    SYSTEM = \"system\"  # General system prompts\n\n\nclass PromptStatus(str, Enum):\n    \"\"\"Prompt lifecycle status.\"\"\"\n\n    DRAFT = \"draft\"  # Being edited, not yet published\n    PUBLISHED = \"published\"  # Active and in use\n    ARCHIVED = \"archived\"  # Soft deleted, kept for history\n\n\n# Standard intent categories matching llm_client.py\nINTENT_CATEGORIES = [\n    \"diagnosis\",\n    \"treatment\",\n    \"drug\",\n    \"guideline\",\n    \"summary\",\n    \"other\",\n]\n\n\nclass Prompt(Base):\n    \"\"\"AI Prompt/Persona configuration.\n\n    Supports both intent-based prompts (e.g., \"intent:diagnosis\") and\n    named personas (e.g., \"persona:friendly_teacher\").\n\n    Attributes:\n        id: Unique identifier (UUID)\n        name: Unique identifier slug (e.g., \"intent:diagnosis\", \"voice:default\")\n        display_name: Human-readable name\n        description: Description of the prompt's purpose\n        prompt_type: Type classification (chat, voice, persona, system)\n        intent_category: For chat prompts, the intent category\n        system_prompt: Current draft content being edited\n        published_content: Currently active/live content\n        status: Lifecycle status (draft, published, archived)\n        is_active: Quick toggle for enabling/disabling\n        current_version: Current version number\n        metadata: Additional settings (voice config, temperature, etc.)\n    \"\"\"\n\n    __tablename__ = \"prompts\"\n\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n\n    # Identity\n    name = Column(String(255), unique=True, nullable=False, index=True)\n    display_name = Column(String(255), nullable=False)\n    description = Column(Text, nullable=True)\n\n    # Classification\n    prompt_type = Column(String(50), nullable=False, default=PromptType.CHAT.value, index=True)\n    intent_category = Column(String(100), nullable=True, index=True)\n\n    # Content - separate draft and published for sandbox testing\n    system_prompt = Column(Text, nullable=False)  # Draft/working copy\n    published_content = Column(Text, nullable=True)  # Currently live content\n\n    # State Management\n    status = Column(String(20), nullable=False, default=PromptStatus.DRAFT.value, index=True)\n    is_active = Column(Boolean, nullable=False, default=True)\n\n    # Version tracking\n    current_version = Column(Integer, nullable=False, default=1)\n\n    # Model settings (per-prompt overrides)\n    temperature = Column(\n        Float,\n        nullable=True,\n        default=0.7,\n        comment=\"LLM temperature (0.0-2.0), higher = more creative\",\n    )\n    max_tokens = Column(Integer, nullable=True, default=1024, comment=\"Maximum response tokens\")\n    model_name = Column(String(100), nullable=True, comment=\"Optional model override (e.g., 'gpt-4o')\")\n\n    # Metadata (voice settings, tags, etc.)\n    prompt_metadata = Column(\"metadata\", JSONB, nullable=True)\n\n    # Timestamps\n    created_at = Column(\n        DateTime(timezone=True),\n        nullable=False,\n        default=lambda: datetime.now(timezone.utc),\n    )\n    updated_at = Column(\n        DateTime(timezone=True),\n        nullable=False,\n        default=lambda: datetime.now(timezone.utc),\n        onupdate=lambda: datetime.now(timezone.utc),\n    )\n    published_at = Column(DateTime(timezone=True), nullable=True)\n\n    # User tracking\n    created_by_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True)\n    updated_by_id = Column(UUID(as_uuid=True), ForeignKey(\"users.id\", ondelete=\"SET NULL\"), nullable=True)\n\n    # Relationships\n    versions = relationship(\n        \"PromptVersion\",\n        back_populates=\"prompt\",\n        cascade=\"all, delete-orphan\",\n        order_by=\"desc(PromptVersion.version_number)\",\n    )\n    created_by = relationship(\"User\", foreign_keys=[created_by_id], lazy=\"joined\")\n    updated_by = relationship(\"User\", foreign_keys=[updated_by_id], lazy=\"joined\")\n\n    def __repr__(self) -> str:\n        return f\"<Prompt(name='{self.name}', type={self.prompt_type}, status={self.status})>\"\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"Convert model to dictionary for API responses and caching.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"name\": self.name,\n            \"display_name\": self.display_name,\n            \"description\": self.description,\n            \"prompt_type\": self.prompt_type,\n            \"intent_category\": self.intent_category,\n            \"system_prompt\": self.system_prompt,\n            \"published_content\": self.published_content,\n            \"status\": self.status,\n            \"is_active\": self.is_active,\n            \"current_version\": self.current_version,\n            \"temperature\": self.temperature,\n            \"max_tokens\": self.max_tokens,\n            \"model_name\": self.model_name,\n            \"metadata\": self.prompt_metadata,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n            \"updated_at\": self.updated_at.isoformat() if self.updated_at else None,\n            \"published_at\": (self.published_at.isoformat() if self.published_at else None),\n            \"created_by_id\": str(self.created_by_id) if self.created_by_id else None,\n            \"updated_by_id\": str(self.updated_by_id) if self.updated_by_id else None,\n            \"created_by_email\": self.created_by.email if self.created_by else None,\n            \"updated_by_email\": self.updated_by.email if self.updated_by else None,\n        }\n\n    def get_active_content(self) -> str:\n        \"\"\"Get the currently active content for this prompt.\n\n        Returns published_content if available and status is published,\n        otherwise returns the draft system_prompt.\n        \"\"\"\n        if self.status == PromptStatus.PUBLISHED.value and self.published_content:\n            return self.published_content\n        return self.system_prompt\n\n\nclass PromptVersion(Base):\n    \"\"\"Immutable version history for prompts.\n\n    Each version represents a snapshot of the prompt at a point in time.\n    Used for audit trail and rollback capability.\n\n    Attributes:\n        id: Unique identifier (UUID)\n        prompt_id: Reference to parent prompt\n        version_number: Sequential version number\n        system_prompt: Snapshot of content at this version\n        change_summary: Description of what changed\n        changed_by_id: User who made this change\n        changed_by_email: Email of user (denormalized for convenience)\n        status: Status at time of version creation\n    \"\"\"\n\n    __tablename__ = \"prompt_versions\"\n\n    id = Column(UUID(as_uuid=True), primary_key=True, default=uuid.uuid4)\n    prompt_id = Column(\n        UUID(as_uuid=True),\n        ForeignKey(\"prompts.id\", ondelete=\"CASCADE\"),\n        nullable=False,\n        index=True,\n    )\n\n    # Version info\n    version_number = Column(Integer, nullable=False)\n\n    # Snapshot of content at this version\n    system_prompt = Column(Text, nullable=False)\n    prompt_type = Column(String(50), nullable=False)\n    intent_category = Column(String(100), nullable=True)\n    version_metadata = Column(\"metadata\", JSONB, nullable=True)\n\n    # Change tracking\n    change_summary = Column(String(500), nullable=True)\n    changed_by_id = Column(UUID(as_uuid=True), nullable=True)\n    changed_by_email = Column(String(255), nullable=True)  # Denormalized\n\n    # Status at time of version creation\n    status = Column(String(20), nullable=False)\n\n    # Timestamp\n    created_at = Column(\n        DateTime(timezone=True),\n        nullable=False,\n        default=lambda: datetime.now(timezone.utc),\n    )\n\n    # Relationships\n    prompt = relationship(\"Prompt\", back_populates=\"versions\")\n\n    # Unique constraint: one version number per prompt\n    __table_args__ = (UniqueConstraint(\"prompt_id\", \"version_number\", name=\"uq_prompt_version\"),)\n\n    def __repr__(self) -> str:\n        return f\"<PromptVersion(prompt_id={self.prompt_id}, version={self.version_number})>\"\n\n    def to_dict(self) -> dict[str, Any]:\n        \"\"\"Convert model to dictionary for API responses.\"\"\"\n        return {\n            \"id\": str(self.id),\n            \"prompt_id\": str(self.prompt_id),\n            \"version_number\": self.version_number,\n            \"system_prompt\": self.system_prompt,\n            \"prompt_type\": self.prompt_type,\n            \"intent_category\": self.intent_category,\n            \"metadata\": self.version_metadata,\n            \"change_summary\": self.change_summary,\n            \"changed_by_id\": str(self.changed_by_id) if self.changed_by_id else None,\n            \"changed_by_email\": self.changed_by_email,\n            \"status\": self.status,\n            \"created_at\": self.created_at.isoformat() if self.created_at else None,\n        }\n"
}
