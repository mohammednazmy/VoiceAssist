{
  "path": "services/api-gateway/app/services/tools/search_tools.py",
  "language": "python",
  "size": 14596,
  "last_modified": "2025-12-04T11:27:01.423Z",
  "lines": 436,
  "content": "\"\"\"\nSearch Tools for VoiceAssist\n\nProvides web search (DuckDuckGo), PubMed search, and knowledge base search.\n\"\"\"\n\nimport logging\nfrom typing import Any, Dict, List\n\nimport httpx\nfrom app.services.tools.tool_service import ToolExecutionContext, ToolResult\n\nlogger = logging.getLogger(__name__)\n\n\nasync def handle_web_search(arguments: Dict[str, Any], context: ToolExecutionContext) -> ToolResult:\n    \"\"\"\n    Search the web using SerpAPI (Google search) or DuckDuckGo fallback.\n\n    Args:\n        arguments: Contains 'query' and optional 'max_results'\n        context: Execution context\n    \"\"\"\n    from app.core.config import settings\n\n    query = arguments.get(\"query\")\n    max_results = arguments.get(\"max_results\", 5)\n\n    if not query:\n        return ToolResult(\n            success=False,\n            data=None,\n            error=\"Search query is required\",\n            error_type=\"ValidationError\",\n        )\n\n    try:\n        # Use SerpAPI if API key is available (preferred - no rate limiting)\n        if settings.SERPAPI_API_KEY:\n            search_results = await _search_serpapi(query, max_results)\n            if search_results:\n                return ToolResult(\n                    success=True,\n                    data={\n                        \"query\": query,\n                        \"results\": search_results,\n                        \"count\": len(search_results),\n                        \"source\": \"google\",\n                    },\n                    message=f\"Found {len(search_results)} results for '{query}'.\",\n                )\n\n        # Fallback to DuckDuckGo if SerpAPI unavailable or failed\n        instant_answer = await _get_duckduckgo_instant_answer(query)\n        search_results = await _search_duckduckgo(query, max_results)\n\n        # Check if we got results\n        if not search_results and not instant_answer.get(\"abstract\"):\n            return ToolResult(\n                success=True,\n                data={\n                    \"query\": query,\n                    \"instant_answer\": \"\",\n                    \"results\": [],\n                    \"count\": 0,\n                    \"rate_limited\": True,\n                },\n                message=(\n                    f\"Web search for '{query}' returned no results. \"\n                    \"The search service may be temporarily unavailable due to rate limiting. \"\n                    \"Try using PubMed search for medical topics, or try again in a few minutes.\"\n                ),\n            )\n\n        return ToolResult(\n            success=True,\n            data={\n                \"query\": query,\n                \"instant_answer\": instant_answer.get(\"abstract\", \"\"),\n                \"source\": instant_answer.get(\"source\", \"\"),\n                \"source_url\": instant_answer.get(\"url\", \"\"),\n                \"results\": search_results,\n                \"count\": len(search_results),\n            },\n            message=f\"Found {len(search_results)} results for '{query}'.\",\n        )\n\n    except Exception as e:\n        logger.exception(f\"Error in web search: {e}\")\n        return ToolResult(\n            success=False,\n            data=None,\n            error=str(e),\n            error_type=type(e).__name__,\n        )\n\n\nasync def _search_serpapi(query: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Search using SerpAPI (Google search results).\n\n    Args:\n        query: Search query\n        max_results: Maximum number of results\n\n    Returns:\n        List of search results with title, url, snippet\n    \"\"\"\n    from app.core.config import settings\n\n    try:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                \"https://serpapi.com/search.json\",\n                params={\n                    \"q\": query,\n                    \"api_key\": settings.SERPAPI_API_KEY,\n                    \"num\": max_results,\n                    \"engine\": \"google\",\n                },\n                timeout=15.0,\n            )\n            response.raise_for_status()\n            data = response.json()\n\n        results = []\n        for item in data.get(\"organic_results\", [])[:max_results]:\n            results.append(\n                {\n                    \"title\": item.get(\"title\", \"\"),\n                    \"url\": item.get(\"link\", \"\"),\n                    \"snippet\": item.get(\"snippet\", \"\"),\n                }\n            )\n\n        logger.info(f\"SerpAPI search returned {len(results)} results for '{query}'\")\n        return results\n\n    except Exception as e:\n        logger.warning(f\"SerpAPI search error: {e}\")\n        return []\n\n\nasync def _get_duckduckgo_instant_answer(query: str) -> Dict[str, Any]:\n    \"\"\"Get instant answer from DuckDuckGo API.\"\"\"\n    try:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                \"https://api.duckduckgo.com/\",\n                params={\n                    \"q\": query,\n                    \"format\": \"json\",\n                    \"no_redirect\": 1,\n                    \"no_html\": 1,\n                },\n                timeout=10.0,\n            )\n            response.raise_for_status()\n            data = response.json()\n\n        return {\n            \"abstract\": data.get(\"AbstractText\", \"\"),\n            \"source\": data.get(\"AbstractSource\", \"\"),\n            \"url\": data.get(\"AbstractURL\", \"\"),\n            \"heading\": data.get(\"Heading\", \"\"),\n            \"answer\": data.get(\"Answer\", \"\"),\n        }\n    except Exception as e:\n        logger.warning(f\"DuckDuckGo instant answer error: {e}\")\n        return {}\n\n\nasync def _search_duckduckgo(query: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"\n    Search DuckDuckGo using the duckduckgo-search library.\n\n    Falls back to API-based search if library not available.\n    \"\"\"\n    import asyncio\n\n    try:\n        # Try using duckduckgo-search library with retry logic\n        from duckduckgo_search import DDGS\n        from duckduckgo_search.exceptions import RatelimitException\n\n        results = []\n        max_retries = 3\n\n        for attempt in range(max_retries):\n            try:\n                with DDGS() as ddgs:\n                    for r in ddgs.text(query, max_results=max_results):\n                        results.append(\n                            {\n                                \"title\": r.get(\"title\", \"\"),\n                                \"url\": r.get(\"href\", \"\"),\n                                \"snippet\": r.get(\"body\", \"\"),\n                            }\n                        )\n                return results\n            except RatelimitException:\n                if attempt < max_retries - 1:\n                    wait_time = (attempt + 1) * 2  # 2, 4, 6 seconds\n                    logger.warning(\n                        f\"DuckDuckGo rate limited, waiting {wait_time}s (attempt {attempt + 1}/{max_retries})\"\n                    )\n                    await asyncio.sleep(wait_time)\n                else:\n                    logger.warning(\"DuckDuckGo rate limit exceeded after retries\")\n                    raise\n            except Exception as e:\n                if \"Ratelimit\" in str(e):\n                    if attempt < max_retries - 1:\n                        wait_time = (attempt + 1) * 2\n                        logger.warning(\n                            f\"DuckDuckGo rate limited, waiting {wait_time}s (attempt {attempt + 1}/{max_retries})\"\n                        )\n                        await asyncio.sleep(wait_time)\n                    else:\n                        raise\n                else:\n                    raise\n\n        return results\n\n    except ImportError:\n        logger.warning(\"duckduckgo-search not installed, using API fallback\")\n        return await _search_duckduckgo_api_fallback(query, max_results)\n    except Exception as e:\n        logger.warning(f\"DuckDuckGo search error: {e}\")\n        # Return empty results with a note about rate limiting\n        return []\n\n\nasync def _search_duckduckgo_api_fallback(query: str, max_results: int) -> List[Dict[str, Any]]:\n    \"\"\"Fallback API-based search using DuckDuckGo's related topics.\"\"\"\n    try:\n        async with httpx.AsyncClient() as client:\n            response = await client.get(\n                \"https://api.duckduckgo.com/\",\n                params={\n                    \"q\": query,\n                    \"format\": \"json\",\n                },\n                timeout=10.0,\n            )\n            response.raise_for_status()\n            data = response.json()\n\n        results = []\n\n        # Get related topics as search results\n        for topic in data.get(\"RelatedTopics\", [])[:max_results]:\n            if isinstance(topic, dict) and \"FirstURL\" in topic:\n                results.append(\n                    {\n                        \"title\": topic.get(\"Text\", \"\")[:100],\n                        \"url\": topic.get(\"FirstURL\", \"\"),\n                        \"snippet\": topic.get(\"Text\", \"\"),\n                    }\n                )\n\n        return results\n\n    except Exception as e:\n        logger.warning(f\"DuckDuckGo API fallback error: {e}\")\n        return []\n\n\nasync def handle_pubmed_search(arguments: Dict[str, Any], context: ToolExecutionContext) -> ToolResult:\n    \"\"\"\n    Search PubMed for medical literature.\n\n    Args:\n        arguments: Contains 'query', optional 'max_results', 'date_range', 'article_types'\n        context: Execution context\n    \"\"\"\n    query = arguments.get(\"query\")\n    max_results = arguments.get(\"max_results\", 5)\n    date_range = arguments.get(\"date_range\")\n    article_types = arguments.get(\"article_types\", [])\n\n    if not query:\n        return ToolResult(\n            success=False,\n            data=None,\n            error=\"Search query is required\",\n            error_type=\"ValidationError\",\n        )\n\n    try:\n        # Use the existing EnhancedPubMedService\n        from app.services.pubmed_enhanced_service import EnhancedPubMedService\n\n        pubmed_service = EnhancedPubMedService()\n\n        # Build search parameters\n        search_query = query\n\n        # Add date filter\n        if date_range:\n            if date_range.isdigit() and len(date_range) == 4:\n                # Year filter\n                search_query += f\" AND {date_range}[pdat]\"\n            elif \"year\" in date_range.lower():\n                # Parse \"last X years\"\n                import re\n\n                match = re.search(r\"(\\d+)\\s*year\", date_range.lower())\n                if match:\n                    years = int(match.group(1))\n                    from datetime import datetime\n\n                    start_year = datetime.now().year - years\n                    search_query += f\" AND {start_year}:{datetime.now().year}[pdat]\"\n\n        # Add article type filters\n        if article_types:\n            type_filter = \" OR \".join(f\"{t}[pt]\" for t in article_types)\n            search_query += f\" AND ({type_filter})\"\n\n        # Perform search\n        results = await pubmed_service.search(search_query, max_results=max_results)\n\n        articles = []\n        for article in results.articles:\n            # Get journal name - handle both string and object types\n            journal_name = article.journal\n            if hasattr(article.journal, \"name\"):\n                journal_name = article.journal.name\n\n            articles.append(\n                {\n                    \"pmid\": article.pmid,\n                    \"title\": article.title,\n                    \"authors\": article.authors[:3] + ([\"et al.\"] if len(article.authors) > 3 else []),\n                    \"journal\": journal_name,\n                    \"pub_date\": article.pub_date,\n                    \"abstract\": (\n                        (article.abstract[:500] + \"...\")\n                        if article.abstract and len(article.abstract) > 500\n                        else article.abstract\n                    ),\n                    \"doi\": article.doi,\n                    \"publication_types\": article.publication_types,\n                    \"url\": f\"https://pubmed.ncbi.nlm.nih.gov/{article.pmid}/\",\n                }\n            )\n\n        return ToolResult(\n            success=True,\n            data={\n                \"query\": query,\n                \"articles\": articles,\n                \"count\": len(articles),\n                \"total_found\": results.total_count,\n            },\n            message=f\"Found {len(articles)} articles on PubMed for '{query}'.\",\n        )\n\n    except Exception as e:\n        logger.exception(f\"Error in PubMed search: {e}\")\n        return ToolResult(\n            success=False,\n            data=None,\n            error=str(e),\n            error_type=type(e).__name__,\n        )\n\n\nasync def handle_kb_search(arguments: Dict[str, Any], context: ToolExecutionContext) -> ToolResult:\n    \"\"\"\n    Search the knowledge base for relevant information.\n\n    Args:\n        arguments: Contains 'query', optional 'sources', 'max_results'\n        context: Execution context\n    \"\"\"\n    query = arguments.get(\"query\")\n    sources = arguments.get(\"sources\", [])\n    max_results = arguments.get(\"max_results\", 5)\n\n    if not query:\n        return ToolResult(\n            success=False,\n            data=None,\n            error=\"Search query is required\",\n            error_type=\"ValidationError\",\n        )\n\n    try:\n        # Use the hybrid search service\n        from app.services.hybrid_search_service import HybridSearchService\n\n        search_service = HybridSearchService()\n\n        # Perform search\n        results = await search_service.search(\n            query=query,\n            top_k=max_results,\n            source_types=sources if sources else None,\n        )\n\n        documents = []\n        for doc in results:\n            documents.append(\n                {\n                    \"id\": doc.id,\n                    \"title\": doc.title,\n                    \"content\": (doc.content[:500] + \"...\" if len(doc.content) > 500 else doc.content),\n                    \"source_type\": doc.source_type,\n                    \"source_name\": doc.source_name,\n                    \"location\": doc.location,\n                    \"relevance_score\": doc.score,\n                }\n            )\n\n        return ToolResult(\n            success=True,\n            data={\n                \"query\": query,\n                \"documents\": documents,\n                \"count\": len(documents),\n            },\n            message=f\"Found {len(documents)} relevant documents in the knowledge base.\",\n        )\n\n    except Exception as e:\n        logger.exception(f\"Error in KB search: {e}\")\n        return ToolResult(\n            success=False,\n            data=None,\n            error=str(e),\n            error_type=type(e).__name__,\n        )\n"
}
