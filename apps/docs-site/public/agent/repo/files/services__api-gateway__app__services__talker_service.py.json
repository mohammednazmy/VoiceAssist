{
  "path": "services/api-gateway/app/services/talker_service.py",
  "language": "python",
  "size": 40282,
  "last_modified": "2025-12-04T21:30:58.283Z",
  "lines": 1106,
  "content": "\"\"\"\nTalker Service - Text-to-Speech Orchestration\n\nUnified TTS service that manages streaming audio synthesis with:\n- Sentence-based chunking from LLM output\n- Audio queue management for gapless playback\n- Cancellation support for barge-in\n- Provider abstraction (ElevenLabs primary, OpenAI fallback)\n\nPhase: Thinker/Talker Voice Pipeline Migration\n\"\"\"\n\nimport asyncio\nimport re\nimport time\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import AsyncIterator, Awaitable, Callable, Dict, List, Optional\n\nfrom app.core.logging import get_logger\nfrom app.core.resilience import elevenlabs_breaker\nfrom app.services.elevenlabs_service import ElevenLabsService, elevenlabs_service\nfrom app.services.openai_tts_service import OpenAITTSService, map_elevenlabs_voice_to_openai, openai_tts_service\nfrom app.services.sentence_chunker import AdaptiveChunkerConfig, ChunkerConfig, SentenceChunker\nfrom app.services.ssml_processor import SSMLProcessor, VoiceStyle\nfrom app.services.tts.quality_presets import QualityPreset, get_preset_config\nfrom pybreaker import CircuitBreakerError\n\nlogger = get_logger(__name__)\n\n\n# ==============================================================================\n# Markdown Stripping for TTS\n# ==============================================================================\n\n\ndef strip_markdown_for_tts(text: str) -> str:\n    \"\"\"\n    Strip markdown and LaTeX formatting from text for natural TTS speech.\n\n    Converts markdown to plain text that sounds natural when spoken:\n    - [Link Text](URL) → \"Link Text\"\n    - **bold** → \"bold\"\n    - *italic* → \"italic\"\n    - `code` → \"code\"\n    - ```code blocks``` → (removed entirely)\n    - # Headers → \"Headers\"\n    - - bullet points → text only\n    - URLs → (removed or simplified)\n    - LaTeX formulas → (removed entirely)\n\n    Args:\n        text: Text that may contain markdown or LaTeX\n\n    Returns:\n        Clean text suitable for TTS\n    \"\"\"\n    if not text:\n        return text\n\n    result = text\n\n    # ===========================================\n    # Remove LaTeX/Math formulas FIRST\n    # ===========================================\n\n    # Remove display math: \\[ ... \\] (can span multiple lines)\n    result = re.sub(r\"\\\\\\[[\\s\\S]*?\\\\\\]\", \"\", result)\n\n    # Remove display math: $$ ... $$ (can span multiple lines)\n    result = re.sub(r\"\\$\\$[\\s\\S]*?\\$\\$\", \"\", result)\n\n    # Remove display math: [ ... ] when it contains LaTeX commands\n    # This pattern matches [ ... ] blocks that contain backslashes (LaTeX)\n    result = re.sub(r\"\\[\\s*\\\\[^]]+\\]\", \"\", result)\n\n    # Remove inline math: \\( ... \\)\n    result = re.sub(r\"\\\\\\(.*?\\\\\\)\", \"\", result)\n\n    # Remove inline math: $ ... $ (single dollars, not greedy)\n    # Be careful not to match currency like \"$5\"\n    result = re.sub(r\"\\$[^$\\d][^$]*\\$\", \"\", result)\n\n    # Remove standalone LaTeX commands that might remain\n    result = re.sub(\n        r\"\\\\(?:text|frac|sqrt|sum|int|times|div|approx|neq|leq|geq|pm)\\{[^}]*\\}\",\n        \"\",\n        result,\n    )\n    result = re.sub(r\"\\\\(?:text|frac|sqrt|sum|int|times|div|approx|neq|leq|geq|pm)\", \"\", result)\n\n    # Remove superscripts/subscripts: ^{...} and _{...}\n    result = re.sub(r\"[\\^_]\\{[^}]*\\}\", \"\", result)\n    result = re.sub(r\"[\\^_]\\d+\", \"\", result)  # Also ^2, _1, etc.\n\n    # ===========================================\n    # Remove Markdown formatting\n    # ===========================================\n\n    # Remove code blocks first (``` ... ```)\n    result = re.sub(r\"```[\\s\\S]*?```\", \"\", result)\n\n    # Remove inline code (`code`)\n    result = re.sub(r\"`([^`]+)`\", r\"\\1\", result)\n\n    # Convert markdown links [text](url) to just \"text\"\n    result = re.sub(r\"\\[([^\\]]+)\\]\\([^)]+\\)\", r\"\\1\", result)\n\n    # Remove reference-style links [text][ref]\n    result = re.sub(r\"\\[([^\\]]+)\\]\\[[^\\]]*\\]\", r\"\\1\", result)\n\n    # Remove bare URLs (http:// or https://)\n    # Replace with empty or say \"link\" to indicate there was a URL\n    result = re.sub(r\"https?://[^\\s\\)]+\", \"\", result)\n\n    # Remove bold (**text** or __text__)\n    result = re.sub(r\"\\*\\*([^*]+)\\*\\*\", r\"\\1\", result)\n    result = re.sub(r\"__([^_]+)__\", r\"\\1\", result)\n\n    # Remove italic (*text* or _text_) - be careful not to catch asterisks in lists\n    result = re.sub(r\"(?<!\\*)\\*([^*]+)\\*(?!\\*)\", r\"\\1\", result)\n    result = re.sub(r\"(?<!_)_([^_]+)_(?!_)\", r\"\\1\", result)\n\n    # Remove strikethrough (~~text~~)\n    result = re.sub(r\"~~([^~]+)~~\", r\"\\1\", result)\n\n    # Remove headers (# text, ## text, etc.) - keep the text\n    result = re.sub(r\"^#{1,6}\\s*\", \"\", result, flags=re.MULTILINE)\n\n    # Remove horizontal rules\n    result = re.sub(r\"^[-*_]{3,}\\s*$\", \"\", result, flags=re.MULTILINE)\n\n    # Remove blockquotes (> text) - keep the text\n    result = re.sub(r\"^>\\s*\", \"\", result, flags=re.MULTILINE)\n\n    # Remove list markers (- item, * item, 1. item)\n    result = re.sub(r\"^[\\s]*[-*+]\\s+\", \"\", result, flags=re.MULTILINE)\n    result = re.sub(r\"^[\\s]*\\d+\\.\\s+\", \"\", result, flags=re.MULTILINE)\n\n    # Remove image markdown ![alt](url)\n    result = re.sub(r\"!\\[([^\\]]*)\\]\\([^)]+\\)\", r\"\\1\", result)\n\n    # Clean up extra whitespace (but preserve single spaces for word boundaries)\n    result = re.sub(r\"\\n{3,}\", \"\\n\\n\", result)  # Max 2 newlines\n    result = re.sub(r\"  +\", \" \", result)  # Multiple spaces to single\n    # Don't strip - preserve leading/trailing spaces for proper word joining\n    # The sentence chunker will handle final whitespace normalization\n\n    return result\n\n\n# ==============================================================================\n# Data Classes\n# ==============================================================================\n\n\nclass TTSProvider(str, Enum):\n    \"\"\"Supported TTS providers.\"\"\"\n\n    ELEVENLABS = \"elevenlabs\"\n    OPENAI = \"openai\"\n\n\nclass TalkerState(str, Enum):\n    \"\"\"State of the Talker service.\"\"\"\n\n    IDLE = \"idle\"\n    SPEAKING = \"speaking\"\n    CANCELLED = \"cancelled\"\n\n\n@dataclass\nclass VoiceConfig:\n    \"\"\"Configuration for voice synthesis.\"\"\"\n\n    provider: TTSProvider = TTSProvider.ELEVENLABS\n    voice_id: str = \"TxGEqnHWrfWFTfGW9XjX\"  # Josh (premium male voice)\n    model_id: str = \"eleven_turbo_v2_5\"  # Best balance of quality and latency\n    stability: float = 0.78  # Higher for consistent voice (0.65-0.85 range)\n    similarity_boost: float = 0.85  # Higher for voice clarity and consistency\n    style: float = 0.08  # Lower for more natural, less dramatic speech\n    use_speaker_boost: bool = True\n    output_format: str = \"pcm_24000\"  # Raw PCM for low-latency streaming playback\n\n    # SSML processing for natural pauses\n    enable_ssml: bool = True  # Enable SSML break tags for natural rhythm\n    voice_style: VoiceStyle = VoiceStyle.CONVERSATIONAL  # Affects pause durations\n\n    # Quality preset (overrides individual settings when set)\n    quality_preset: Optional[QualityPreset] = None\n\n    def apply_preset(self, preset: QualityPreset) -> \"VoiceConfig\":\n        \"\"\"\n        Apply a quality preset to this config.\n\n        Returns a new VoiceConfig with preset values applied.\n        \"\"\"\n        preset_config = get_preset_config(preset)\n\n        return VoiceConfig(\n            provider=self.provider,\n            voice_id=self.voice_id,\n            model_id=self.model_id,\n            stability=preset_config.stability,\n            similarity_boost=preset_config.similarity_boost,\n            style=preset_config.style_exaggeration,\n            use_speaker_boost=self.use_speaker_boost,\n            output_format=self.output_format,\n            enable_ssml=preset_config.enable_ssml,\n            voice_style=preset_config.voice_style,\n            quality_preset=preset,\n        )\n\n\n@dataclass\nclass AudioChunk:\n    \"\"\"A chunk of audio data ready for playback.\"\"\"\n\n    data: bytes\n    format: str  # \"mp3\" or \"pcm16\"\n    is_final: bool = False\n    sentence_index: int = 0\n    latency_ms: int = 0\n\n\n@dataclass\nclass TalkerMetrics:\n    \"\"\"Metrics for a TTS session.\"\"\"\n\n    sentences_processed: int = 0\n    total_chars_synthesized: int = 0\n    total_audio_bytes: int = 0\n    total_latency_ms: int = 0\n    first_audio_latency_ms: int = 0\n    cancelled: bool = False\n\n\n# ==============================================================================\n# Audio Queue for Gapless Playback\n# ==============================================================================\n\n\nclass AudioQueue:\n    \"\"\"\n    Manages audio chunks for gapless playback with cancellation support.\n\n    Features:\n    - Async queue for audio chunks\n    - Cancellation clears pending audio\n    - Tracks queue state\n    \"\"\"\n\n    def __init__(self, max_size: int = 50):\n        self._queue: asyncio.Queue[Optional[AudioChunk]] = asyncio.Queue(maxsize=max_size)\n        self._cancelled = False\n        self._finished = False\n\n    async def put(self, chunk: AudioChunk) -> bool:\n        \"\"\"\n        Add an audio chunk to the queue.\n\n        Returns:\n            True if added, False if cancelled\n        \"\"\"\n        if self._cancelled:\n            return False\n\n        try:\n            await asyncio.wait_for(self._queue.put(chunk), timeout=5.0)\n            return True\n        except asyncio.TimeoutError:\n            logger.warning(\"Audio queue full, dropping chunk\")\n            return False\n\n    async def get(self) -> Optional[AudioChunk]:\n        \"\"\"\n        Get the next audio chunk.\n\n        Returns:\n            AudioChunk or None if queue is empty/cancelled/finished\n        \"\"\"\n        if self._cancelled and self._queue.empty():\n            return None\n\n        try:\n            chunk = await asyncio.wait_for(self._queue.get(), timeout=1.0)\n            return chunk\n        except asyncio.TimeoutError:\n            if self._finished:\n                return None\n            return None  # Timeout but not finished - caller should retry\n\n    async def cancel(self) -> None:\n        \"\"\"Cancel the queue and clear pending audio.\"\"\"\n        self._cancelled = True\n        # Drain the queue\n        while not self._queue.empty():\n            try:\n                self._queue.get_nowait()\n            except asyncio.QueueEmpty:\n                break\n\n    def finish(self) -> None:\n        \"\"\"Signal that no more audio will be added.\"\"\"\n        self._finished = True\n\n    def is_cancelled(self) -> bool:\n        \"\"\"Check if the queue was cancelled.\"\"\"\n        return self._cancelled\n\n    def is_empty(self) -> bool:\n        \"\"\"Check if the queue is empty.\"\"\"\n        return self._queue.empty()\n\n    def reset(self) -> None:\n        \"\"\"Reset the queue for reuse.\"\"\"\n        self._cancelled = False\n        self._finished = False\n        while not self._queue.empty():\n            try:\n                self._queue.get_nowait()\n            except asyncio.QueueEmpty:\n                break\n\n\n# ==============================================================================\n# Talker Service\n# ==============================================================================\n\n\nclass TalkerService:\n    \"\"\"\n    Unified TTS service for the Thinker/Talker pipeline.\n\n    Handles:\n    - Streaming LLM tokens through sentence chunker\n    - Parallel TTS synthesis for each sentence\n    - Audio queue management for gapless output\n    - Cancellation (barge-in support)\n    - TTS provider failover (ElevenLabs → OpenAI)\n\n    Usage:\n        talker = TalkerService()\n\n        # Start a speaking session\n        session = await talker.start_session(\n            voice_config=VoiceConfig(),\n            on_audio_chunk=handle_audio,  # Called for each audio chunk\n        )\n\n        # Feed tokens from LLM\n        for token in llm_stream:\n            if session.is_cancelled():\n                break\n            await session.add_token(token)\n\n        # Finish and get final audio\n        await session.finish()\n    \"\"\"\n\n    def __init__(self):\n        self._elevenlabs = elevenlabs_service\n        self._openai_tts = openai_tts_service\n        self._default_config = VoiceConfig()\n\n    def is_enabled(self) -> bool:\n        \"\"\"Check if TTS is available (either provider).\"\"\"\n        return self._elevenlabs.is_enabled() or self._openai_tts.is_enabled()\n\n    def get_provider(self) -> TTSProvider:\n        \"\"\"Get the primary TTS provider.\"\"\"\n        if self._elevenlabs.is_enabled():\n            return TTSProvider.ELEVENLABS\n        return TTSProvider.OPENAI\n\n    def get_fallback_available(self) -> bool:\n        \"\"\"Check if fallback TTS provider is available.\"\"\"\n        return self._openai_tts.is_enabled()\n\n    async def start_session(\n        self,\n        on_audio_chunk: Callable[[AudioChunk], Awaitable[None]],\n        voice_config: Optional[VoiceConfig] = None,\n    ) -> \"TalkerSession\":\n        \"\"\"\n        Start a new TTS session.\n\n        Args:\n            on_audio_chunk: Async callback for each audio chunk\n            voice_config: Voice configuration (uses defaults if not provided)\n\n        Returns:\n            TalkerSession for managing the TTS process\n        \"\"\"\n        config = voice_config or self._default_config\n\n        return TalkerSession(\n            elevenlabs=self._elevenlabs,\n            openai_tts=self._openai_tts,\n            config=config,\n            on_audio_chunk=on_audio_chunk,\n        )\n\n    async def synthesize_text(\n        self,\n        text: str,\n        voice_config: Optional[VoiceConfig] = None,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"\n        Simple streaming synthesis for a complete text.\n\n        Args:\n            text: Text to synthesize\n            voice_config: Voice configuration\n\n        Yields:\n            Audio data chunks\n        \"\"\"\n        config = voice_config or self._default_config\n\n        async for chunk in self._elevenlabs.synthesize_stream(\n            text=text,\n            voice_id=config.voice_id,\n            model_id=config.model_id,\n            output_format=config.output_format,\n            stability=config.stability,\n            similarity_boost=config.similarity_boost,\n            style=config.style,\n            use_speaker_boost=config.use_speaker_boost,\n        ):\n            yield chunk\n\n    def get_available_voices(self) -> List[Dict]:\n        \"\"\"Get list of available ElevenLabs voices.\"\"\"\n        return [\n            # Premium Voices (Recommended)\n            {\n                \"id\": \"pNInz6obpgDQGcFmaJgB\",\n                \"name\": \"Adam\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"TxGEqnHWrfWFTfGW9XjX\",\n                \"name\": \"Josh\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"EXAVITQu4vr4xnSDxMaL\",\n                \"name\": \"Bella\",\n                \"gender\": \"female\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"21m00Tcm4TlvDq8ikWAM\",\n                \"name\": \"Rachel\",\n                \"gender\": \"female\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            # Conversational Voices (warm, natural tone)\n            {\n                \"id\": \"nPczCjzI2devNBz1zQrb\",\n                \"name\": \"Brian\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"XB0fDUnXU5powFXDhCwa\",\n                \"name\": \"Charlotte\",\n                \"gender\": \"female\",\n                \"accent\": \"Swedish\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"XrExE9yKIg1WjnnlVkGX\",\n                \"name\": \"Matilda\",\n                \"gender\": \"female\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"JBFqnCBsd6RMkjVDRZzb\",\n                \"name\": \"George\",\n                \"gender\": \"male\",\n                \"accent\": \"British\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"IKne3meq5aSn9XLyUdCD\",\n                \"name\": \"Charlie\",\n                \"gender\": \"male\",\n                \"accent\": \"Australian\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"pFZP5JQG7iQjIQuC4Bku\",\n                \"name\": \"Lily\",\n                \"gender\": \"female\",\n                \"accent\": \"British\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"N2lVS1w4EtoT3dr4eOWO\",\n                \"name\": \"Callum\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"onwK4e9ZLuTAKqWW03F9\",\n                \"name\": \"Daniel\",\n                \"gender\": \"male\",\n                \"accent\": \"British\",\n                \"premium\": True,\n            },\n            {\n                \"id\": \"Xb7hH8MSUJpSbSDYk0k2\",\n                \"name\": \"Alice\",\n                \"gender\": \"female\",\n                \"accent\": \"British\",\n                \"premium\": True,\n            },\n            # Standard Voices\n            {\n                \"id\": \"AZnzlk1XvdvUeBnXmlld\",\n                \"name\": \"Domi\",\n                \"gender\": \"female\",\n                \"accent\": \"American\",\n                \"premium\": False,\n            },\n            {\n                \"id\": \"ErXwobaYiN019PkySvjV\",\n                \"name\": \"Antoni\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": False,\n            },\n            {\n                \"id\": \"MF3mGyEYCl7XYWbV9V6O\",\n                \"name\": \"Elli\",\n                \"gender\": \"female\",\n                \"accent\": \"American\",\n                \"premium\": False,\n            },\n            {\n                \"id\": \"VR6AewLTigWG4xSOukaG\",\n                \"name\": \"Arnold\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": False,\n            },\n            {\n                \"id\": \"yoZ06aMxZJJ28mfd3POQ\",\n                \"name\": \"Sam\",\n                \"gender\": \"male\",\n                \"accent\": \"American\",\n                \"premium\": False,\n            },\n        ]\n\n\n# Fallback recovery configuration\nFALLBACK_COOLDOWN_SECONDS = 30.0  # Try ElevenLabs again after 30 seconds in fallback\nFALLBACK_MIN_SENTENCES_BEFORE_RETRY = 3  # Don't retry until at least 3 sentences synthesized\n\n\nclass TalkerSession:\n    \"\"\"\n    A single TTS speaking session with streaming support.\n\n    Manages the flow:\n    1. Receive LLM tokens\n    2. Chunk into sentences\n    3. Synthesize each sentence (with failover)\n    4. Stream audio chunks to callback\n\n    Failover Strategy:\n    - Primary: ElevenLabs (premium quality)\n    - Fallback: OpenAI TTS (reliable, good quality)\n    - Triggers: Circuit breaker open, connection errors, API errors\n    - Recovery: After cooldown period, retry ElevenLabs\n    \"\"\"\n\n    def __init__(\n        self,\n        elevenlabs: ElevenLabsService,\n        openai_tts: OpenAITTSService,\n        config: VoiceConfig,\n        on_audio_chunk: Callable[[AudioChunk], Awaitable[None]],\n    ):\n        self._elevenlabs = elevenlabs\n        self._openai_tts = openai_tts\n        self._config = config\n        self._on_audio_chunk = on_audio_chunk\n\n        # Track failover state for this session\n        self._using_fallback = False\n        self._fallback_triggered_at: Optional[float] = None\n        self._sentences_since_fallback: int = 0  # Track sentences since fallback triggered\n\n        # Get adaptive chunking config from quality preset (if set) or use defaults\n        if config.quality_preset:\n            preset_config = get_preset_config(config.quality_preset)\n            adaptive_config = preset_config.adaptive_chunking\n            self._audio_chunk_size = preset_config.audio_chunk_size\n        else:\n            # Default adaptive config (BALANCED preset behavior)\n            adaptive_config = AdaptiveChunkerConfig(\n                first_chunk_min=20,\n                first_chunk_optimal=30,\n                first_chunk_max=50,\n                subsequent_min=40,\n                subsequent_optimal=120,\n                subsequent_max=200,\n                chunks_before_natural=1,\n                enabled=True,\n            )\n            self._audio_chunk_size = 8192  # Default chunk size\n\n        # Adaptive chunking for optimal TTFA AND naturalness\n        # Strategy: Small first chunk for fast time-to-first-audio (~150ms),\n        # then larger natural chunks for better prosody after first audio plays.\n        self._chunker = SentenceChunker(\n            config=ChunkerConfig(\n                min_chunk_chars=40,  # Fallback when adaptive is disabled\n                optimal_chunk_chars=120,\n                max_chunk_chars=200,\n            ),\n            adaptive_config=adaptive_config,\n        )\n\n        # Markdown-aware buffer for TTS\n        # Accumulates tokens to detect and strip markdown before chunking\n        self._markdown_buffer = \"\"\n\n        # SSML processor for natural speech pauses\n        self._ssml_processor = SSMLProcessor() if config.enable_ssml else None\n        self._voice_style = config.voice_style\n\n        # Voice continuity tracking\n        # Store previous sentence text to pass as context for consistent voice\n        self._previous_text: str = \"\"\n\n        # State\n        self._state = TalkerState.IDLE\n        self._sentence_index = 0\n        self._first_audio_time: Optional[float] = None\n        self._start_time: Optional[float] = None\n\n        # Metrics\n        self._metrics = TalkerMetrics()\n\n        # Sequential synthesis for voice consistency\n        # (parallel synthesis can cause voice variations between chunks)\n        self._synthesis_tasks: List[asyncio.Task] = []\n        self._synthesis_semaphore = asyncio.Semaphore(1)  # Sequential synthesis for consistency\n\n    @property\n    def state(self) -> TalkerState:\n        \"\"\"Get current state.\"\"\"\n        return self._state\n\n    def is_cancelled(self) -> bool:\n        \"\"\"Check if session was cancelled.\"\"\"\n        return self._state == TalkerState.CANCELLED\n\n    async def add_token(self, token: str) -> None:\n        \"\"\"\n        Add a token from the LLM stream.\n\n        Args:\n            token: Token from LLM response\n        \"\"\"\n        if self._state == TalkerState.CANCELLED:\n            return\n\n        if self._start_time is None:\n            self._start_time = time.time()\n\n        self._state = TalkerState.SPEAKING\n\n        # Process token through markdown-aware buffer before chunking\n        clean_text = self._process_markdown_token(token)\n\n        if clean_text:\n            # Add cleaned text to chunker and get any complete sentences\n            sentences = self._chunker.add_token(clean_text)\n\n            # Synthesize each sentence (may run concurrently)\n            for sentence in sentences:\n                await self._synthesize_sentence(sentence)\n\n    def _process_markdown_token(self, token: str) -> str:\n        \"\"\"\n        Process a token through the markdown/LaTeX-aware buffer.\n\n        Accumulates tokens to detect patterns that should be stripped for TTS:\n        - Markdown links: [text](url)\n        - LaTeX display math: [ ... ] with backslashes\n        - LaTeX inline: \\\\( ... \\\\) and \\\\[ ... \\\\]\n        - Bold/italic: **text** and *text*\n\n        Args:\n            token: Raw token from LLM\n\n        Returns:\n            Clean text to send to chunker (may be empty if buffering)\n        \"\"\"\n        self._markdown_buffer += token\n\n        # ===========================================\n        # Check for incomplete LaTeX blocks FIRST\n        # ===========================================\n\n        # Check for LaTeX display math: [ \\... ] (square brackets with backslash)\n        # This is common in LLM responses for formulas\n        open_bracket = self._markdown_buffer.rfind(\"[\")\n        if open_bracket != -1:\n            after_bracket = self._markdown_buffer[open_bracket:]\n            # If this looks like LaTeX (contains backslash after bracket)\n            if \"\\\\\" in after_bracket:\n                # Wait for closing ] if not present\n                # Count brackets to handle nested cases\n                bracket_count = after_bracket.count(\"[\") - after_bracket.count(\"]\")\n                if bracket_count > 0 and len(self._markdown_buffer) < 1000:\n                    # Unclosed LaTeX block, keep buffering\n                    return \"\"\n\n        # Check for LaTeX \\[ ... \\] blocks\n        if \"\\\\[\" in self._markdown_buffer:\n            last_open = self._markdown_buffer.rfind(\"\\\\[\")\n            after_open = self._markdown_buffer[last_open:]\n            if \"\\\\]\" not in after_open and len(self._markdown_buffer) < 1000:\n                # Unclosed \\[ block, keep buffering\n                return \"\"\n\n        # Check for LaTeX \\( ... \\) blocks\n        if \"\\\\(\" in self._markdown_buffer:\n            last_open = self._markdown_buffer.rfind(\"\\\\(\")\n            after_open = self._markdown_buffer[last_open:]\n            if \"\\\\)\" not in after_open and len(self._markdown_buffer) < 500:\n                # Unclosed \\( block, keep buffering\n                return \"\"\n\n        # Check for $$ ... $$ blocks\n        dollar_count = self._markdown_buffer.count(\"$$\")\n        if dollar_count % 2 == 1 and len(self._markdown_buffer) < 1000:\n            # Unclosed $$ block, keep buffering\n            return \"\"\n\n        # ===========================================\n        # Check for incomplete Markdown patterns\n        # ===========================================\n\n        # Check for markdown links [text](url)\n        if open_bracket != -1:\n            after_bracket = self._markdown_buffer[open_bracket:]\n            # Only treat as markdown link if no backslash (not LaTeX)\n            if \"\\\\\" not in after_bracket:\n                if \"](\" in after_bracket:\n                    # We have [text]( - check if URL is complete\n                    if \")\" not in after_bracket.split(\"](\")[1]:\n                        # URL not complete, keep buffering\n                        return \"\"\n                elif \"]\" not in after_bracket:\n                    # Link text not complete, keep buffering\n                    if len(self._markdown_buffer) < 500:\n                        return \"\"\n\n        # Check for unclosed bold/italic (but don't wait too long)\n        if self._markdown_buffer.endswith(\"*\") and len(self._markdown_buffer) < 200:\n            trailing_asterisks = len(self._markdown_buffer) - len(self._markdown_buffer.rstrip(\"*\"))\n            if trailing_asterisks in (1, 2):\n                if len(self._markdown_buffer) < 50:\n                    return \"\"\n\n        # Strip markdown/LaTeX from the buffer and return clean text\n        clean = strip_markdown_for_tts(self._markdown_buffer)\n        self._markdown_buffer = \"\"\n        return clean\n\n    def _flush_markdown_buffer(self) -> str:\n        \"\"\"Flush any remaining content in the markdown buffer.\"\"\"\n        if self._markdown_buffer:\n            clean = strip_markdown_for_tts(self._markdown_buffer)\n            self._markdown_buffer = \"\"\n            return clean\n        return \"\"\n\n    async def _synthesize_sentence(self, sentence: str) -> None:\n        \"\"\"\n        Synthesize a single sentence and stream audio chunks.\n\n        Implements failover strategy:\n        1. Check if ElevenLabs circuit breaker is open → use OpenAI immediately\n        2. Try ElevenLabs synthesis\n        3. On failure, fall back to OpenAI TTS\n        4. Continue with fallback for rest of session\n\n        Args:\n            sentence: Text to synthesize\n        \"\"\"\n        if self._state == TalkerState.CANCELLED:\n            return\n\n        # Strip markdown formatting for natural TTS speech\n        # This converts [Link Text](URL) to \"Link Text\", removes **bold**, etc.\n        # The original markdown is preserved in the chat transcript\n        tts_text = strip_markdown_for_tts(sentence)\n\n        # Skip if text is empty after stripping (e.g., was just a code block)\n        if not tts_text or not tts_text.strip():\n            logger.debug(f\"Skipping empty TTS text (original: {sentence[:50]}...)\")\n            return\n\n        # Apply SSML processing for natural pauses (if enabled)\n        if self._ssml_processor:\n            tts_text = self._ssml_processor.process(tts_text, style=self._voice_style)\n\n        sentence_idx = self._sentence_index\n        self._sentence_index += 1\n        self._metrics.sentences_processed += 1\n        self._metrics.total_chars_synthesized += len(tts_text)\n\n        start_time = time.time()\n\n        try:\n            # Use semaphore for sequential synthesis (ensures voice consistency)\n            async with self._synthesis_semaphore:\n                if self._state == TalkerState.CANCELLED:\n                    return\n\n                # Determine which provider to use\n                use_fallback = self._using_fallback\n\n                # Check if we should try to recover from fallback\n                if use_fallback and self._fallback_triggered_at:\n                    time_in_fallback = time.time() - self._fallback_triggered_at\n                    if (\n                        time_in_fallback >= FALLBACK_COOLDOWN_SECONDS\n                        and self._sentences_since_fallback >= FALLBACK_MIN_SENTENCES_BEFORE_RETRY\n                    ):\n                        # Check if ElevenLabs circuit breaker is now closed\n                        try:\n                            elevenlabs_breaker.call(lambda: None)\n                            # Circuit breaker is closed, try to recover\n                            logger.info(\n                                \"Attempting to recover from TTS fallback to ElevenLabs\",\n                                extra={\n                                    \"time_in_fallback_sec\": round(time_in_fallback, 1),\n                                    \"sentences_since_fallback\": self._sentences_since_fallback,\n                                },\n                            )\n                            use_fallback = False  # Try ElevenLabs again\n                        except CircuitBreakerError:\n                            # Circuit breaker still open, stay in fallback\n                            pass\n\n                # Check if ElevenLabs circuit breaker is open\n                if not use_fallback:\n                    try:\n                        elevenlabs_breaker.call(lambda: None)\n                    except CircuitBreakerError:\n                        logger.warning(\n                            \"ElevenLabs circuit breaker OPEN, using OpenAI TTS fallback\",\n                            extra={\"sentence_idx\": sentence_idx},\n                        )\n                        use_fallback = True\n                        self._using_fallback = True\n                        self._fallback_triggered_at = time.time()\n                        self._sentences_since_fallback = 0\n\n                chunk_count = 0\n                provider_used = \"openai\" if use_fallback else \"elevenlabs\"\n\n                if use_fallback and self._openai_tts.is_enabled():\n                    # Use OpenAI TTS fallback\n                    chunk_count = await self._synthesize_with_openai(tts_text, sentence_idx, start_time)\n                    self._sentences_since_fallback += 1\n                else:\n                    # Try ElevenLabs (primary)\n                    try:\n                        chunk_count = await self._synthesize_with_elevenlabs(tts_text, sentence_idx, start_time)\n                        # ElevenLabs succeeded - if we were recovering from fallback, reset state\n                        if self._using_fallback:\n                            logger.info(\n                                \"TTS fallback recovery successful - back to ElevenLabs\",\n                                extra={\n                                    \"sentence_idx\": sentence_idx,\n                                    \"time_in_fallback_sec\": (\n                                        round(time.time() - self._fallback_triggered_at, 1)\n                                        if self._fallback_triggered_at\n                                        else 0\n                                    ),\n                                },\n                            )\n                            self._using_fallback = False\n                            self._fallback_triggered_at = None\n                            self._sentences_since_fallback = 0\n                    except (CircuitBreakerError, Exception) as e:\n                        # ElevenLabs failed, try OpenAI fallback\n                        if self._openai_tts.is_enabled():\n                            logger.warning(\n                                f\"ElevenLabs TTS failed ({type(e).__name__}), \" \"falling back to OpenAI TTS\",\n                                extra={\n                                    \"error\": str(e)[:100],\n                                    \"sentence_idx\": sentence_idx,\n                                },\n                            )\n                            self._using_fallback = True\n                            self._fallback_triggered_at = time.time()\n                            self._sentences_since_fallback = 0\n                            provider_used = \"openai\"\n                            chunk_count = await self._synthesize_with_openai(tts_text, sentence_idx, start_time)\n                            self._sentences_since_fallback += 1\n                        else:\n                            # No fallback available, re-raise\n                            raise\n\n                # Update previous text for next synthesis (maintains voice continuity)\n                self._previous_text = tts_text\n\n                latency_ms = int((time.time() - start_time) * 1000)\n                self._metrics.total_latency_ms += latency_ms\n\n                # Log with context info\n                stripped = len(tts_text) != len(sentence)\n                logger.debug(\n                    f\"Synthesized sentence {sentence_idx}\",\n                    extra={\n                        \"chars\": len(tts_text),\n                        \"original_chars\": len(sentence) if stripped else None,\n                        \"markdown_stripped\": stripped,\n                        \"chunks\": chunk_count,\n                        \"latency_ms\": latency_ms,\n                        \"provider\": provider_used,\n                        \"has_previous_context\": bool(self._previous_text),\n                    },\n                )\n\n        except Exception as e:\n            logger.error(f\"TTS synthesis error (all providers failed): {e}\")\n            # Don't fail the entire session, just log the error\n\n    async def _synthesize_with_elevenlabs(self, tts_text: str, sentence_idx: int, start_time: float) -> int:\n        \"\"\"Synthesize using ElevenLabs (primary provider).\"\"\"\n        chunk_count = 0\n        async for audio_data in self._elevenlabs.synthesize_stream(\n            text=tts_text,\n            voice_id=self._config.voice_id,\n            model_id=self._config.model_id,\n            output_format=self._config.output_format,\n            stability=self._config.stability,\n            similarity_boost=self._config.similarity_boost,\n            style=self._config.style,\n            use_speaker_boost=self._config.use_speaker_boost,\n            chunk_size=self._audio_chunk_size,\n            previous_text=self._previous_text,\n        ):\n            if self._state == TalkerState.CANCELLED:\n                return chunk_count\n\n            chunk_count += 1\n            latency_ms = int((time.time() - start_time) * 1000)\n\n            # Track first audio latency\n            if self._first_audio_time is None:\n                self._first_audio_time = time.time()\n                self._metrics.first_audio_latency_ms = int((self._first_audio_time - self._start_time) * 1000)\n                logger.info(f\"First audio latency: {self._metrics.first_audio_latency_ms}ms\")\n\n            self._metrics.total_audio_bytes += len(audio_data)\n\n            # Send audio chunk to callback\n            chunk = AudioChunk(\n                data=audio_data,\n                format=\"pcm16\",  # Raw PCM16 at 24kHz\n                is_final=False,\n                sentence_index=sentence_idx,\n                latency_ms=latency_ms,\n            )\n            await self._on_audio_chunk(chunk)\n\n        return chunk_count\n\n    async def _synthesize_with_openai(self, tts_text: str, sentence_idx: int, start_time: float) -> int:\n        \"\"\"Synthesize using OpenAI TTS (fallback provider).\"\"\"\n        # Map ElevenLabs voice to OpenAI voice\n        openai_voice = map_elevenlabs_voice_to_openai(self._config.voice_id)\n\n        chunk_count = 0\n        async for audio_data in self._openai_tts.synthesize_stream(\n            text=tts_text,\n            voice=openai_voice,\n            model=\"tts-1\",  # Use fast model for low latency\n            speed=1.0,\n            response_format=\"pcm\",  # Raw PCM for streaming\n            chunk_size=self._audio_chunk_size,\n        ):\n            if self._state == TalkerState.CANCELLED:\n                return chunk_count\n\n            chunk_count += 1\n            latency_ms = int((time.time() - start_time) * 1000)\n\n            # Track first audio latency\n            if self._first_audio_time is None:\n                self._first_audio_time = time.time()\n                self._metrics.first_audio_latency_ms = int((self._first_audio_time - self._start_time) * 1000)\n                logger.info(f\"First audio latency (OpenAI fallback): \" f\"{self._metrics.first_audio_latency_ms}ms\")\n\n            self._metrics.total_audio_bytes += len(audio_data)\n\n            # Send audio chunk to callback\n            # Note: OpenAI PCM is 24kHz 16-bit mono, same as ElevenLabs pcm_24000\n            chunk = AudioChunk(\n                data=audio_data,\n                format=\"pcm16\",\n                is_final=False,\n                sentence_index=sentence_idx,\n                latency_ms=latency_ms,\n            )\n            await self._on_audio_chunk(chunk)\n\n        return chunk_count\n\n    async def finish(self) -> TalkerMetrics:\n        \"\"\"\n        Finish the session and synthesize any remaining text.\n\n        Returns:\n            TalkerMetrics with session statistics\n        \"\"\"\n        if self._state == TalkerState.CANCELLED:\n            return self._metrics\n\n        # Flush any remaining markdown buffer content first\n        remaining_markdown = self._flush_markdown_buffer()\n        if remaining_markdown:\n            # Add to chunker for proper sentence handling\n            sentences = self._chunker.add_token(remaining_markdown)\n            for sentence in sentences:\n                await self._synthesize_sentence(sentence)\n\n        # Flush remaining text from chunker\n        final_text = self._chunker.flush()\n        if final_text:\n            await self._synthesize_sentence(final_text)\n\n        # Wait for any pending synthesis tasks\n        if self._synthesis_tasks:\n            await asyncio.gather(*self._synthesis_tasks, return_exceptions=True)\n\n        # Send final chunk marker\n        final_chunk = AudioChunk(\n            data=b\"\",\n            format=\"pcm16\",\n            is_final=True,\n            sentence_index=self._sentence_index,\n        )\n        await self._on_audio_chunk(final_chunk)\n\n        self._state = TalkerState.IDLE\n\n        logger.info(\n            \"TTS session complete\",\n            extra={\n                \"sentences\": self._metrics.sentences_processed,\n                \"chars\": self._metrics.total_chars_synthesized,\n                \"audio_bytes\": self._metrics.total_audio_bytes,\n                \"first_audio_ms\": self._metrics.first_audio_latency_ms,\n            },\n        )\n\n        return self._metrics\n\n    async def cancel(self) -> None:\n        \"\"\"\n        Cancel the session (for barge-in).\n\n        Stops all synthesis and clears pending audio.\n        \"\"\"\n        self._state = TalkerState.CANCELLED\n        self._metrics.cancelled = True\n\n        # Cancel pending synthesis tasks\n        for task in self._synthesis_tasks:\n            if not task.done():\n                task.cancel()\n\n        logger.info(\"TTS session cancelled (barge-in)\")\n\n    def get_metrics(self) -> TalkerMetrics:\n        \"\"\"Get current session metrics.\"\"\"\n        return self._metrics\n\n\n# Global service instance\ntalker_service = TalkerService()\n"
}
