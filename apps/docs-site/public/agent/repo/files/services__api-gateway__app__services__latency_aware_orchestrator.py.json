{
  "path": "services/api-gateway/app/services/latency_aware_orchestrator.py",
  "language": "python",
  "size": 20276,
  "last_modified": "2025-12-04T18:47:50.955Z",
  "lines": 516,
  "content": "\"\"\"\nLatency-Aware Voice Orchestrator\nProvides voice pipeline processing with latency budgets and adaptive degradation.\n\nPart of Voice Mode Enhancement Plan v4.1\nReference: /home/asimo/.claude/plans/noble-bubbling-trinket.md#performance-safeguards\n\"\"\"\n\nimport asyncio\nimport logging\nimport time\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\n\nfrom pydantic import BaseModel\n\nlogger = logging.getLogger(__name__)\n\n\nclass DegradationType(str, Enum):\n    \"\"\"Types of degradation that can be applied.\"\"\"\n\n    LANGUAGE_DETECTION_SKIPPED = \"language_detection_skipped\"\n    LANGUAGE_DETECTION_BUDGET_EXCEEDED = \"language_detection_budget_exceeded\"\n    TRANSLATION_SKIPPED = \"translation_skipped\"\n    TRANSLATION_BUDGET_EXCEEDED = \"translation_budget_exceeded\"\n    TRANSLATION_FAILED = \"translation_failed\"\n    RAG_LIMITED_TO_1 = \"rag_limited_to_1\"\n    RAG_LIMITED_TO_3 = \"rag_limited_to_3\"\n    RAG_RETRIEVAL_FAILED = \"rag_retrieval_failed\"\n    LLM_CONTEXT_SHORTENED = \"llm_context_shortened\"\n    TTS_USED_CACHED_GREETING = \"tts_used_cached_greeting\"\n    PARALLEL_STT_REDUCED = \"parallel_stt_reduced\"\n\n\nclass TranslationFailedError(Exception):\n    \"\"\"Exception raised when translation fails or returns a failed result.\"\"\"\n\n    pass\n\n\n@dataclass\nclass LatencyBudget:\n    \"\"\"Latency budget configuration per stage.\"\"\"\n\n    audio_capture_ms: int = 50\n    stt_ms: int = 200\n    language_detection_ms: int = 50\n    translation_ms: int = 200\n    rag_ms: int = 300\n    llm_first_token_ms: int = 300\n    tts_first_chunk_ms: int = 150\n    total_budget_ms: int = 700\n\n\n@dataclass\nclass StageMetrics:\n    \"\"\"Metrics for a single processing stage.\"\"\"\n\n    stage_name: str\n    start_time: float\n    end_time: float\n    budget_ms: int\n    actual_ms: float\n    exceeded: bool = False\n    degradation_applied: Optional[DegradationType] = None\n\n    @property\n    def remaining_budget_ms(self) -> float:\n        return max(0, self.budget_ms - self.actual_ms)\n\n\nclass VoiceProcessingResult(BaseModel):\n    \"\"\"Result of voice processing pipeline.\"\"\"\n\n    transcript: str\n    response: str\n    audio_data: Optional[bytes] = None\n    detected_language: str = \"en\"\n    response_language: str = \"en\"\n    total_latency_ms: float\n    stage_latencies: Dict[str, float] = {}\n    degradation_applied: List[str] = []\n    warnings: List[str] = []\n\n\nclass LatencyAwareVoiceOrchestrator:\n    \"\"\"\n    Voice pipeline orchestrator with latency budgets and adaptive degradation.\n\n    Ensures voice interactions remain responsive by:\n    1. Tracking latency at each processing stage\n    2. Applying graceful degradation when budgets are exceeded\n    3. Reporting degradation events to the frontend\n    4. Maintaining metrics for monitoring\n\n    Latency Budgets Per Stage:\n    | Stage              | Max Latency | Action on Exceed           |\n    |--------------------|-------------|----------------------------|\n    | Audio capture      | 50ms        | Log warning                |\n    | STT (primary)      | 200ms       | Use cached partial         |\n    | Language detection | 50ms        | Default to user language   |\n    | Translation        | 200ms       | Skip translation           |\n    | RAG retrieval      | 300ms       | Return top-1 only          |\n    | LLM first token    | 300ms       | Use shorter context        |\n    | TTS first chunk    | 150ms       | Use cached greeting        |\n    | **Total E2E**      | **700ms**   | **Degrade features**       |\n    \"\"\"\n\n    def __init__(\n        self,\n        budget: Optional[LatencyBudget] = None,\n        stt_service=None,\n        language_detector=None,\n        translator=None,\n        rag_service=None,\n        llm_service=None,\n        tts_service=None,\n    ):\n        self.budget = budget or LatencyBudget()\n        self.stt = stt_service\n        self.language_detector = language_detector\n        self.translator = translator\n        self.rag = rag_service\n        self.llm = llm_service\n        self.tts = tts_service\n\n        # Metrics collection\n        self.metrics = {\n            \"total_requests\": 0,\n            \"degraded_requests\": 0,\n            \"avg_latency_ms\": 0.0,\n            \"degradation_counts\": {},\n        }\n\n    async def process_with_budgets(\n        self,\n        audio_data: bytes,\n        user_language: Optional[str] = None,\n        session_id: Optional[str] = None,\n    ) -> VoiceProcessingResult:\n        \"\"\"\n        Process voice input with latency budgets and adaptive degradation.\n\n        Args:\n            audio_data: Raw audio bytes from client\n            user_language: User's preferred language (fallback for detection)\n            session_id: Session ID for context\n\n        Returns:\n            VoiceProcessingResult with response and metrics\n        \"\"\"\n        start_time = time.monotonic()\n        remaining_budget = self.budget.total_budget_ms\n        degradation_applied: List[DegradationType] = []\n        stage_latencies: Dict[str, float] = {}\n        warnings: List[str] = []\n\n        self.metrics[\"total_requests\"] += 1\n\n        try:\n            # Stage 1: STT\n            stt_start = time.monotonic()\n            transcript = await self._run_stt_with_timeout(audio_data)\n            stt_latency = (time.monotonic() - stt_start) * 1000\n            stage_latencies[\"stt\"] = stt_latency\n            remaining_budget -= stt_latency\n\n            if not transcript:\n                return VoiceProcessingResult(\n                    transcript=\"\",\n                    response=\"I didn't catch that. Could you please repeat?\",\n                    detected_language=user_language or \"en\",\n                    response_language=user_language or \"en\",\n                    total_latency_ms=(time.monotonic() - start_time) * 1000,\n                    stage_latencies=stage_latencies,\n                    warnings=[\"No speech detected\"],\n                )\n\n            # Stage 2: Language detection (with budget check)\n            lang_start = time.monotonic()\n            if remaining_budget > self.budget.language_detection_ms:\n                try:\n                    detected_lang = await asyncio.wait_for(\n                        self._detect_language(transcript), timeout=self.budget.language_detection_ms / 1000\n                    )\n                except asyncio.TimeoutError:\n                    detected_lang = user_language or \"en\"\n                    degradation_applied.append(DegradationType.LANGUAGE_DETECTION_SKIPPED)\n                    warnings.append(\"Language detection timed out\")\n            else:\n                detected_lang = user_language or \"en\"\n                degradation_applied.append(DegradationType.LANGUAGE_DETECTION_BUDGET_EXCEEDED)\n\n            stage_latencies[\"language_detection\"] = (time.monotonic() - lang_start) * 1000\n            remaining_budget -= stage_latencies[\"language_detection\"]\n\n            # Stage 3: Translation (skip if budget tight or same language)\n            english_query = transcript\n            trans_start = time.monotonic()\n\n            if detected_lang != \"en\":\n                translation_budget_available = remaining_budget > (\n                    self.budget.translation_ms\n                    + self.budget.rag_ms\n                    + self.budget.llm_first_token_ms\n                    + self.budget.tts_first_chunk_ms\n                )\n\n                if translation_budget_available:\n                    try:\n                        english_query = await asyncio.wait_for(\n                            self._translate(transcript, detected_lang, \"en\"),\n                            timeout=self.budget.translation_ms / 1000,\n                        )\n                    except asyncio.TimeoutError:\n                        english_query = transcript  # Use original\n                        degradation_applied.append(DegradationType.TRANSLATION_SKIPPED)\n                        warnings.append(\"Translation timed out, using original query\")\n                    except TranslationFailedError as e:\n                        # Translation service returned failed=True or raised error\n                        english_query = transcript  # Fallback to original query\n                        degradation_applied.append(DegradationType.TRANSLATION_FAILED)\n                        warnings.append(f\"Translation failed (graceful degradation): {str(e)}\")\n                        logger.warning(\n                            f\"Translation degradation applied for {detected_lang}->en: {e}\"\n                        )\n                    except Exception as e:\n                        # Unexpected error - still degrade gracefully\n                        english_query = transcript\n                        degradation_applied.append(DegradationType.TRANSLATION_FAILED)\n                        warnings.append(f\"Translation failed (unexpected): {str(e)}\")\n                        logger.error(f\"Unexpected translation error: {e}\", exc_info=True)\n                else:\n                    degradation_applied.append(DegradationType.TRANSLATION_BUDGET_EXCEEDED)\n                    warnings.append(\"Translation skipped due to latency budget\")\n\n            stage_latencies[\"translation\"] = (time.monotonic() - trans_start) * 1000\n            remaining_budget -= stage_latencies[\"translation\"]\n\n            # Stage 4: RAG retrieval (limit results if budget tight)\n            rag_start = time.monotonic()\n            rag_limit = self._determine_rag_limit(remaining_budget)\n\n            if rag_limit < 5:\n                if rag_limit == 1:\n                    degradation_applied.append(DegradationType.RAG_LIMITED_TO_1)\n                else:\n                    degradation_applied.append(DegradationType.RAG_LIMITED_TO_3)\n                warnings.append(f\"RAG limited to {rag_limit} results\")\n\n            try:\n                rag_results = await asyncio.wait_for(\n                    self._retrieve_context(english_query, limit=rag_limit), timeout=self.budget.rag_ms / 1000\n                )\n            except asyncio.TimeoutError:\n                rag_results = []\n                degradation_applied.append(DegradationType.RAG_RETRIEVAL_FAILED)\n                warnings.append(\"RAG retrieval timed out\")\n            except Exception as e:\n                rag_results = []\n                degradation_applied.append(DegradationType.RAG_RETRIEVAL_FAILED)\n                warnings.append(f\"RAG retrieval failed: {str(e)}\")\n\n            stage_latencies[\"rag\"] = (time.monotonic() - rag_start) * 1000\n            remaining_budget -= stage_latencies[\"rag\"]\n\n            # Stage 5: LLM generation\n            llm_start = time.monotonic()\n            response_language = detected_lang\n\n            # Shorten context if budget is very tight\n            context = rag_results\n            if remaining_budget < 400 and len(rag_results) > 2:\n                context = rag_results[:2]\n                degradation_applied.append(DegradationType.LLM_CONTEXT_SHORTENED)\n                warnings.append(\"LLM context shortened due to latency budget\")\n\n            try:\n                response = await self._generate_response(\n                    query=transcript, context=context, response_language=response_language\n                )\n            except Exception as e:\n                logger.error(f\"LLM generation failed: {e}\")\n                response = self._get_fallback_response(response_language)\n                warnings.append(f\"LLM generation failed: {str(e)}\")\n\n            stage_latencies[\"llm\"] = (time.monotonic() - llm_start) * 1000\n            remaining_budget -= stage_latencies[\"llm\"]\n\n            # Stage 6: TTS (if requested)\n            audio_result = None\n            tts_start = time.monotonic()\n\n            if self.tts:\n                try:\n                    audio_result = await asyncio.wait_for(\n                        self._synthesize_speech(response, response_language),\n                        timeout=self.budget.tts_first_chunk_ms / 1000,\n                    )\n                except asyncio.TimeoutError:\n                    degradation_applied.append(DegradationType.TTS_USED_CACHED_GREETING)\n                    warnings.append(\"TTS timed out, using cached response\")\n                except Exception as e:\n                    warnings.append(f\"TTS failed: {str(e)}\")\n\n            stage_latencies[\"tts\"] = (time.monotonic() - tts_start) * 1000\n\n            # Calculate total latency\n            total_latency = (time.monotonic() - start_time) * 1000\n\n            # Update metrics\n            if degradation_applied:\n                self.metrics[\"degraded_requests\"] += 1\n                for deg in degradation_applied:\n                    self.metrics[\"degradation_counts\"][deg.value] = (\n                        self.metrics[\"degradation_counts\"].get(deg.value, 0) + 1\n                    )\n\n            # Running average\n            total_reqs = self.metrics[\"total_requests\"]\n            self.metrics[\"avg_latency_ms\"] = (\n                self.metrics[\"avg_latency_ms\"] * (total_reqs - 1) + total_latency\n            ) / total_reqs\n\n            return VoiceProcessingResult(\n                transcript=transcript,\n                response=response,\n                audio_data=audio_result,\n                detected_language=detected_lang,\n                response_language=response_language,\n                total_latency_ms=total_latency,\n                stage_latencies=stage_latencies,\n                degradation_applied=[d.value for d in degradation_applied],\n                warnings=warnings,\n            )\n\n        except Exception as e:\n            logger.error(f\"Voice processing failed: {e}\", exc_info=True)\n            total_latency = (time.monotonic() - start_time) * 1000\n            return VoiceProcessingResult(\n                transcript=\"\",\n                response=\"I'm sorry, I encountered an error. Please try again.\",\n                detected_language=user_language or \"en\",\n                response_language=user_language or \"en\",\n                total_latency_ms=total_latency,\n                stage_latencies=stage_latencies,\n                degradation_applied=[d.value for d in degradation_applied],\n                warnings=[f\"Processing error: {str(e)}\"],\n            )\n\n    def _determine_rag_limit(self, remaining_budget_ms: float) -> int:\n        \"\"\"Determine RAG result limit based on remaining budget.\"\"\"\n        if remaining_budget_ms > 600:\n            return 5\n        elif remaining_budget_ms > 400:\n            return 3\n        else:\n            return 1\n\n    async def _run_stt_with_timeout(self, audio_data: bytes) -> str:\n        \"\"\"Run STT with timeout.\"\"\"\n        if not self.stt:\n            logger.warning(\"STT service not configured\")\n            return \"\"\n\n        try:\n            return await asyncio.wait_for(self.stt.transcribe(audio_data), timeout=self.budget.stt_ms / 1000)\n        except asyncio.TimeoutError:\n            logger.warning(\"STT timed out\")\n            return \"\"\n        except Exception as e:\n            logger.error(f\"STT failed: {e}\")\n            return \"\"\n\n    async def _detect_language(self, text: str) -> str:\n        \"\"\"Detect language of text.\"\"\"\n        if not self.language_detector:\n            return \"en\"\n\n        try:\n            return await self.language_detector.detect(text)\n        except Exception as e:\n            logger.warning(f\"Language detection failed: {e}\")\n            return \"en\"\n\n    async def _translate(self, text: str, source: str, target: str) -> str:\n        \"\"\"\n        Translate text with proper failure handling.\n\n        Args:\n            text: Text to translate\n            source: Source language code\n            target: Target language code\n\n        Returns:\n            Translated text\n\n        Raises:\n            TranslationFailedError: When translation fails or result.failed is True\n        \"\"\"\n        if not self.translator:\n            return text\n\n        try:\n            result = await self.translator.translate(text, source, target)\n\n            # Check for failed flag in result (graceful degradation marker)\n            if hasattr(result, \"failed\") and result.failed:\n                error_msg = getattr(result, \"error_message\", \"Translation failed\")\n                logger.warning(f\"Translation marked as failed: {error_msg}\")\n                raise TranslationFailedError(error_msg)\n\n            return result.text if hasattr(result, \"text\") else str(result)\n        except TranslationFailedError:\n            raise  # Re-raise our custom exception\n        except Exception as e:\n            logger.error(f\"Translation failed: {e}\")\n            raise TranslationFailedError(str(e))\n\n    async def _retrieve_context(self, query: str, limit: int = 5) -> List[Dict]:\n        \"\"\"Retrieve RAG context.\"\"\"\n        if not self.rag:\n            return []\n\n        try:\n            results = await self.rag.search(query, top_k=limit)\n            return results if results else []\n        except Exception as e:\n            logger.error(f\"RAG retrieval failed: {e}\")\n            raise\n\n    async def _generate_response(self, query: str, context: List[Dict], response_language: str = \"en\") -> str:\n        \"\"\"Generate LLM response.\"\"\"\n        if not self.llm:\n            return self._get_fallback_response(response_language)\n\n        # Build context string\n        context_str = \"\\n\".join([str(c.get(\"content\", c)) if isinstance(c, dict) else str(c) for c in context[:5]])\n\n        from app.services.llm_client import LLMRequest\n\n        response = await self.llm.generate(\n            LLMRequest(\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": f\"You are a helpful medical assistant. Respond in {response_language}.\",\n                    },\n                    {\"role\": \"user\", \"content\": f\"Context: {context_str}\\n\\nQuestion: {query}\"},\n                ],\n                max_tokens=512,\n                temperature=0.7,\n            )\n        )\n        return response.content\n\n    async def _synthesize_speech(self, text: str, language: str = \"en\") -> Optional[bytes]:\n        \"\"\"Synthesize speech from text.\"\"\"\n        if not self.tts:\n            return None\n\n        try:\n            return await self.tts.synthesize(text, language=language)\n        except Exception as e:\n            logger.error(f\"TTS synthesis failed: {e}\")\n            return None\n\n    def _get_fallback_response(self, language: str) -> str:\n        \"\"\"Get a fallback response for the given language.\"\"\"\n        fallbacks = {\n            \"en\": \"I apologize, but I'm unable to process your request at the moment.\",\n            \"es\": \"Lo siento, no puedo procesar su solicitud en este momento.\",\n            \"fr\": \"Je m'excuse, je ne peux pas traiter votre demande pour le moment.\",\n            \"de\": \"Es tut mir leid, ich kann Ihre Anfrage im Moment nicht bearbeiten.\",\n            \"ar\": \"عذراً، لا أستطيع معالجة طلبك في الوقت الحالي.\",\n            \"zh\": \"抱歉，我目前无法处理您的请求。\",\n        }\n        return fallbacks.get(language, fallbacks[\"en\"])\n\n    def get_metrics(self) -> Dict[str, Any]:\n        \"\"\"Get current orchestrator metrics.\"\"\"\n        return {\n            **self.metrics,\n            \"degradation_rate\": (\n                self.metrics[\"degraded_requests\"] / self.metrics[\"total_requests\"]\n                if self.metrics[\"total_requests\"] > 0\n                else 0\n            ),\n        }\n\n    async def notify_degradation(self, session_id: str, degradations: List[DegradationType], latency_ms: float) -> None:\n        \"\"\"\n        Notify frontend about applied degradations.\n\n        This can be called to send a WebSocket message or update a status endpoint.\n        \"\"\"\n        logger.info(\n            f\"Degradation notification for session {session_id}: \"\n            f\"{[d.value for d in degradations]}, latency={latency_ms:.1f}ms\"\n        )\n        # TODO: Implement WebSocket notification\n\n\n# Singleton instance\n_orchestrator: Optional[LatencyAwareVoiceOrchestrator] = None\n\n\ndef get_latency_aware_orchestrator() -> LatencyAwareVoiceOrchestrator:\n    \"\"\"Get or create orchestrator instance.\"\"\"\n    global _orchestrator\n    if _orchestrator is None:\n        _orchestrator = LatencyAwareVoiceOrchestrator()\n    return _orchestrator\n"
}
