{
  "path": "services/api-gateway/app/services/audio_processing_service.py",
  "language": "python",
  "size": 14955,
  "last_modified": "2025-12-05T03:03:38.724Z",
  "lines": 453,
  "content": "\"\"\"\nAudio Processing Service - AEC, AGC, and Noise Suppression\n\nVoice Mode v4 - Phase 1 Foundation\n\nProvides unified audio preprocessing for the voice pipeline:\n- Acoustic Echo Cancellation (AEC)\n- Automatic Gain Control (AGC)\n- Noise Suppression (NS)\n\nUses WebRTC Audio Processing or RNNoise for noise suppression,\nwith browser-side processing where available.\n\"\"\"\n\nimport asyncio\nimport logging\nimport math\nimport struct\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, Callable, Dict, List, Optional, Tuple\n\nimport numpy as np\n\nlogger = logging.getLogger(__name__)\n\n\nclass ProcessingMode(Enum):\n    \"\"\"Audio processing mode selection.\"\"\"\n    BROWSER = \"browser\"  # Client-side WebRTC processing\n    SERVER = \"server\"  # Server-side processing\n    ADAPTIVE = \"adaptive\"  # Choose based on client capabilities\n    DISABLED = \"disabled\"  # No processing\n\n\nclass NoiseSuppressionModel(Enum):\n    \"\"\"Noise suppression model options.\"\"\"\n    WEBRTC = \"webrtc\"  # WebRTC noise suppression\n    RNNOISE = \"rnnoise\"  # RNNoise deep learning model\n    SPECTRAL = \"spectral\"  # Simple spectral subtraction\n    NONE = \"none\"\n\n\n@dataclass\nclass AudioProcessingConfig:\n    \"\"\"Configuration for audio processing pipeline.\"\"\"\n    # Noise suppression\n    noise_suppression_enabled: bool = True\n    noise_suppression_model: NoiseSuppressionModel = NoiseSuppressionModel.SPECTRAL\n    ns_aggressiveness: int = 2  # 0-3, higher = more aggressive\n    ns_threshold_db: float = -40.0  # SNR threshold for activation\n\n    # Echo cancellation\n    echo_cancellation_enabled: bool = True\n    aec_tail_length_ms: int = 128  # Echo tail length\n    aec_nlp_enabled: bool = True  # Non-linear processing\n\n    # Automatic gain control\n    automatic_gain_control_enabled: bool = True\n    agc_target_level_dbfs: float = -18.0  # Target output level\n    agc_compression_gain_db: float = 9.0  # Max compression\n    agc_limiter_enabled: bool = True\n\n    # Processing mode\n    processing_mode: ProcessingMode = ProcessingMode.ADAPTIVE\n\n    # Sample rates\n    input_sample_rate: int = 16000\n    output_sample_rate: int = 16000\n\n    # Frame configuration\n    frame_duration_ms: int = 20  # 20ms frames\n\n    # Quality settings\n    enable_high_pass_filter: bool = True\n    high_pass_cutoff_hz: float = 80.0  # Remove sub-bass rumble\n\n\n@dataclass\nclass AudioContext:\n    \"\"\"Context for audio processing (playback state, etc.).\"\"\"\n    playback_buffer: Optional[bytes] = None\n    playback_active: bool = False\n    noise_profile: Optional[np.ndarray] = None\n    gain_history: List[float] = field(default_factory=list)\n    last_speech_time: Optional[datetime] = None\n\n\n@dataclass\nclass ProcessingMetrics:\n    \"\"\"Metrics for audio processing performance.\"\"\"\n    frames_processed: int = 0\n    noise_frames_detected: int = 0\n    echo_cancelled_frames: int = 0\n    gain_adjusted_frames: int = 0\n    processing_time_ms_avg: float = 0.0\n    snr_estimate_db: float = 0.0\n\n\nclass AudioProcessingService:\n    \"\"\"\n    Unified audio preprocessing service for voice pipeline.\n\n    Handles AEC, AGC, and noise suppression with configurable modes.\n    \"\"\"\n\n    def __init__(self, config: Optional[AudioProcessingConfig] = None):\n        self.config = config or AudioProcessingConfig()\n        self._initialized = False\n        self._metrics = ProcessingMetrics()\n\n        # Processing components (lazy-loaded)\n        self._noise_profile: Optional[np.ndarray] = None\n        self._noise_floor_db: float = -60.0\n        self._gain_smoothing: float = 0.95\n        self._current_gain: float = 1.0\n\n        # High-pass filter state\n        self._hp_state: float = 0.0\n\n        # Callbacks\n        self._on_metrics_update: Optional[Callable[[ProcessingMetrics], None]] = None\n\n    async def initialize(self) -> None:\n        \"\"\"Initialize audio processing components.\"\"\"\n        if self._initialized:\n            return\n\n        logger.info(\n            \"Initializing AudioProcessingService\",\n            extra={\n                \"mode\": self.config.processing_mode.value,\n                \"ns_enabled\": self.config.noise_suppression_enabled,\n                \"aec_enabled\": self.config.echo_cancellation_enabled,\n                \"agc_enabled\": self.config.automatic_gain_control_enabled,\n            }\n        )\n\n        # Pre-compute filter coefficients\n        self._compute_filter_coefficients()\n\n        self._initialized = True\n\n    def _compute_filter_coefficients(self) -> None:\n        \"\"\"Pre-compute filter coefficients for efficiency.\"\"\"\n        # High-pass filter coefficient (simple first-order)\n        rc = 1.0 / (2.0 * math.pi * self.config.high_pass_cutoff_hz)\n        dt = 1.0 / self.config.input_sample_rate\n        self._hp_alpha = rc / (rc + dt)\n\n    async def process_frame(\n        self,\n        audio_frame: bytes,\n        context: Optional[AudioContext] = None\n    ) -> bytes:\n        \"\"\"\n        Process a single audio frame through the pipeline.\n\n        Order: High-pass -> AEC -> AGC -> NS\n\n        Args:\n            audio_frame: Raw PCM16 audio bytes\n            context: Optional context with playback state\n\n        Returns:\n            Processed PCM16 audio bytes\n        \"\"\"\n        if not self._initialized:\n            await self.initialize()\n\n        start_time = datetime.now(timezone.utc)\n        context = context or AudioContext()\n\n        # Convert to numpy array\n        samples = self._bytes_to_samples(audio_frame)\n\n        # 1. High-pass filter (remove DC offset and rumble)\n        if self.config.enable_high_pass_filter:\n            samples = self._apply_high_pass_filter(samples)\n\n        # 2. Echo cancellation\n        if self.config.echo_cancellation_enabled and context.playback_active:\n            samples = await self._apply_echo_cancellation(samples, context)\n\n        # 3. Automatic gain control\n        if self.config.automatic_gain_control_enabled:\n            samples = self._apply_agc(samples)\n\n        # 4. Noise suppression\n        if self.config.noise_suppression_enabled:\n            snr = self._estimate_snr(samples)\n            if snr < self.config.ns_threshold_db:\n                samples = self._apply_noise_suppression(samples)\n                self._metrics.noise_frames_detected += 1\n\n        # Update metrics\n        self._metrics.frames_processed += 1\n        elapsed_ms = (datetime.now(timezone.utc) - start_time).total_seconds() * 1000\n        self._metrics.processing_time_ms_avg = (\n            self._metrics.processing_time_ms_avg * 0.95 + elapsed_ms * 0.05\n        )\n\n        return self._samples_to_bytes(samples)\n\n    def _bytes_to_samples(self, audio_bytes: bytes) -> np.ndarray:\n        \"\"\"Convert PCM16 bytes to float samples.\"\"\"\n        samples = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32)\n        return samples / 32768.0  # Normalize to [-1, 1]\n\n    def _samples_to_bytes(self, samples: np.ndarray) -> bytes:\n        \"\"\"Convert float samples back to PCM16 bytes.\"\"\"\n        # Clip and convert\n        clipped = np.clip(samples * 32768.0, -32768, 32767)\n        return clipped.astype(np.int16).tobytes()\n\n    def _apply_high_pass_filter(self, samples: np.ndarray) -> np.ndarray:\n        \"\"\"Apply first-order high-pass filter.\"\"\"\n        filtered = np.zeros_like(samples)\n        prev_input = 0.0\n        prev_output = self._hp_state\n\n        for i, sample in enumerate(samples):\n            filtered[i] = self._hp_alpha * (prev_output + sample - prev_input)\n            prev_input = sample\n            prev_output = filtered[i]\n\n        self._hp_state = prev_output\n        return filtered\n\n    async def _apply_echo_cancellation(\n        self,\n        samples: np.ndarray,\n        context: AudioContext\n    ) -> np.ndarray:\n        \"\"\"\n        Apply acoustic echo cancellation.\n\n        Simple cross-correlation based AEC for speaker playback removal.\n        \"\"\"\n        if not context.playback_buffer:\n            return samples\n\n        # Convert playback to samples\n        playback = self._bytes_to_samples(context.playback_buffer)\n\n        if len(playback) < len(samples):\n            return samples\n\n        # Compute cross-correlation to find echo delay\n        correlation = np.correlate(samples, playback[:len(samples)], mode='same')\n        delay_idx = np.argmax(np.abs(correlation))\n\n        # Estimate echo coefficient\n        echo_coef = correlation[delay_idx] / (np.sum(playback[:len(samples)]**2) + 1e-10)\n        echo_coef = np.clip(echo_coef, -1.0, 1.0)\n\n        # Subtract estimated echo\n        if abs(echo_coef) > 0.1:  # Only if significant echo detected\n            echo_estimate = echo_coef * playback[:len(samples)]\n            samples = samples - echo_estimate\n            self._metrics.echo_cancelled_frames += 1\n\n        return samples\n\n    def _apply_agc(self, samples: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Apply automatic gain control.\n\n        Maintains consistent output level with smooth gain transitions.\n        \"\"\"\n        # Compute RMS energy\n        rms = np.sqrt(np.mean(samples**2) + 1e-10)\n        rms_db = 20 * math.log10(rms + 1e-10)\n\n        # Target level\n        target_rms = 10 ** (self.config.agc_target_level_dbfs / 20)\n\n        # Compute desired gain\n        desired_gain = target_rms / (rms + 1e-10)\n\n        # Apply compression limit\n        max_gain = 10 ** (self.config.agc_compression_gain_db / 20)\n        desired_gain = min(desired_gain, max_gain)\n\n        # Smooth gain transition\n        self._current_gain = (\n            self._gain_smoothing * self._current_gain +\n            (1 - self._gain_smoothing) * desired_gain\n        )\n\n        # Apply gain\n        output = samples * self._current_gain\n\n        # Apply limiter\n        if self.config.agc_limiter_enabled:\n            output = np.tanh(output)  # Soft limiting\n\n        self._metrics.gain_adjusted_frames += 1\n        return output\n\n    def _apply_noise_suppression(self, samples: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Apply noise suppression using spectral subtraction.\n\n        For production, consider using RNNoise or WebRTC NS.\n        \"\"\"\n        # FFT-based spectral subtraction\n        n_fft = 512\n        hop = n_fft // 4\n\n        # Pad if needed\n        if len(samples) < n_fft:\n            samples = np.pad(samples, (0, n_fft - len(samples)))\n\n        # STFT\n        window = np.hanning(n_fft)\n        n_frames = (len(samples) - n_fft) // hop + 1\n\n        output = np.zeros_like(samples)\n\n        for i in range(n_frames):\n            start = i * hop\n            frame = samples[start:start + n_fft] * window\n            spectrum = np.fft.rfft(frame)\n            magnitude = np.abs(spectrum)\n            phase = np.angle(spectrum)\n\n            # Estimate noise floor from quiet regions\n            if self._noise_profile is None:\n                self._noise_profile = magnitude * 0.1\n            else:\n                # Update noise profile during quiet periods\n                frame_energy = np.mean(magnitude**2)\n                if frame_energy < 0.01:  # Quiet frame\n                    self._noise_profile = 0.9 * self._noise_profile + 0.1 * magnitude\n\n            # Spectral subtraction\n            alpha = 2.0  # Over-subtraction factor\n            beta = 0.01  # Spectral floor\n            subtracted = magnitude - alpha * self._noise_profile\n            subtracted = np.maximum(subtracted, beta * magnitude)\n\n            # Reconstruct\n            clean_spectrum = subtracted * np.exp(1j * phase)\n            clean_frame = np.fft.irfft(clean_spectrum)\n\n            # Overlap-add\n            output[start:start + n_fft] += clean_frame * window\n\n        # Normalize overlap-add\n        output = output / 1.5  # Approximate normalization\n\n        return output[:len(samples)]\n\n    def _estimate_snr(self, samples: np.ndarray) -> float:\n        \"\"\"Estimate signal-to-noise ratio in dB.\"\"\"\n        rms = np.sqrt(np.mean(samples**2) + 1e-10)\n        rms_db = 20 * math.log10(rms)\n\n        # SNR estimate relative to noise floor\n        snr = rms_db - self._noise_floor_db\n        self._metrics.snr_estimate_db = snr\n\n        return snr\n\n    async def calibrate_noise_floor(\n        self,\n        audio_samples: List[bytes],\n        duration_ms: int = 3000\n    ) -> float:\n        \"\"\"\n        Calibrate noise floor from ambient audio samples.\n\n        Args:\n            audio_samples: List of audio frames to analyze\n            duration_ms: Total duration of samples\n\n        Returns:\n            Estimated noise floor in dB\n        \"\"\"\n        all_samples = np.concatenate([\n            self._bytes_to_samples(frame) for frame in audio_samples\n        ])\n\n        # Use lower percentile as noise floor estimate\n        frame_energies = []\n        frame_size = int(self.config.input_sample_rate * 0.02)  # 20ms frames\n\n        for i in range(0, len(all_samples) - frame_size, frame_size):\n            frame = all_samples[i:i + frame_size]\n            energy = np.mean(frame**2)\n            frame_energies.append(energy)\n\n        # 10th percentile as noise floor\n        noise_energy = np.percentile(frame_energies, 10)\n        self._noise_floor_db = 10 * math.log10(noise_energy + 1e-10)\n\n        logger.info(f\"Calibrated noise floor: {self._noise_floor_db:.1f} dB\")\n        return self._noise_floor_db\n\n    def get_metrics(self) -> ProcessingMetrics:\n        \"\"\"Get current processing metrics.\"\"\"\n        return self._metrics\n\n    def reset_metrics(self) -> None:\n        \"\"\"Reset processing metrics.\"\"\"\n        self._metrics = ProcessingMetrics()\n\n    def on_metrics_update(self, callback: Callable[[ProcessingMetrics], None]) -> None:\n        \"\"\"Register callback for metrics updates.\"\"\"\n        self._on_metrics_update = callback\n\n    def update_config(self, **kwargs) -> None:\n        \"\"\"Update configuration parameters.\"\"\"\n        for key, value in kwargs.items():\n            if hasattr(self.config, key):\n                setattr(self.config, key, value)\n\n        # Recompute filter coefficients if needed\n        if 'high_pass_cutoff_hz' in kwargs or 'input_sample_rate' in kwargs:\n            self._compute_filter_coefficients()\n\n\n# Singleton instance\n_audio_processing_service: Optional[AudioProcessingService] = None\n\n\ndef get_audio_processing_service() -> AudioProcessingService:\n    \"\"\"Get or create the singleton AudioProcessingService instance.\"\"\"\n    global _audio_processing_service\n    if _audio_processing_service is None:\n        _audio_processing_service = AudioProcessingService()\n    return _audio_processing_service\n\n\nasync def process_audio_frame(\n    audio_frame: bytes,\n    context: Optional[AudioContext] = None\n) -> bytes:\n    \"\"\"\n    Convenience function to process a single audio frame.\n\n    Args:\n        audio_frame: Raw PCM16 audio bytes\n        context: Optional context with playback state\n\n    Returns:\n        Processed PCM16 audio bytes\n    \"\"\"\n    service = get_audio_processing_service()\n    return await service.process_frame(audio_frame, context)\n"
}
