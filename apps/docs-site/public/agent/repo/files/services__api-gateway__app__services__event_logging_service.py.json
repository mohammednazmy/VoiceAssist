{
  "path": "services/api-gateway/app/services/event_logging_service.py",
  "language": "python",
  "size": 12599,
  "last_modified": "2025-12-05T03:07:13.133Z",
  "lines": 417,
  "content": "\"\"\"\nEvent Logging Service for structured session event capture.\n\nThis service provides:\n- Async event logging with batching\n- Event querying for inspection/replay\n- Background flush to avoid blocking main request flow\n\"\"\"\n\nimport asyncio\nimport uuid\nfrom collections import deque\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Optional\n\nfrom app.core.database import get_db\nfrom app.core.logging import get_logger\nfrom app.models.session_event import EventType, SessionEvent\nfrom sqlalchemy.orm import Session\n\nlogger = get_logger(__name__)\n\n\nclass EventLoggingService:\n    \"\"\"\n    Service for logging and querying session events.\n\n    Features:\n    - Buffered async logging to reduce DB pressure\n    - Periodic flush to ensure events are persisted\n    - Query interface for event inspection\n    \"\"\"\n\n    def __init__(self, buffer_size: int = 100, flush_interval_seconds: float = 5.0):\n        \"\"\"\n        Initialize the event logging service.\n\n        Args:\n            buffer_size: Max events to buffer before forcing a flush\n            flush_interval_seconds: Interval for periodic flushes\n        \"\"\"\n        self.buffer_size = buffer_size\n        self.flush_interval = flush_interval_seconds\n        self._buffer: deque = deque(maxlen=buffer_size * 2)  # Extra room\n        self._lock = asyncio.Lock()\n        self._flush_task: Optional[asyncio.Task] = None\n        self._running = False\n\n    async def start(self):\n        \"\"\"Start the background flush task.\"\"\"\n        if self._running:\n            return\n        self._running = True\n        self._flush_task = asyncio.create_task(self._periodic_flush())\n        logger.info(\"EventLoggingService started\")\n\n    async def stop(self):\n        \"\"\"Stop the service and flush remaining events.\"\"\"\n        self._running = False\n        if self._flush_task:\n            self._flush_task.cancel()\n            try:\n                await self._flush_task\n            except asyncio.CancelledError:\n                pass\n        # Final flush\n        await self._flush_buffer()\n        logger.info(\"EventLoggingService stopped\")\n\n    async def log_event(\n        self,\n        conversation_id: uuid.UUID,\n        event_type: EventType | str,\n        payload: Optional[Dict[str, Any]] = None,\n        session_id: Optional[str] = None,\n        branch_id: Optional[str] = None,\n        user_id: Optional[uuid.UUID] = None,\n        source: str = \"backend\",\n        trace_id: Optional[str] = None,\n    ) -> None:\n        \"\"\"\n        Log a session event asynchronously.\n\n        Events are buffered and flushed periodically or when buffer is full.\n\n        Args:\n            conversation_id: ID of the conversation\n            event_type: Type of event\n            payload: Event-specific data\n            session_id: Optional session identifier\n            branch_id: Optional branch identifier\n            user_id: Optional user identifier\n            source: Source of the event\n            trace_id: Optional trace ID for correlation\n        \"\"\"\n        event = SessionEvent.create(\n            conversation_id=conversation_id,\n            event_type=event_type,\n            payload=payload,\n            session_id=session_id,\n            branch_id=branch_id,\n            user_id=user_id,\n            source=source,\n            trace_id=trace_id,\n        )\n\n        async with self._lock:\n            self._buffer.append(event)\n\n            # Flush if buffer is getting full\n            if len(self._buffer) >= self.buffer_size:\n                asyncio.create_task(self._flush_buffer())\n\n    async def log_event_sync(\n        self,\n        db: Session,\n        conversation_id: uuid.UUID,\n        event_type: EventType | str,\n        payload: Optional[Dict[str, Any]] = None,\n        session_id: Optional[str] = None,\n        branch_id: Optional[str] = None,\n        user_id: Optional[uuid.UUID] = None,\n        source: str = \"backend\",\n        trace_id: Optional[str] = None,\n    ) -> SessionEvent:\n        \"\"\"\n        Log a session event synchronously (immediate DB write).\n\n        Use this for critical events that must be persisted immediately.\n\n        Args:\n            db: Database session\n            conversation_id: ID of the conversation\n            event_type: Type of event\n            payload: Event-specific data\n            session_id: Optional session identifier\n            branch_id: Optional branch identifier\n            user_id: Optional user identifier\n            source: Source of the event\n            trace_id: Optional trace ID for correlation\n\n        Returns:\n            The created SessionEvent\n        \"\"\"\n        event = SessionEvent.create(\n            conversation_id=conversation_id,\n            event_type=event_type,\n            payload=payload,\n            session_id=session_id,\n            branch_id=branch_id,\n            user_id=user_id,\n            source=source,\n            trace_id=trace_id,\n        )\n\n        db.add(event)\n        db.commit()\n        db.refresh(event)\n\n        return event\n\n    async def _flush_buffer(self) -> None:\n        \"\"\"Flush buffered events to the database.\"\"\"\n        async with self._lock:\n            if not self._buffer:\n                return\n\n            events = list(self._buffer)\n            self._buffer.clear()\n\n        if not events:\n            return\n\n        try:\n            # Get a database session\n            db_gen = get_db()\n            db = next(db_gen)\n            try:\n                for event in events:\n                    db.add(event)\n                db.commit()\n                logger.debug(f\"Flushed {len(events)} events to database\")\n            finally:\n                try:\n                    next(db_gen)\n                except StopIteration:\n                    pass\n        except Exception as e:\n            logger.error(f\"Error flushing events to database: {e}\")\n            # Re-add events to buffer for retry\n            async with self._lock:\n                for event in events:\n                    self._buffer.appendleft(event)\n\n    async def _periodic_flush(self) -> None:\n        \"\"\"Background task to periodically flush events.\"\"\"\n        while self._running:\n            await asyncio.sleep(self.flush_interval)\n            await self._flush_buffer()\n\n    # =========================================================================\n    # Query Methods\n    # =========================================================================\n\n    def get_events_for_conversation(\n        self,\n        db: Session,\n        conversation_id: uuid.UUID,\n        event_types: Optional[List[str]] = None,\n        since: Optional[datetime] = None,\n        limit: int = 100,\n        offset: int = 0,\n    ) -> List[SessionEvent]:\n        \"\"\"\n        Get events for a conversation.\n\n        Args:\n            db: Database session\n            conversation_id: ID of the conversation\n            event_types: Optional filter by event types\n            since: Optional filter for events after this time\n            limit: Max events to return\n            offset: Pagination offset\n\n        Returns:\n            List of SessionEvent objects\n        \"\"\"\n        query = db.query(SessionEvent).filter(SessionEvent.conversation_id == conversation_id)\n\n        if event_types:\n            query = query.filter(SessionEvent.event_type.in_(event_types))\n\n        if since:\n            query = query.filter(SessionEvent.created_at >= since)\n\n        return query.order_by(SessionEvent.created_at.asc()).offset(offset).limit(limit).all()\n\n    def get_events_for_session(\n        self,\n        db: Session,\n        session_id: str,\n        limit: int = 100,\n        offset: int = 0,\n    ) -> List[SessionEvent]:\n        \"\"\"\n        Get events for a specific session (e.g., WebSocket session).\n\n        Args:\n            db: Database session\n            session_id: Session identifier\n            limit: Max events to return\n            offset: Pagination offset\n\n        Returns:\n            List of SessionEvent objects\n        \"\"\"\n        return (\n            db.query(SessionEvent)\n            .filter(SessionEvent.session_id == session_id)\n            .order_by(SessionEvent.created_at.asc())\n            .offset(offset)\n            .limit(limit)\n            .all()\n        )\n\n    def get_error_events(\n        self,\n        db: Session,\n        conversation_id: uuid.UUID,\n        since: Optional[datetime] = None,\n        limit: int = 50,\n    ) -> List[SessionEvent]:\n        \"\"\"\n        Get error events for a conversation.\n\n        Args:\n            db: Database session\n            conversation_id: ID of the conversation\n            since: Optional filter for events after this time\n            limit: Max events to return\n\n        Returns:\n            List of error SessionEvent objects\n        \"\"\"\n        error_types = [\n            EventType.ERROR_WEBSOCKET.value,\n            EventType.ERROR_VOICE.value,\n            EventType.ERROR_API.value,\n            EventType.ERROR_BACKEND.value,\n        ]\n\n        query = db.query(SessionEvent).filter(\n            SessionEvent.conversation_id == conversation_id,\n            SessionEvent.event_type.in_(error_types),\n        )\n\n        if since:\n            query = query.filter(SessionEvent.created_at >= since)\n\n        return query.order_by(SessionEvent.created_at.desc()).limit(limit).all()\n\n\n# Global singleton instance\nevent_logger = EventLoggingService()\n\n\n# Convenience functions for common events\nasync def log_websocket_connect(\n    conversation_id: uuid.UUID,\n    session_id: str,\n    user_id: Optional[uuid.UUID] = None,\n    trace_id: Optional[str] = None,\n) -> None:\n    \"\"\"Log a WebSocket connection event.\"\"\"\n    await event_logger.log_event(\n        conversation_id=conversation_id,\n        event_type=EventType.WEBSOCKET_CONNECT,\n        session_id=session_id,\n        user_id=user_id,\n        trace_id=trace_id,\n        payload={\"timestamp\": datetime.utcnow().isoformat()},\n    )\n\n\nasync def log_websocket_disconnect(\n    conversation_id: uuid.UUID,\n    session_id: str,\n    reason: Optional[str] = None,\n    trace_id: Optional[str] = None,\n) -> None:\n    \"\"\"Log a WebSocket disconnection event.\"\"\"\n    await event_logger.log_event(\n        conversation_id=conversation_id,\n        event_type=EventType.WEBSOCKET_DISCONNECT,\n        session_id=session_id,\n        trace_id=trace_id,\n        payload={\"reason\": reason, \"timestamp\": datetime.utcnow().isoformat()},\n    )\n\n\nasync def log_message_created(\n    conversation_id: uuid.UUID,\n    message_id: str,\n    role: str,\n    branch_id: Optional[str] = None,\n    user_id: Optional[uuid.UUID] = None,\n    trace_id: Optional[str] = None,\n) -> None:\n    \"\"\"Log a message creation event.\"\"\"\n    await event_logger.log_event(\n        conversation_id=conversation_id,\n        event_type=EventType.MESSAGE_CREATED,\n        branch_id=branch_id,\n        user_id=user_id,\n        trace_id=trace_id,\n        payload={\n            \"message_id\": message_id,\n            \"role\": role,\n            \"timestamp\": datetime.utcnow().isoformat(),\n        },\n    )\n\n\nasync def log_branch_created(\n    conversation_id: uuid.UUID,\n    branch_id: str,\n    parent_message_id: str,\n    user_id: Optional[uuid.UUID] = None,\n    trace_id: Optional[str] = None,\n) -> None:\n    \"\"\"Log a branch creation event.\"\"\"\n    await event_logger.log_event(\n        conversation_id=conversation_id,\n        event_type=EventType.BRANCH_CREATED,\n        branch_id=branch_id,\n        user_id=user_id,\n        trace_id=trace_id,\n        payload={\n            \"parent_message_id\": parent_message_id,\n            \"timestamp\": datetime.utcnow().isoformat(),\n        },\n    )\n\n\nasync def log_error(\n    conversation_id: uuid.UUID,\n    error_type: str,\n    error_code: str,\n    error_message: str,\n    session_id: Optional[str] = None,\n    user_id: Optional[uuid.UUID] = None,\n    trace_id: Optional[str] = None,\n    details: Optional[Dict[str, Any]] = None,\n) -> None:\n    \"\"\"Log an error event.\"\"\"\n    event_type_map = {\n        \"websocket\": EventType.ERROR_WEBSOCKET,\n        \"voice\": EventType.ERROR_VOICE,\n        \"api\": EventType.ERROR_API,\n        \"backend\": EventType.ERROR_BACKEND,\n    }\n    event_type = event_type_map.get(error_type, EventType.ERROR_BACKEND)\n\n    await event_logger.log_event(\n        conversation_id=conversation_id,\n        event_type=event_type,\n        session_id=session_id,\n        user_id=user_id,\n        trace_id=trace_id,\n        payload={\n            \"error_code\": error_code,\n            \"error_message\": error_message,\n            \"details\": details,\n            \"timestamp\": datetime.utcnow().isoformat(),\n        },\n    )\n"
}
