{
  "path": "services/api-gateway/app/services/voice_style_detector.py",
  "language": "python",
  "size": 10106,
  "last_modified": "2025-12-04T11:27:01.976Z",
  "lines": 315,
  "content": "\"\"\"\nVoice Style Detector Service\n\nDetects appropriate voice style/tone based on content context for medical AI assistant.\nUsed to automatically adjust TTS parameters for more natural, context-appropriate speech.\n\nVoice Styles:\n- CALM: Default medical explanations (stable, measured pace)\n- URGENT: Medical warnings, emergencies (dynamic, faster)\n- EMPATHETIC: Sensitive health topics (warm, slower)\n- INSTRUCTIONAL: Step-by-step guidance (clear, deliberate)\n- CONVERSATIONAL: General chat (natural, varied)\n\"\"\"\n\nimport re\nfrom dataclasses import dataclass\nfrom enum import Enum\nfrom typing import Dict, Optional\n\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\nclass VoiceStyleContext(str, Enum):\n    \"\"\"Voice style contexts for medical AI assistant.\"\"\"\n\n    CALM = \"calm\"  # Default explanations\n    URGENT = \"urgent\"  # Medical warnings/emergencies\n    EMPATHETIC = \"empathetic\"  # Sensitive health topics\n    INSTRUCTIONAL = \"instructional\"  # Step-by-step guidance\n    CONVERSATIONAL = \"conversational\"  # General chat\n\n\n@dataclass\nclass VoiceStylePreset:\n    \"\"\"TTS parameters preset for a voice style.\"\"\"\n\n    context: VoiceStyleContext\n    stability: float  # 0-1: lower = more expressive\n    similarity_boost: float  # 0-1: voice matching fidelity\n    style: float  # 0-1: style/emotion exaggeration (ElevenLabs)\n    speech_rate: float  # 0.5-2.0: speech rate multiplier\n\n    def to_dict(self) -> Dict[str, float]:\n        \"\"\"Convert to dictionary for API responses.\"\"\"\n        return {\n            \"context\": self.context.value,\n            \"stability\": self.stability,\n            \"similarity_boost\": self.similarity_boost,\n            \"style\": self.style,\n            \"speech_rate\": self.speech_rate,\n        }\n\n\n# Predefined presets for medical context\nMEDICAL_VOICE_PRESETS: Dict[VoiceStyleContext, VoiceStylePreset] = {\n    VoiceStyleContext.CALM: VoiceStylePreset(\n        context=VoiceStyleContext.CALM,\n        stability=0.65,\n        similarity_boost=0.75,\n        style=0.2,\n        speech_rate=0.95,\n    ),\n    VoiceStyleContext.URGENT: VoiceStylePreset(\n        context=VoiceStyleContext.URGENT,\n        stability=0.45,  # More dynamic for emphasis\n        similarity_boost=0.7,\n        style=0.5,  # More expressive\n        speech_rate=1.1,  # Slightly faster\n    ),\n    VoiceStyleContext.EMPATHETIC: VoiceStylePreset(\n        context=VoiceStyleContext.EMPATHETIC,\n        stability=0.7,\n        similarity_boost=0.8,\n        style=0.3,\n        speech_rate=0.9,  # Slower, more deliberate\n    ),\n    VoiceStyleContext.INSTRUCTIONAL: VoiceStylePreset(\n        context=VoiceStyleContext.INSTRUCTIONAL,\n        stability=0.6,\n        similarity_boost=0.75,\n        style=0.15,\n        speech_rate=1.0,  # Clear, measured pace\n    ),\n    VoiceStyleContext.CONVERSATIONAL: VoiceStylePreset(\n        context=VoiceStyleContext.CONVERSATIONAL,\n        stability=0.55,\n        similarity_boost=0.7,\n        style=0.25,\n        speech_rate=1.0,\n    ),\n}\n\n\nclass VoiceStyleDetector:\n    \"\"\"\n    Detects appropriate voice style from text content.\n\n    Uses keyword matching and pattern detection to determine\n    the appropriate tone for medical AI responses.\n    \"\"\"\n\n    # Keywords indicating urgent/emergency content\n    URGENT_KEYWORDS = [\n        \"emergency\",\n        \"immediately\",\n        \"call 911\",\n        \"seek medical attention\",\n        \"warning\",\n        \"urgent\",\n        \"danger\",\n        \"critical\",\n        \"life-threatening\",\n        \"poison control\",\n        \"go to the er\",\n        \"emergency room\",\n        \"chest pain\",\n        \"difficulty breathing\",\n        \"stroke symptoms\",\n        \"heart attack\",\n        \"allergic reaction\",\n        \"anaphylaxis\",\n    ]\n\n    # Keywords indicating empathetic/sensitive content\n    EMPATHETIC_KEYWORDS = [\n        \"understand\",\n        \"difficult\",\n        \"concerning\",\n        \"worried\",\n        \"anxious\",\n        \"scared\",\n        \"sorry to hear\",\n        \"must be hard\",\n        \"challenging\",\n        \"grief\",\n        \"loss\",\n        \"depression\",\n        \"anxiety\",\n        \"mental health\",\n        \"emotional\",\n        \"sensitive\",\n        \"support\",\n        \"comfort\",\n        \"care\",\n    ]\n\n    # Patterns indicating instructional content\n    INSTRUCTIONAL_PATTERNS = [\n        r\"step\\s+\\d+\",\n        r\"first[,\\s]\",\n        r\"then[,\\s]\",\n        r\"next[,\\s]\",\n        r\"finally[,\\s]\",\n        r\"follow\\s+these\\s+steps\",\n        r\"here's\\s+how\",\n        r\"instructions\",\n        r\"to\\s+do\\s+this\",\n        r\"you\\s+should\",\n        r\"make\\s+sure\\s+to\",\n        r\"\\d+\\.\\s+\",  # Numbered lists\n    ]\n\n    # Keywords indicating conversational/casual content\n    CONVERSATIONAL_KEYWORDS = [\n        \"hello\",\n        \"hi there\",\n        \"how are you\",\n        \"nice to\",\n        \"great question\",\n        \"that's interesting\",\n        \"by the way\",\n        \"anyway\",\n        \"so basically\",\n        \"you know\",\n    ]\n\n    def __init__(self):\n        self._urgent_pattern = re.compile(\n            \"|\".join(re.escape(kw) for kw in self.URGENT_KEYWORDS),\n            re.IGNORECASE,\n        )\n        self._empathetic_pattern = re.compile(\n            \"|\".join(re.escape(kw) for kw in self.EMPATHETIC_KEYWORDS),\n            re.IGNORECASE,\n        )\n        self._instructional_pattern = re.compile(\n            \"|\".join(self.INSTRUCTIONAL_PATTERNS),\n            re.IGNORECASE,\n        )\n        self._conversational_pattern = re.compile(\n            \"|\".join(re.escape(kw) for kw in self.CONVERSATIONAL_KEYWORDS),\n            re.IGNORECASE,\n        )\n\n    def detect_style(\n        self,\n        text: str,\n        clinical_context: Optional[Dict] = None,\n    ) -> VoiceStyleContext:\n        \"\"\"\n        Detect appropriate voice style from text content.\n\n        Args:\n            text: The text to analyze\n            clinical_context: Optional clinical context metadata\n\n        Returns:\n            VoiceStyleContext enum value\n        \"\"\"\n        if not text:\n            return VoiceStyleContext.CALM\n\n        text_lower = text.lower()\n\n        # Priority 1: Urgent content (most important to catch)\n        if self._urgent_pattern.search(text_lower):\n            logger.debug(\"Detected URGENT style\", extra={\"text_preview\": text[:100]})\n            return VoiceStyleContext.URGENT\n\n        # Priority 2: Empathetic content\n        if self._empathetic_pattern.search(text_lower):\n            logger.debug(\"Detected EMPATHETIC style\", extra={\"text_preview\": text[:100]})\n            return VoiceStyleContext.EMPATHETIC\n\n        # Priority 3: Instructional content\n        if self._instructional_pattern.search(text_lower):\n            logger.debug(\"Detected INSTRUCTIONAL style\", extra={\"text_preview\": text[:100]})\n            return VoiceStyleContext.INSTRUCTIONAL\n\n        # Priority 4: Conversational content\n        if self._conversational_pattern.search(text_lower):\n            logger.debug(\"Detected CONVERSATIONAL style\", extra={\"text_preview\": text[:100]})\n            return VoiceStyleContext.CONVERSATIONAL\n\n        # Default: Calm medical explanation\n        return VoiceStyleContext.CALM\n\n    def get_preset(self, style: VoiceStyleContext) -> VoiceStylePreset:\n        \"\"\"Get the voice preset for a given style.\"\"\"\n        return MEDICAL_VOICE_PRESETS.get(style, MEDICAL_VOICE_PRESETS[VoiceStyleContext.CALM])\n\n    def get_all_presets(self) -> Dict[str, Dict]:\n        \"\"\"Get all available style presets.\"\"\"\n        return {style.value: preset.to_dict() for style, preset in MEDICAL_VOICE_PRESETS.items()}\n\n    def apply_style_to_synthesis(\n        self,\n        text: str,\n        base_stability: float = 0.5,\n        base_similarity_boost: float = 0.75,\n        base_style: float = 0.0,\n        base_speech_rate: float = 1.0,\n        auto_detect: bool = True,\n        explicit_style: Optional[VoiceStyleContext] = None,\n    ) -> Dict[str, float]:\n        \"\"\"\n        Apply style-based adjustments to TTS parameters.\n\n        Args:\n            text: Text to synthesize\n            base_stability: User's base stability preference\n            base_similarity_boost: User's base similarity boost preference\n            base_style: User's base style preference\n            base_speech_rate: User's base speech rate preference\n            auto_detect: Whether to auto-detect style from content\n            explicit_style: Explicitly requested style (overrides auto-detect)\n\n        Returns:\n            Dictionary with adjusted TTS parameters\n        \"\"\"\n        # Determine style\n        if explicit_style is not None:\n            style = explicit_style\n        elif auto_detect:\n            style = self.detect_style(text)\n        else:\n            style = VoiceStyleContext.CALM\n\n        preset = self.get_preset(style)\n\n        # Blend user preferences with style preset (60% user, 40% preset)\n        user_weight = 0.6\n        preset_weight = 0.4\n\n        adjusted_params = {\n            \"stability\": base_stability * user_weight + preset.stability * preset_weight,\n            \"similarity_boost\": base_similarity_boost * user_weight + preset.similarity_boost * preset_weight,\n            \"style\": base_style * user_weight + preset.style * preset_weight,\n            \"speech_rate\": base_speech_rate * user_weight + preset.speech_rate * preset_weight,\n            \"detected_style\": style.value,\n        }\n\n        # Clamp values to valid ranges\n        adjusted_params[\"stability\"] = max(0.0, min(1.0, adjusted_params[\"stability\"]))\n        adjusted_params[\"similarity_boost\"] = max(0.0, min(1.0, adjusted_params[\"similarity_boost\"]))\n        adjusted_params[\"style\"] = max(0.0, min(1.0, adjusted_params[\"style\"]))\n        adjusted_params[\"speech_rate\"] = max(0.5, min(2.0, adjusted_params[\"speech_rate\"]))\n\n        logger.debug(\n            f\"Applied voice style: {style.value}\",\n            extra={\n                \"style\": style.value,\n                \"stability\": adjusted_params[\"stability\"],\n                \"speech_rate\": adjusted_params[\"speech_rate\"],\n            },\n        )\n\n        return adjusted_params\n\n\n# Global service instance\nvoice_style_detector = VoiceStyleDetector()\n"
}
