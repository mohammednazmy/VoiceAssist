{
  "path": "services/api-gateway/app/services/phi_stt_router.py",
  "language": "python",
  "size": 20765,
  "last_modified": "2025-12-04T21:30:58.283Z",
  "lines": 590,
  "content": "\"\"\"\nPHI-Aware STT Routing Service\nRoutes speech-to-text processing based on PHI sensitivity detection.\n\nPart of Voice Mode Enhancement Plan v4.1 - Workstream 3\nReference: docs/voice/phi-aware-stt-routing.md\n\nFeatures:\n- PHI detection with sensitivity scoring\n- Dynamic routing: Cloud STT / Hybrid / Local Whisper\n- Session-level PHI context tracking\n- Audit logging for HIPAA compliance\n- Telemetry hooks for frontend PHI mode indicator\n\nRouting Priority Order (most secure to fastest):\n============================================\n1. LOCAL (on-device Whisper)\n   - Triggered when: PHI score >= 0.7 OR explicit prior PHI in session\n   - Latency: ~200-400ms additional\n   - Security: Full HIPAA compliance, no data leaves device\n\n2. HYBRID (cloud with redaction)\n   - Triggered when: 0.3 <= PHI score < 0.7\n   - Latency: ~50-100ms additional for redaction\n   - Security: PHI entities redacted before cloud transmission\n\n3. CLOUD (standard cloud STT)\n   - Triggered when: PHI score < 0.3 AND no prior PHI context\n   - Latency: Fastest (~100-150ms)\n   - Security: Standard cloud processing (not for PHI)\n\nThe router biases toward more secure routing when:\n- Medical context is detected (is_medical_session=True)\n- Session has prior PHI detected (has_prior_phi=True)\n- User explicitly requests secure mode\n\"\"\"\n\nimport logging\nimport time\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional\n\nfrom app.core.config import settings\nfrom app.services.phi_detector import PHIDetectionResult, PHIDetector\nfrom app.services.phi_telemetry import PHIRoutingMode, PHITelemetryService, get_phi_telemetry_service\n\nlogger = logging.getLogger(__name__)\n\n\nclass STTRouting(str, Enum):\n    \"\"\"STT routing decisions.\"\"\"\n\n    CLOUD = \"cloud\"  # Use cloud STT (fastest)\n    HYBRID = \"hybrid\"  # Use cloud with redaction\n    LOCAL = \"local\"  # Use local Whisper (most secure)\n\n\nclass STTProvider(str, Enum):\n    \"\"\"Available STT providers.\"\"\"\n\n    OPENAI_WHISPER = \"openai_whisper\"\n    OPENAI_WHISPER_REDACTED = \"openai_whisper_redacted\"\n    LOCAL_WHISPER = \"local_whisper\"\n    GOOGLE_STT = \"google_stt\"\n    AZURE_STT = \"azure_stt\"\n\n\n@dataclass\nclass PHIRoutingConfig:\n    \"\"\"Configuration for PHI-aware STT routing.\"\"\"\n\n    # Threshold for routing to local Whisper (high PHI probability)\n    local_threshold: float = 0.7\n\n    # Threshold for hybrid mode (moderate PHI probability)\n    hybrid_threshold: float = 0.3\n\n    # Session context window (number of messages to consider)\n    session_context_window: int = 10\n\n    # Whether to bias toward local for medical context\n    medical_context_bias: bool = True\n\n    # Default provider for cloud routing\n    cloud_provider: STTProvider = STTProvider.OPENAI_WHISPER\n\n    # Local Whisper model configuration\n    local_model_size: str = \"large-v3\"\n    local_model_device: str = \"cuda\"\n\n\n@dataclass\nclass STTRoutingResult:\n    \"\"\"Result of STT routing decision.\"\"\"\n\n    routing: STTRouting\n    provider: STTProvider\n    phi_score: float\n    phi_entities: List[str] = field(default_factory=list)\n    from_session_context: bool = False\n    latency_ms: float = 0.0\n    decision_reason: str = \"\"\n\n\n@dataclass\nclass TranscriptionResult:\n    \"\"\"Result of speech-to-text transcription.\"\"\"\n\n    text: str\n    routing: STTRouting\n    provider: STTProvider\n    phi_score: float\n    phi_entities: List[str] = field(default_factory=list)\n    redacted_entities: List[str] = field(default_factory=list)\n    latency_ms: float = 0.0\n    confidence: float = 1.0\n    language: str = \"en\"\n\n\nclass SessionPHIContext:\n    \"\"\"Tracks PHI context within a session.\"\"\"\n\n    def __init__(self, session_id: str, window_size: int = 10):\n        self.session_id = session_id\n        self.window_size = window_size\n        self._phi_history: List[PHIDetectionResult] = []\n        self._has_prior_phi: bool = False\n        self._phi_types_seen: set = set()\n\n    def add_detection(self, result: PHIDetectionResult) -> None:\n        \"\"\"Add a PHI detection result to session history.\"\"\"\n        self._phi_history.append(result)\n        if len(self._phi_history) > self.window_size:\n            self._phi_history.pop(0)\n\n        if result.contains_phi:\n            self._has_prior_phi = True\n            self._phi_types_seen.update(result.phi_types)\n\n    @property\n    def has_prior_phi(self) -> bool:\n        \"\"\"Check if PHI was detected in this session.\"\"\"\n        return self._has_prior_phi\n\n    @property\n    def phi_types_seen(self) -> set:\n        \"\"\"Get all PHI types seen in this session.\"\"\"\n        return self._phi_types_seen\n\n    def get_session_phi_score(self) -> float:\n        \"\"\"Calculate aggregate PHI score for session.\"\"\"\n        if not self._phi_history:\n            return 0.0\n\n        # Weight recent detections more heavily\n        weights = [0.5 + (i * 0.05) for i in range(len(self._phi_history))]\n        total_weight = sum(weights)\n\n        weighted_score = sum(w * (1.0 if r.contains_phi else 0.0) for w, r in zip(weights, self._phi_history))\n\n        return weighted_score / total_weight if total_weight > 0 else 0.0\n\n\nclass LocalWhisperTranscriber:\n    \"\"\"Local Whisper transcription for PHI-sensitive audio.\"\"\"\n\n    def __init__(self, model_size: str = \"large-v3\", device: str = \"cuda\"):\n        self.model_size = model_size\n        self.device = device\n        self._model = None\n        self._initialized = False\n\n    async def _ensure_initialized(self) -> None:\n        \"\"\"Lazy initialization of Whisper model.\"\"\"\n        if self._initialized:\n            return\n\n        try:\n            from faster_whisper import WhisperModel\n\n            self._model = WhisperModel(self.model_size, device=self.device, compute_type=\"float16\")\n            self._initialized = True\n            logger.info(f\"Local Whisper model loaded: {self.model_size} on {self.device}\")\n        except ImportError:\n            logger.warning(\"faster-whisper not installed, local transcription unavailable\")\n        except Exception as e:\n            logger.error(f\"Failed to initialize local Whisper: {e}\")\n\n    async def transcribe(self, audio_data: bytes, language: Optional[str] = None) -> TranscriptionResult:\n        \"\"\"Transcribe audio using local Whisper.\"\"\"\n        await self._ensure_initialized()\n\n        if not self._model:\n            raise RuntimeError(\"Local Whisper model not available\")\n\n        start_time = time.monotonic()\n\n        try:\n            # Write audio to temp file (faster-whisper requires file path)\n            import tempfile\n\n            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n                f.write(audio_data)\n                temp_path = f.name\n\n            # Transcribe\n            segments, info = self._model.transcribe(\n                temp_path,\n                language=language,\n                beam_size=5,\n                vad_filter=True,\n            )\n\n            # Collect transcription\n            text = \" \".join(segment.text for segment in segments)\n            detected_language = info.language\n\n            # Clean up temp file\n            import os\n\n            os.unlink(temp_path)\n\n            latency_ms = (time.monotonic() - start_time) * 1000\n\n            return TranscriptionResult(\n                text=text.strip(),\n                routing=STTRouting.LOCAL,\n                provider=STTProvider.LOCAL_WHISPER,\n                phi_score=1.0,  # Local processing implies PHI present\n                latency_ms=latency_ms,\n                language=detected_language,\n            )\n\n        except Exception as e:\n            logger.error(f\"Local Whisper transcription failed: {e}\")\n            raise\n\n\nclass CloudSTTClient:\n    \"\"\"Cloud STT client with optional redaction.\"\"\"\n\n    def __init__(self, provider: STTProvider = STTProvider.OPENAI_WHISPER):\n        self.provider = provider\n        self._phi_detector = PHIDetector()\n\n    async def transcribe(\n        self,\n        audio_data: bytes,\n        language: Optional[str] = None,\n        redact_phi: bool = False,\n    ) -> TranscriptionResult:\n        \"\"\"Transcribe audio using cloud STT.\"\"\"\n        start_time = time.monotonic()\n\n        if self.provider == STTProvider.OPENAI_WHISPER:\n            text, detected_lang = await self._transcribe_openai(audio_data, language)\n        elif self.provider == STTProvider.GOOGLE_STT:\n            text, detected_lang = await self._transcribe_google(audio_data, language)\n        else:\n            raise ValueError(f\"Unsupported provider: {self.provider}\")\n\n        redacted_entities = []\n        if redact_phi:\n            # Detect and redact PHI from transcript\n            phi_result = self._phi_detector.detect(text)\n            if phi_result.contains_phi:\n                text = self._phi_detector.sanitize(text)\n                redacted_entities = phi_result.phi_types\n\n        latency_ms = (time.monotonic() - start_time) * 1000\n\n        return TranscriptionResult(\n            text=text,\n            routing=STTRouting.HYBRID if redact_phi else STTRouting.CLOUD,\n            provider=self.provider,\n            phi_score=0.0 if not redact_phi else 0.5,\n            redacted_entities=redacted_entities,\n            latency_ms=latency_ms,\n            language=detected_lang or language or \"en\",\n        )\n\n    async def _transcribe_openai(self, audio_data: bytes, language: Optional[str] = None) -> tuple[str, str]:\n        \"\"\"Transcribe using OpenAI Whisper API.\"\"\"\n        import httpx\n\n        api_key = getattr(settings, \"openai_api_key\", None)\n        if not api_key:\n            raise RuntimeError(\"OpenAI API key not configured\")\n\n        async with httpx.AsyncClient() as client:\n            response = await client.post(\n                \"https://api.openai.com/v1/audio/transcriptions\",\n                headers={\"Authorization\": f\"Bearer {api_key}\"},\n                files={\"file\": (\"audio.wav\", audio_data, \"audio/wav\")},\n                data={\n                    \"model\": \"whisper-1\",\n                    \"language\": language or \"\",\n                    \"response_format\": \"verbose_json\",\n                },\n                timeout=30.0,\n            )\n            response.raise_for_status()\n            data = response.json()\n            return data.get(\"text\", \"\"), data.get(\"language\", \"en\")\n\n    async def _transcribe_google(self, audio_data: bytes, language: Optional[str] = None) -> tuple[str, str]:\n        \"\"\"Transcribe using Google Cloud Speech-to-Text.\"\"\"\n        # Placeholder for Google STT integration\n        raise NotImplementedError(\"Google STT not implemented\")\n\n\nclass PHISTTRouter:\n    \"\"\"\n    PHI-aware STT router that dynamically routes audio based on sensitivity.\n\n    Routing decisions:\n    - PHI score < 0.3: Cloud STT (fastest)\n    - PHI score 0.3-0.7: Hybrid mode with redaction\n    - PHI score >= 0.7: Local Whisper (most secure)\n\n    Telemetry Integration:\n    - Broadcasts routing decisions to subscribed frontends\n    - Provides real-time PHI mode indicator state\n    - Records metrics for observability\n    \"\"\"\n\n    def __init__(\n        self,\n        config: Optional[PHIRoutingConfig] = None,\n        phi_detector: Optional[PHIDetector] = None,\n        telemetry_service: Optional[PHITelemetryService] = None,\n    ):\n        self.config = config or PHIRoutingConfig()\n        self.phi_detector = phi_detector or PHIDetector()\n        self._telemetry = telemetry_service or get_phi_telemetry_service()\n        self._session_contexts: Dict[str, SessionPHIContext] = {}\n        self._local_transcriber: Optional[LocalWhisperTranscriber] = None\n        self._cloud_client: Optional[CloudSTTClient] = None\n\n    def _get_session_context(self, session_id: str) -> SessionPHIContext:\n        \"\"\"Get or create session PHI context.\"\"\"\n        if session_id not in self._session_contexts:\n            self._session_contexts[session_id] = SessionPHIContext(\n                session_id=session_id,\n                window_size=self.config.session_context_window,\n            )\n        return self._session_contexts[session_id]\n\n    def _get_local_transcriber(self) -> LocalWhisperTranscriber:\n        \"\"\"Get or create local Whisper transcriber.\"\"\"\n        if self._local_transcriber is None:\n            self._local_transcriber = LocalWhisperTranscriber(\n                model_size=self.config.local_model_size,\n                device=self.config.local_model_device,\n            )\n        return self._local_transcriber\n\n    def _get_cloud_client(self) -> CloudSTTClient:\n        \"\"\"Get or create cloud STT client.\"\"\"\n        if self._cloud_client is None:\n            self._cloud_client = CloudSTTClient(provider=self.config.cloud_provider)\n        return self._cloud_client\n\n    def route(\n        self,\n        text_hint: Optional[str] = None,\n        session_id: Optional[str] = None,\n        context: Optional[Dict[str, Any]] = None,\n    ) -> STTRoutingResult:\n        \"\"\"\n        Determine STT routing based on PHI indicators.\n\n        Args:\n            text_hint: Optional text hint (e.g., from partial transcription)\n            session_id: Session ID for context tracking\n            context: Additional context (e.g., has_prior_phi)\n\n        Returns:\n            STTRoutingResult with routing decision\n        \"\"\"\n        start_time = time.monotonic()\n        context = context or {}\n\n        phi_score = 0.0\n        phi_entities = []\n        from_session_context = False\n        decision_reason = \"default\"\n\n        # Check session context\n        if session_id:\n            session_context = self._get_session_context(session_id)\n            if session_context.has_prior_phi:\n                phi_score = max(phi_score, 0.6)  # Bias toward secure routing\n                from_session_context = True\n                phi_entities.extend(session_context.phi_types_seen)\n                decision_reason = \"session_has_prior_phi\"\n\n        # Check explicit context flags\n        if context.get(\"has_prior_phi\"):\n            phi_score = max(phi_score, 0.8)\n            from_session_context = True\n            decision_reason = \"explicit_prior_phi_flag\"\n\n        # Medical context bias\n        if self.config.medical_context_bias and context.get(\"is_medical_session\"):\n            phi_score = max(phi_score, 0.4)\n            decision_reason = \"medical_context_bias\"\n\n        # Analyze text hint if provided\n        if text_hint:\n            detection = self.phi_detector.detect(text_hint, context.get(\"clinical_context\"))\n            if detection.contains_phi:\n                phi_score = max(phi_score, detection.confidence)\n                phi_entities.extend(detection.phi_types)\n                decision_reason = f\"phi_detected_in_hint: {detection.phi_types}\"\n\n                # Update session context\n                if session_id:\n                    self._get_session_context(session_id).add_detection(detection)\n\n        # Determine routing based on score\n        if phi_score >= self.config.local_threshold:\n            routing = STTRouting.LOCAL\n            provider = STTProvider.LOCAL_WHISPER\n        elif phi_score >= self.config.hybrid_threshold:\n            routing = STTRouting.HYBRID\n            provider = STTProvider.OPENAI_WHISPER_REDACTED\n        else:\n            routing = STTRouting.CLOUD\n            provider = self.config.cloud_provider\n\n        latency_ms = (time.monotonic() - start_time) * 1000\n\n        result = STTRoutingResult(\n            routing=routing,\n            provider=provider,\n            phi_score=phi_score,\n            phi_entities=list(set(phi_entities)),\n            from_session_context=from_session_context,\n            latency_ms=latency_ms,\n            decision_reason=decision_reason,\n        )\n\n        # Audit log\n        logger.info(\n            \"PHI routing decision\",\n            extra={\n                \"session_id\": session_id,\n                \"phi_score\": phi_score,\n                \"routing\": routing.value,\n                \"provider\": provider.value,\n                \"phi_entities\": phi_entities,\n                \"decision_reason\": decision_reason,\n                \"latency_ms\": latency_ms,\n            },\n        )\n\n        # Update telemetry for frontend visibility\n        if session_id:\n            telemetry_mode = PHIRoutingMode(routing.value)\n            self._telemetry.update_routing_state(\n                session_id=session_id,\n                mode=telemetry_mode,\n                phi_score=phi_score,\n                phi_entities=list(set(phi_entities)),\n                routing_reason=decision_reason,\n                has_prior_phi=from_session_context,\n            )\n\n        return result\n\n    async def transcribe(\n        self,\n        audio_data: bytes,\n        session_id: Optional[str] = None,\n        context: Optional[Dict[str, Any]] = None,\n        language: Optional[str] = None,\n    ) -> TranscriptionResult:\n        \"\"\"\n        Transcribe audio with PHI-aware routing.\n\n        Args:\n            audio_data: Raw audio bytes (WAV format)\n            session_id: Session ID for context tracking\n            context: Additional context\n            language: Expected language code\n\n        Returns:\n            TranscriptionResult with transcript and routing info\n        \"\"\"\n        # Get routing decision\n        routing_result = self.route(\n            text_hint=None,  # No hint available yet\n            session_id=session_id,\n            context=context,\n        )\n\n        try:\n            if routing_result.routing == STTRouting.LOCAL:\n                # Use local Whisper\n                transcriber = self._get_local_transcriber()\n                result = await transcriber.transcribe(audio_data, language)\n\n            elif routing_result.routing == STTRouting.HYBRID:\n                # Use cloud with redaction\n                client = self._get_cloud_client()\n                result = await client.transcribe(audio_data, language, redact_phi=True)\n\n            else:\n                # Use cloud directly\n                client = self._get_cloud_client()\n                result = await client.transcribe(audio_data, language, redact_phi=False)\n\n            # Update with routing info\n            result.phi_score = routing_result.phi_score\n            result.phi_entities = routing_result.phi_entities\n\n            # Update session context with transcript\n            if session_id and result.text:\n                detection = self.phi_detector.detect(result.text)\n                self._get_session_context(session_id).add_detection(detection)\n                if detection.contains_phi:\n                    result.phi_entities = list(set(result.phi_entities + detection.phi_types))\n\n            return result\n\n        except Exception as e:\n            logger.error(f\"Transcription failed: {e}\")\n            # Fall back to cloud if local fails\n            if routing_result.routing == STTRouting.LOCAL:\n                logger.warning(\"Falling back to cloud STT after local failure\")\n                client = self._get_cloud_client()\n                return await client.transcribe(audio_data, language, redact_phi=True)\n            raise\n\n    def clear_session(self, session_id: str) -> None:\n        \"\"\"Clear session context and telemetry state.\"\"\"\n        if session_id in self._session_contexts:\n            del self._session_contexts[session_id]\n        # Clean up telemetry\n        self._telemetry.end_session(session_id)\n\n    def get_frontend_state(self, session_id: str) -> Optional[Dict[str, Any]]:\n        \"\"\"\n        Get current PHI routing state for frontend display.\n\n        Returns a dictionary suitable for the PHI indicator component:\n        {\n            \"sessionId\": \"...\",\n            \"phiMode\": \"local\" | \"hybrid\" | \"cloud\",\n            \"phiScore\": 0.0-1.0,\n            \"isSecureMode\": bool,\n            \"hasPriorPhi\": bool,\n            \"indicatorColor\": \"green\" | \"yellow\" | \"blue\",\n            \"indicatorIcon\": \"shield\" | \"lock\" | \"cloud\",\n            \"tooltip\": \"...\"\n        }\n        \"\"\"\n        return self._telemetry.get_frontend_state(session_id)\n\n    def init_session(\n        self,\n        session_id: str,\n        is_medical_context: bool = False,\n    ) -> None:\n        \"\"\"\n        Initialize a new PHI routing session with telemetry.\n\n        Args:\n            session_id: Unique session identifier\n            is_medical_context: Whether this is a medical context session\n        \"\"\"\n        # Initialize session context\n        self._get_session_context(session_id)\n        # Initialize telemetry\n        self._telemetry.init_session(session_id, is_medical_context)\n\n\n# Singleton instance\n_phi_stt_router: Optional[PHISTTRouter] = None\n\n\nasync def get_phi_stt_router() -> PHISTTRouter:\n    \"\"\"Get or create PHI STT router instance.\"\"\"\n    global _phi_stt_router\n    if _phi_stt_router is None:\n        _phi_stt_router = PHISTTRouter()\n    return _phi_stt_router\n"
}
