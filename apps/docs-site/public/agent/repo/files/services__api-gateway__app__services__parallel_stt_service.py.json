{
  "path": "services/api-gateway/app/services/parallel_stt_service.py",
  "language": "python",
  "size": 20091,
  "last_modified": "2025-12-05T03:18:20.321Z",
  "lines": 632,
  "content": "\"\"\"\nParallel STT Service - Multi-Provider Parallel Speech Recognition\n\nVoice Mode v4 - Phase 2 Integration\n\nProvides parallel transcription across multiple STT providers:\n- Run multiple STT streams concurrently for different languages\n- Select best transcript based on confidence scoring\n- Early termination on high-confidence result\n- Language-aware provider selection\n\nImproves accuracy for code-switching and multilingual conversations.\n\"\"\"\n\nimport asyncio\nimport logging\nimport time\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, AsyncIterator, Callable, Dict, List, Optional, Tuple\n\nlogger = logging.getLogger(__name__)\n\n\nclass STTProviderType(Enum):\n    \"\"\"Supported STT providers.\"\"\"\n    DEEPGRAM = \"deepgram\"\n    WHISPER_API = \"whisper_api\"\n    WHISPER_LOCAL = \"whisper_local\"\n    GOOGLE_SPEECH = \"google_speech\"\n    AZURE_SPEECH = \"azure_speech\"\n    SPEECHMATICS = \"speechmatics\"\n\n\nclass LanguageCode(str, Enum):\n    \"\"\"Supported language codes.\"\"\"\n    ENGLISH = \"en\"\n    ARABIC = \"ar\"\n    SPANISH = \"es\"\n    FRENCH = \"fr\"\n    GERMAN = \"de\"\n    CHINESE = \"zh\"\n    HINDI = \"hi\"\n    URDU = \"ur\"\n    PORTUGUESE = \"pt\"\n    ITALIAN = \"it\"\n    JAPANESE = \"ja\"\n    KOREAN = \"ko\"\n    RUSSIAN = \"ru\"\n\n\n@dataclass\nclass ProviderCapabilities:\n    \"\"\"Capabilities of an STT provider.\"\"\"\n    provider: STTProviderType\n    supported_languages: List[LanguageCode]\n    supports_code_switching: bool\n    supports_streaming: bool\n    avg_latency_ms: float\n    cost_per_minute: float  # USD\n    priority: int  # Lower = higher priority\n\n\n@dataclass\nclass TranscriptResult:\n    \"\"\"Result from a single STT provider.\"\"\"\n    text: str\n    language: LanguageCode\n    confidence: float\n    provider: STTProviderType\n    latency_ms: float\n    is_final: bool\n    word_timings: List[Dict[str, Any]] = field(default_factory=list)\n    alternatives: List[str] = field(default_factory=list)\n\n\n@dataclass\nclass ParallelTranscriptResult:\n    \"\"\"Result from parallel STT transcription.\"\"\"\n    best_transcript: TranscriptResult\n    all_results: List[TranscriptResult]\n    consensus_text: Optional[str]  # If multiple agree\n    consensus_confidence: float\n    total_latency_ms: float\n    providers_used: List[STTProviderType]\n    early_terminated: bool\n\n\n@dataclass\nclass ParallelSTTConfig:\n    \"\"\"Configuration for parallel STT service.\"\"\"\n    # Parallel execution\n    max_parallel_streams: int = 3\n    min_parallel_streams: int = 1\n\n    # Early termination\n    early_termination_confidence: float = 0.95\n    early_termination_enabled: bool = True\n\n    # Timeout\n    stream_timeout_seconds: float = 10.0\n\n    # Consensus\n    require_consensus: bool = False\n    consensus_threshold: float = 0.8  # Min agreement for consensus\n\n    # Cost optimization\n    max_cost_per_request: float = 0.05  # USD\n    prefer_cheaper_providers: bool = True\n\n    # Provider selection\n    provider_weights: Dict[STTProviderType, float] = field(default_factory=dict)\n\n\n# Provider capability registry\nPROVIDER_CAPABILITIES = {\n    STTProviderType.DEEPGRAM: ProviderCapabilities(\n        provider=STTProviderType.DEEPGRAM,\n        supported_languages=[\n            LanguageCode.ENGLISH, LanguageCode.SPANISH, LanguageCode.FRENCH,\n            LanguageCode.GERMAN, LanguageCode.PORTUGUESE, LanguageCode.ITALIAN,\n            LanguageCode.HINDI, LanguageCode.JAPANESE, LanguageCode.KOREAN,\n        ],\n        supports_code_switching=False,\n        supports_streaming=True,\n        avg_latency_ms=120,\n        cost_per_minute=0.0043,\n        priority=1,\n    ),\n    STTProviderType.WHISPER_LOCAL: ProviderCapabilities(\n        provider=STTProviderType.WHISPER_LOCAL,\n        supported_languages=list(LanguageCode),  # All languages\n        supports_code_switching=True,\n        supports_streaming=False,\n        avg_latency_ms=500,\n        cost_per_minute=0.0,  # Free (local)\n        priority=3,\n    ),\n    STTProviderType.WHISPER_API: ProviderCapabilities(\n        provider=STTProviderType.WHISPER_API,\n        supported_languages=list(LanguageCode),  # All languages\n        supports_code_switching=True,\n        supports_streaming=False,\n        avg_latency_ms=800,\n        cost_per_minute=0.006,\n        priority=2,\n    ),\n    STTProviderType.SPEECHMATICS: ProviderCapabilities(\n        provider=STTProviderType.SPEECHMATICS,\n        supported_languages=[\n            LanguageCode.ENGLISH, LanguageCode.ARABIC, LanguageCode.SPANISH,\n            LanguageCode.FRENCH, LanguageCode.GERMAN, LanguageCode.CHINESE,\n        ],\n        supports_code_switching=True,\n        supports_streaming=True,\n        avg_latency_ms=180,\n        cost_per_minute=0.008,\n        priority=2,\n    ),\n}\n\n\n@dataclass\nclass ParallelSTTMetrics:\n    \"\"\"Metrics for parallel STT performance.\"\"\"\n    total_requests: int = 0\n    parallel_requests: int = 0\n    single_provider_requests: int = 0\n    early_terminations: int = 0\n    consensus_achieved: int = 0\n    avg_latency_ms: float = 0.0\n    provider_usage: Dict[str, int] = field(default_factory=dict)\n    provider_success_rate: Dict[str, float] = field(default_factory=dict)\n    cost_total_usd: float = 0.0\n\n\nclass ParallelSTTService:\n    \"\"\"\n    Parallel STT transcription service.\n\n    Runs multiple STT providers concurrently and selects the best result.\n    \"\"\"\n\n    def __init__(self, config: Optional[ParallelSTTConfig] = None):\n        self.config = config or ParallelSTTConfig()\n        self._initialized = False\n        self._metrics = ParallelSTTMetrics()\n\n        # Provider handlers\n        self._providers: Dict[STTProviderType, Callable] = {}\n\n        # Results queue for streaming\n        self._results_queue: asyncio.Queue = asyncio.Queue()\n\n    async def initialize(self) -> None:\n        \"\"\"Initialize the service and provider connections.\"\"\"\n        if self._initialized:\n            return\n\n        logger.info(\n            \"Initializing ParallelSTTService\",\n            extra={\n                \"max_parallel\": self.config.max_parallel_streams,\n                \"early_termination\": self.config.early_termination_enabled,\n            }\n        )\n\n        self._initialized = True\n\n    def register_provider(\n        self,\n        provider: STTProviderType,\n        handler: Callable[..., asyncio.Task]\n    ) -> None:\n        \"\"\"\n        Register a provider handler.\n\n        Args:\n            provider: Provider type\n            handler: Async callable that performs transcription\n        \"\"\"\n        self._providers[provider] = handler\n        logger.debug(f\"Registered STT provider: {provider.value}\")\n\n    async def transcribe_parallel(\n        self,\n        audio_data: bytes,\n        suspected_languages: Optional[List[LanguageCode]] = None,\n        preferred_providers: Optional[List[STTProviderType]] = None,\n    ) -> ParallelTranscriptResult:\n        \"\"\"\n        Transcribe audio using multiple providers in parallel.\n\n        Args:\n            audio_data: PCM16 audio bytes\n            suspected_languages: Languages to prioritize\n            preferred_providers: Specific providers to use\n\n        Returns:\n            ParallelTranscriptResult with best and all transcripts\n        \"\"\"\n        if not self._initialized:\n            await self.initialize()\n\n        start_time = time.time()\n        self._metrics.total_requests += 1\n\n        # Select providers to use\n        providers = self._select_providers(\n            suspected_languages or [LanguageCode.ENGLISH],\n            preferred_providers\n        )\n\n        if len(providers) > 1:\n            self._metrics.parallel_requests += 1\n        else:\n            self._metrics.single_provider_requests += 1\n\n        # Create transcription tasks\n        tasks = []\n        for provider in providers[:self.config.max_parallel_streams]:\n            if provider in self._providers:\n                task = asyncio.create_task(\n                    self._transcribe_with_provider(\n                        provider, audio_data, suspected_languages\n                    )\n                )\n                tasks.append((provider, task))\n\n                # Track usage\n                self._metrics.provider_usage[provider.value] = \\\n                    self._metrics.provider_usage.get(provider.value, 0) + 1\n\n        if not tasks:\n            raise ValueError(\"No providers available for transcription\")\n\n        # Wait for results with early termination\n        results = await self._wait_for_results(tasks)\n\n        # Select best result\n        best = self._select_best_result(results)\n\n        # Check for consensus\n        consensus_text, consensus_confidence = self._calculate_consensus(results)\n\n        total_latency = (time.time() - start_time) * 1000\n        self._metrics.avg_latency_ms = (\n            self._metrics.avg_latency_ms * 0.9 + total_latency * 0.1\n        )\n\n        return ParallelTranscriptResult(\n            best_transcript=best,\n            all_results=results,\n            consensus_text=consensus_text,\n            consensus_confidence=consensus_confidence,\n            total_latency_ms=total_latency,\n            providers_used=[p for p, _ in tasks],\n            early_terminated=len(results) < len(tasks),\n        )\n\n    def _select_providers(\n        self,\n        languages: List[LanguageCode],\n        preferred: Optional[List[STTProviderType]] = None\n    ) -> List[STTProviderType]:\n        \"\"\"Select providers based on language support and capabilities.\"\"\"\n        if preferred:\n            return preferred\n\n        candidates = []\n\n        for provider, capabilities in PROVIDER_CAPABILITIES.items():\n            # Check language support\n            lang_supported = any(\n                lang in capabilities.supported_languages\n                for lang in languages\n            )\n\n            if not lang_supported:\n                continue\n\n            # Calculate score\n            score = 0.0\n\n            # Priority (lower is better)\n            score += (5 - capabilities.priority) * 10\n\n            # Latency (lower is better)\n            score += (1000 - capabilities.avg_latency_ms) / 100\n\n            # Code switching support\n            if capabilities.supports_code_switching and len(languages) > 1:\n                score += 20\n\n            # Cost optimization\n            if self.config.prefer_cheaper_providers:\n                score += (0.01 - capabilities.cost_per_minute) * 100\n\n            # Custom weights\n            if provider in self.config.provider_weights:\n                score *= self.config.provider_weights[provider]\n\n            candidates.append((provider, score))\n\n        # Sort by score (descending)\n        candidates.sort(key=lambda x: x[1], reverse=True)\n\n        return [p for p, _ in candidates]\n\n    async def _transcribe_with_provider(\n        self,\n        provider: STTProviderType,\n        audio_data: bytes,\n        languages: Optional[List[LanguageCode]]\n    ) -> TranscriptResult:\n        \"\"\"Transcribe with a single provider.\"\"\"\n        start_time = time.time()\n\n        handler = self._providers.get(provider)\n        if not handler:\n            raise ValueError(f\"No handler for provider: {provider}\")\n\n        try:\n            result = await asyncio.wait_for(\n                handler(audio_data, languages),\n                timeout=self.config.stream_timeout_seconds\n            )\n\n            latency_ms = (time.time() - start_time) * 1000\n\n            # Update success rate\n            current_rate = self._metrics.provider_success_rate.get(provider.value, 1.0)\n            self._metrics.provider_success_rate[provider.value] = \\\n                current_rate * 0.95 + 0.05\n\n            return TranscriptResult(\n                text=result.get(\"text\", \"\"),\n                language=LanguageCode(result.get(\"language\", \"en\")),\n                confidence=result.get(\"confidence\", 0.0),\n                provider=provider,\n                latency_ms=latency_ms,\n                is_final=result.get(\"is_final\", True),\n                word_timings=result.get(\"words\", []),\n                alternatives=result.get(\"alternatives\", []),\n            )\n\n        except asyncio.TimeoutError:\n            logger.warning(f\"Timeout for provider {provider.value}\")\n\n            # Update success rate\n            current_rate = self._metrics.provider_success_rate.get(provider.value, 1.0)\n            self._metrics.provider_success_rate[provider.value] = \\\n                current_rate * 0.95\n\n            return TranscriptResult(\n                text=\"\",\n                language=LanguageCode.ENGLISH,\n                confidence=0.0,\n                provider=provider,\n                latency_ms=self.config.stream_timeout_seconds * 1000,\n                is_final=True,\n            )\n\n        except Exception as e:\n            logger.error(f\"Error with provider {provider.value}: {e}\")\n\n            current_rate = self._metrics.provider_success_rate.get(provider.value, 1.0)\n            self._metrics.provider_success_rate[provider.value] = \\\n                current_rate * 0.95\n\n            return TranscriptResult(\n                text=\"\",\n                language=LanguageCode.ENGLISH,\n                confidence=0.0,\n                provider=provider,\n                latency_ms=(time.time() - start_time) * 1000,\n                is_final=True,\n            )\n\n    async def _wait_for_results(\n        self,\n        tasks: List[Tuple[STTProviderType, asyncio.Task]]\n    ) -> List[TranscriptResult]:\n        \"\"\"Wait for results with optional early termination.\"\"\"\n        results = []\n        pending = {task: provider for provider, task in tasks}\n\n        while pending:\n            done, _ = await asyncio.wait(\n                pending.keys(),\n                timeout=self.config.stream_timeout_seconds,\n                return_when=asyncio.FIRST_COMPLETED\n            )\n\n            if not done:\n                break\n\n            for task in done:\n                provider = pending.pop(task)\n                try:\n                    result = task.result()\n                    results.append(result)\n\n                    # Check for early termination\n                    if (self.config.early_termination_enabled and\n                        result.confidence >= self.config.early_termination_confidence):\n\n                        logger.debug(\n                            f\"Early termination: {provider.value} \"\n                            f\"confidence={result.confidence:.2f}\"\n                        )\n                        self._metrics.early_terminations += 1\n\n                        # Cancel remaining tasks\n                        for remaining_task in pending.keys():\n                            remaining_task.cancel()\n\n                        return results\n\n                except Exception as e:\n                    logger.warning(f\"Task failed for {provider}: {e}\")\n\n        return results\n\n    def _select_best_result(\n        self,\n        results: List[TranscriptResult]\n    ) -> TranscriptResult:\n        \"\"\"Select the best transcript from results.\"\"\"\n        if not results:\n            return TranscriptResult(\n                text=\"\",\n                language=LanguageCode.ENGLISH,\n                confidence=0.0,\n                provider=STTProviderType.DEEPGRAM,\n                latency_ms=0,\n                is_final=True,\n            )\n\n        # Filter out empty results\n        valid_results = [r for r in results if r.text.strip()]\n\n        if not valid_results:\n            return results[0]\n\n        # Score results\n        scored = []\n        for result in valid_results:\n            score = result.confidence\n\n            # Bonus for lower latency\n            score += (1000 - min(result.latency_ms, 1000)) / 5000\n\n            # Bonus for word timings\n            if result.word_timings:\n                score += 0.05\n\n            scored.append((result, score))\n\n        # Return highest scoring\n        scored.sort(key=lambda x: x[1], reverse=True)\n        return scored[0][0]\n\n    def _calculate_consensus(\n        self,\n        results: List[TranscriptResult]\n    ) -> Tuple[Optional[str], float]:\n        \"\"\"Calculate consensus across multiple transcripts.\"\"\"\n        valid_results = [r for r in results if r.text.strip()]\n\n        if len(valid_results) < 2:\n            return None, 0.0\n\n        # Simple word-level agreement\n        texts = [r.text.lower().strip() for r in valid_results]\n\n        # Check for exact matches\n        if len(set(texts)) == 1:\n            self._metrics.consensus_achieved += 1\n            return valid_results[0].text, 1.0\n\n        # Calculate word overlap\n        word_sets = [set(t.split()) for t in texts]\n\n        if not word_sets:\n            return None, 0.0\n\n        # Intersection of all word sets\n        common_words = word_sets[0]\n        for ws in word_sets[1:]:\n            common_words = common_words.intersection(ws)\n\n        # Union of all word sets\n        all_words = set()\n        for ws in word_sets:\n            all_words = all_words.union(ws)\n\n        if not all_words:\n            return None, 0.0\n\n        overlap_ratio = len(common_words) / len(all_words)\n\n        if overlap_ratio >= self.config.consensus_threshold:\n            self._metrics.consensus_achieved += 1\n            # Use the highest confidence result as consensus\n            best = max(valid_results, key=lambda r: r.confidence)\n            return best.text, overlap_ratio\n\n        return None, overlap_ratio\n\n    async def transcribe_streaming(\n        self,\n        audio_stream: AsyncIterator[bytes],\n        languages: Optional[List[LanguageCode]] = None,\n        on_partial: Optional[Callable[[str], None]] = None,\n    ) -> ParallelTranscriptResult:\n        \"\"\"\n        Streaming transcription with parallel providers.\n\n        Args:\n            audio_stream: Async iterator of audio chunks\n            languages: Language hints\n            on_partial: Callback for partial results\n\n        Returns:\n            Final parallel transcript result\n        \"\"\"\n        # Collect audio chunks\n        chunks = []\n        async for chunk in audio_stream:\n            chunks.append(chunk)\n\n        # Combine and transcribe\n        full_audio = b''.join(chunks)\n        return await self.transcribe_parallel(full_audio, languages)\n\n    def get_metrics(self) -> ParallelSTTMetrics:\n        \"\"\"Get current service metrics.\"\"\"\n        return self._metrics\n\n    def reset_metrics(self) -> None:\n        \"\"\"Reset service metrics.\"\"\"\n        self._metrics = ParallelSTTMetrics()\n\n    def get_provider_stats(self) -> Dict[str, Any]:\n        \"\"\"Get statistics for each provider.\"\"\"\n        return {\n            provider.value: {\n                \"usage\": self._metrics.provider_usage.get(provider.value, 0),\n                \"success_rate\": self._metrics.provider_success_rate.get(provider.value, 1.0),\n                \"capabilities\": {\n                    \"languages\": [l.value for l in PROVIDER_CAPABILITIES[provider].supported_languages],\n                    \"streaming\": PROVIDER_CAPABILITIES[provider].supports_streaming,\n                    \"code_switching\": PROVIDER_CAPABILITIES[provider].supports_code_switching,\n                    \"latency_ms\": PROVIDER_CAPABILITIES[provider].avg_latency_ms,\n                }\n            }\n            for provider in PROVIDER_CAPABILITIES\n        }\n\n\n# Singleton instance\n_parallel_stt_service: Optional[ParallelSTTService] = None\n\n\ndef get_parallel_stt_service() -> ParallelSTTService:\n    \"\"\"Get or create the singleton ParallelSTTService instance.\"\"\"\n    global _parallel_stt_service\n    if _parallel_stt_service is None:\n        _parallel_stt_service = ParallelSTTService()\n    return _parallel_stt_service\n\n\nasync def transcribe_parallel(\n    audio_data: bytes,\n    languages: Optional[List[LanguageCode]] = None,\n) -> ParallelTranscriptResult:\n    \"\"\"\n    Convenience function for parallel transcription.\n\n    Args:\n        audio_data: PCM16 audio bytes\n        languages: Language hints\n\n    Returns:\n        ParallelTranscriptResult\n    \"\"\"\n    service = get_parallel_stt_service()\n    await service.initialize()\n    return await service.transcribe_parallel(audio_data, languages)\n"
}
