{
  "path": "services/api-gateway/app/services/external_connectors.py",
  "language": "python",
  "size": 9814,
  "last_modified": "2025-12-04T11:26:56.849Z",
  "lines": 279,
  "content": "\"\"\"External data source connectors and periodic sync scheduler.\n\nProvides lightweight clients for OpenEvidence and PubMed along with a\nsimple asyncio-based scheduler to keep the local KB refreshed. The\nconnectors are intentionally resilient and accept injected HTTP clients\nor services for testing so that contract tests can run without hitting\nreal APIs.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport asyncio\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nfrom typing import TYPE_CHECKING, Any, Dict, Iterable, List, Optional\n\nimport httpx\nfrom app.core.config import settings\nfrom app.core.logging import get_logger\n\nlogger = get_logger(__name__)\n\nif TYPE_CHECKING:\n    from app.services.pubmed_enhanced_service import EnhancedPubMedService, PubMedArticle\n\n\n@dataclass\nclass ExternalRecord:\n    \"\"\"Normalized record pulled from an external evidence source.\"\"\"\n\n    id: str\n    title: str\n    summary: str\n    source: str\n    url: Optional[str] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n\n@dataclass\nclass SyncResult:\n    \"\"\"Result of a sync cycle for a connector.\"\"\"\n\n    source: str\n    fetched: int\n    stored: int\n    errors: List[str] = field(default_factory=list)\n    last_synced_at: datetime = field(default_factory=datetime.utcnow)\n\n\nclass OpenEvidenceConnector:\n    \"\"\"Connector for the OpenEvidence API.\"\"\"\n\n    name = \"openevidence\"\n\n    def __init__(\n        self,\n        api_key: Optional[str] = None,\n        base_url: str = \"https://api.openevidence.com\",\n        client: Optional[httpx.AsyncClient] = None,\n        default_topics: Optional[Iterable[str]] = None,\n        timeout: float = 10.0,\n    ) -> None:\n        self.api_key = api_key or settings.OPENEVIDENCE_API_KEY\n        self.base_url = base_url or settings.OPENEVIDENCE_BASE_URL\n        self.client = client\n        self.default_topics = list(default_topics or [\"cardiology\", \"infectious disease\"])\n        self.timeout = timeout\n\n    async def fetch_recent(self, query: str, limit: int = 5) -> List[ExternalRecord]:\n        \"\"\"Fetch recent evidence for a query.\n\n        Returns empty results when credentials are missing to avoid noisy\n        failures in environments without API keys.\n        \"\"\"\n\n        if not self.api_key and self.client is None:\n            logger.warning(\"OpenEvidence API key missing; returning no results\")\n            return []\n\n        headers = {}\n        if self.api_key:\n            headers[\"Authorization\"] = f\"Bearer {self.api_key}\"\n\n        close_client = False\n        client = self.client\n        if client is None:\n            client = httpx.AsyncClient(base_url=self.base_url, headers=headers, timeout=self.timeout)\n            close_client = True\n\n        try:\n            response = await client.get(\"/v1/search\", params={\"q\": query, \"limit\": limit})\n            response.raise_for_status()\n            payload = response.json()\n            records: List[ExternalRecord] = []\n\n            for raw in payload.get(\"results\", []):\n                record = ExternalRecord(\n                    id=str(raw.get(\"id\") or raw.get(\"uid\") or raw.get(\"reference_id\", \"\")),\n                    title=raw.get(\"title\") or \"Untitled evidence\",\n                    summary=raw.get(\"summary\") or raw.get(\"abstract\", \"\"),\n                    source=self.name,\n                    url=raw.get(\"url\"),\n                    metadata={\n                        \"source_type\": raw.get(\"source_type\", self.name),\n                        \"score\": raw.get(\"score\"),\n                        \"quality\": raw.get(\"quality\"),\n                    },\n                )\n                records.append(record)\n\n            return records\n        except httpx.HTTPError as exc:  # pragma: no cover - network failures\n            logger.error(\"OpenEvidence request failed: %s\", exc)\n            return []\n        finally:\n            if close_client:\n                await client.aclose()\n\n    async def sync(self, topics: Optional[Iterable[str]] = None) -> SyncResult:\n        \"\"\"Sync a set of topics from OpenEvidence.\"\"\"\n\n        queries = list(topics or self.default_topics)\n        fetched_records: List[ExternalRecord] = []\n        errors: List[str] = []\n\n        for topic in queries:\n            try:\n                fetched_records.extend(await self.fetch_recent(topic))\n            except Exception as exc:  # noqa: BLE001\n                logger.error(\"OpenEvidence sync failed for topic %s\", topic, exc_info=True)\n                errors.append(str(exc))\n\n        return SyncResult(\n            source=self.name,\n            fetched=len(fetched_records),\n            stored=len(fetched_records),  # Storage layer coming in future phases\n            errors=errors,\n        )\n\n\nclass PubMedConnector:\n    \"\"\"Connector for PubMed using EnhancedPubMedService.\"\"\"\n\n    name = \"pubmed\"\n\n    def __init__(\n        self,\n        service: Optional[\"EnhancedPubMedService\"] = None,\n        api_key: Optional[str] = None,\n        tool_email: Optional[str] = None,\n    ) -> None:\n        if service is None:\n            from app.services.pubmed_enhanced_service import EnhancedPubMedService\n\n            self.service = EnhancedPubMedService(api_key=api_key, email=tool_email)\n        else:\n            self.service = service\n        self.default_queries = [\"systematic review\", \"randomized trial\"]\n\n    async def fetch_recent(self, query: str, max_results: int = 5) -> List[ExternalRecord]:\n        \"\"\"Search PubMed for recent articles.\"\"\"\n\n        try:\n            search_result = await self.service.search(query=query, max_results=max_results, sort=\"pub_date\")\n        except Exception as exc:  # noqa: BLE001\n            logger.error(\"PubMed search failed for '%s': %s\", query, exc)\n            return []\n\n        return [self._to_record(article) for article in search_result.articles]\n\n    async def sync(self, queries: Optional[Iterable[str]] = None) -> SyncResult:\n        \"\"\"Sync recent PubMed articles for common clinical queries.\"\"\"\n\n        topics = list(queries or self.default_queries)\n        fetched_records: List[ExternalRecord] = []\n        errors: List[str] = []\n\n        for topic in topics:\n            try:\n                fetched_records.extend(await self.fetch_recent(topic))\n            except Exception as exc:  # noqa: BLE001\n                logger.error(\"PubMed sync failed for topic %s\", topic, exc_info=True)\n                errors.append(str(exc))\n\n        return SyncResult(\n            source=self.name,\n            fetched=len(fetched_records),\n            stored=len(fetched_records),\n            errors=errors,\n        )\n\n    def _to_record(self, article: \"PubMedArticle\") -> ExternalRecord:\n        \"\"\"Normalize PubMed article into ExternalRecord.\"\"\"\n\n        return ExternalRecord(\n            id=article.pmid,\n            title=article.title,\n            summary=article.abstract or article.citation,\n            source=self.name,\n            url=f\"https://pubmed.ncbi.nlm.nih.gov/{article.pmid}/\",\n            metadata={\n                \"source_type\": \"pubmed\",\n                \"doi\": article.doi,\n                \"status\": article.status.value if article.status else None,\n                \"publication_types\": article.publication_types,\n            },\n        )\n\n\nclass ExternalSyncScheduler:\n    \"\"\"Simple scheduler to run external connector syncs periodically.\"\"\"\n\n    def __init__(\n        self,\n        connectors: Iterable[object],\n        default_interval_minutes: int = 180,\n        per_connector_intervals: Optional[Dict[str, int]] = None,\n        tick_seconds: Optional[float] = None,\n    ) -> None:\n        self.connectors = list(connectors)\n        self.default_interval_minutes = default_interval_minutes\n        self.per_connector_intervals = per_connector_intervals or {}\n        self.tick_seconds = tick_seconds\n        self._tasks: List[asyncio.Task] = []\n        self._stop_event = asyncio.Event()\n\n    async def start(self) -> None:\n        \"\"\"Start background sync tasks for each connector.\"\"\"\n\n        self._stop_event.clear()\n        for connector in self.connectors:\n            interval = self.per_connector_intervals.get(getattr(connector, \"name\", \"\"), self.default_interval_minutes)\n            if interval <= 0:\n                logger.info(\n                    \"Skipping connector %s because interval is %s\",\n                    getattr(connector, \"name\", \"unknown\"),\n                    interval,\n                )\n                continue\n\n            task = asyncio.create_task(self._run_connector(connector, interval))\n            self._tasks.append(task)\n\n        logger.info(\"Started %d external sync tasks\", len(self._tasks))\n\n    async def stop(self) -> None:\n        \"\"\"Stop background tasks and wait for completion.\"\"\"\n\n        self._stop_event.set()\n        for task in self._tasks:\n            task.cancel()\n            try:\n                await task\n            except asyncio.CancelledError:\n                logger.debug(\"Cancelled sync task\")\n\n        self._tasks.clear()\n\n    async def _run_connector(self, connector: object, interval_minutes: int) -> None:\n        \"\"\"Run a connector on an interval until stopped.\"\"\"\n\n        interval_seconds = self.tick_seconds if self.tick_seconds is not None else max(interval_minutes, 1) * 60\n\n        while not self._stop_event.is_set():\n            try:\n                sync_method = getattr(connector, \"sync\")\n                await sync_method()\n            except Exception as exc:  # noqa: BLE001\n                logger.error(\n                    \"External sync failed for %s: %s\",\n                    getattr(connector, \"name\", \"unknown\"),\n                    exc,\n                )\n\n            try:\n                await asyncio.wait_for(self._stop_event.wait(), timeout=interval_seconds)\n            except asyncio.TimeoutError:\n                continue\n"
}
