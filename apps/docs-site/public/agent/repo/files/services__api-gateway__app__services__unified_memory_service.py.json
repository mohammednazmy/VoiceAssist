{
  "path": "services/api-gateway/app/services/unified_memory_service.py",
  "language": "python",
  "size": 20909,
  "last_modified": "2025-12-04T21:30:58.283Z",
  "lines": 654,
  "content": "\"\"\"\nUnified Conversation Memory Service\nMaintains context across voice and text interactions with cross-modal support.\n\nPart of Voice Mode Enhancement Plan v4.1 - Workstream 5\nReference: docs/voice/unified-memory.md\n\nFeatures:\n- Cross-modal context: Shared memory between voice and text modes\n- Language switching events: Tracks when users switch languages\n- Mode transition handling: Preserves context when switching voice â†” text\n- Session persistence: Maintains memory across browser refreshes\n- Privacy controls: User-controlled memory retention\n\"\"\"\n\nimport json\nimport logging\nfrom dataclasses import dataclass, field\nfrom datetime import datetime, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Literal, Optional\n\nfrom pydantic import BaseModel, Field\n\nlogger = logging.getLogger(__name__)\n\n\nclass ConversationMode(str, Enum):\n    \"\"\"Conversation interaction mode.\"\"\"\n\n    VOICE = \"voice\"\n    TEXT = \"text\"\n\n\nclass EventType(str, Enum):\n    \"\"\"Types of memory events.\"\"\"\n\n    MODE_SWITCH = \"mode_switch\"\n    LANGUAGE_SWITCH = \"language_switch\"\n    TOPIC_CHANGE = \"topic_change\"\n    PHI_DETECTED = \"phi_detected\"\n    RAG_RETRIEVAL = \"rag_retrieval\"\n\n\n@dataclass\nclass MemoryEntry:\n    \"\"\"Single memory entry in the conversation.\"\"\"\n\n    id: str\n    session_id: str\n    user_id: str\n    timestamp: datetime\n\n    # Content\n    role: Literal[\"user\", \"assistant\", \"system\"]\n    content: str\n    mode: ConversationMode\n\n    # Context\n    language: str = \"en\"\n    detected_language: str = \"en\"\n    language_switched: bool = False\n\n    # RAG context\n    retrieved_passages: List[str] = field(default_factory=list)\n    sources: List[Dict] = field(default_factory=list)\n\n    # Metadata\n    latency_ms: Optional[float] = None\n    degradations: List[str] = field(default_factory=list)\n    phi_detected: bool = False\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for serialization.\"\"\"\n        return {\n            \"id\": self.id,\n            \"session_id\": self.session_id,\n            \"user_id\": self.user_id,\n            \"timestamp\": self.timestamp.isoformat(),\n            \"role\": self.role,\n            \"content\": self.content,\n            \"mode\": self.mode.value if isinstance(self.mode, ConversationMode) else self.mode,\n            \"language\": self.language,\n            \"detected_language\": self.detected_language,\n            \"language_switched\": self.language_switched,\n            \"retrieved_passages\": self.retrieved_passages,\n            \"sources\": self.sources,\n            \"latency_ms\": self.latency_ms,\n            \"degradations\": self.degradations,\n            \"phi_detected\": self.phi_detected,\n        }\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> \"MemoryEntry\":\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(\n            id=data[\"id\"],\n            session_id=data[\"session_id\"],\n            user_id=data[\"user_id\"],\n            timestamp=datetime.fromisoformat(data[\"timestamp\"]),\n            role=data[\"role\"],\n            content=data[\"content\"],\n            mode=ConversationMode(data[\"mode\"]) if isinstance(data[\"mode\"], str) else data[\"mode\"],\n            language=data.get(\"language\", \"en\"),\n            detected_language=data.get(\"detected_language\", \"en\"),\n            language_switched=data.get(\"language_switched\", False),\n            retrieved_passages=data.get(\"retrieved_passages\", []),\n            sources=data.get(\"sources\", []),\n            latency_ms=data.get(\"latency_ms\"),\n            degradations=data.get(\"degradations\", []),\n            phi_detected=data.get(\"phi_detected\", False),\n        )\n\n\n@dataclass\nclass MemoryEvent:\n    \"\"\"Event in the conversation timeline.\"\"\"\n\n    event_type: EventType\n    timestamp: datetime\n    data: Dict[str, Any] = field(default_factory=dict)\n\n\nclass ConversationContext(BaseModel):\n    \"\"\"Context retrieved for LLM prompt building.\"\"\"\n\n    messages: List[Dict] = Field(default_factory=list)\n    language_history: List[Dict] = Field(default_factory=list)\n    mode_history: List[Dict] = Field(default_factory=list)\n    current_language: str = \"en\"\n    current_mode: str = \"text\"\n    rag_context: List[Dict] = Field(default_factory=list)\n\n\nclass MemorySettings(BaseModel):\n    \"\"\"User's memory and privacy preferences.\"\"\"\n\n    enabled: bool = True\n    retention_days: int = 30\n    cross_session: bool = True\n    save_voice_transcripts: bool = True\n    save_rag_context: bool = True\n    anonymize_phi: bool = True\n\n\nclass UnifiedMemoryService:\n    \"\"\"\n    Unified conversation memory service for cross-modal context.\n\n    Provides:\n    - Shared memory between voice and text modes\n    - Language and mode switch tracking\n    - Session persistence via Redis\n    - Context building for LLM prompts\n    - Privacy-respecting memory management\n    \"\"\"\n\n    # Default TTLs\n    SESSION_TTL = 86400  # 24 hours\n    SHORT_TERM_TTL = 86400 * 7  # 7 days\n    MAX_MESSAGES = 50\n\n    def __init__(\n        self,\n        redis_client=None,\n        postgres_client=None,\n    ):\n        self.redis = redis_client\n        self.postgres = postgres_client\n        self._local_cache: Dict[str, List[MemoryEntry]] = {}\n        self._events_cache: Dict[str, List[MemoryEvent]] = {}\n        self._settings_cache: Dict[str, MemorySettings] = {}\n\n    async def _get_redis(self):\n        \"\"\"Get Redis client lazily.\"\"\"\n        if self.redis is None:\n            try:\n                from app.core.redis import get_redis_client\n\n                self.redis = await get_redis_client()\n            except Exception as e:\n                logger.warning(f\"Redis not available: {e}\")\n        return self.redis\n\n    def _generate_id(self) -> str:\n        \"\"\"Generate unique memory entry ID.\"\"\"\n        import uuid\n\n        return str(uuid.uuid4())\n\n    async def add_entry(\n        self,\n        session_id: str,\n        user_id: str,\n        entry: MemoryEntry,\n    ) -> None:\n        \"\"\"\n        Add a memory entry to the conversation.\n\n        Args:\n            session_id: Session identifier\n            user_id: User identifier\n            entry: Memory entry to add\n        \"\"\"\n        # Ensure entry has required fields\n        if not entry.id:\n            entry.id = self._generate_id()\n        entry.session_id = session_id\n        entry.user_id = user_id\n        if not entry.timestamp:\n            entry.timestamp = datetime.now(timezone.utc)\n\n        # Add to local cache\n        cache_key = session_id\n        if cache_key not in self._local_cache:\n            self._local_cache[cache_key] = []\n\n        self._local_cache[cache_key].append(entry)\n\n        # Trim to max messages\n        if len(self._local_cache[cache_key]) > self.MAX_MESSAGES:\n            self._local_cache[cache_key] = self._local_cache[cache_key][-self.MAX_MESSAGES :]\n\n        # Persist to Redis\n        redis = await self._get_redis()\n        if redis:\n            try:\n                redis_key = f\"memory:{session_id}\"\n                data = json.dumps([e.to_dict() for e in self._local_cache[cache_key]])\n                await redis.setex(redis_key, self.SESSION_TTL, data)\n            except Exception as e:\n                logger.warning(f\"Failed to persist memory to Redis: {e}\")\n\n        logger.debug(\n            \"Memory entry added\",\n            extra={\n                \"session_id\": session_id,\n                \"entry_id\": entry.id,\n                \"role\": entry.role,\n                \"mode\": entry.mode.value if isinstance(entry.mode, ConversationMode) else entry.mode,\n                \"language\": entry.language,\n            },\n        )\n\n    async def add_event(\n        self,\n        session_id: str,\n        event_type: EventType,\n        data: Dict[str, Any],\n    ) -> None:\n        \"\"\"\n        Add an event to the conversation timeline.\n\n        Args:\n            session_id: Session identifier\n            event_type: Type of event\n            data: Event data\n        \"\"\"\n        event = MemoryEvent(\n            event_type=event_type,\n            timestamp=datetime.now(timezone.utc),\n            data=data,\n        )\n\n        # Add to local cache\n        if session_id not in self._events_cache:\n            self._events_cache[session_id] = []\n        self._events_cache[session_id].append(event)\n\n        # Persist to Redis\n        redis = await self._get_redis()\n        if redis:\n            try:\n                redis_key = f\"events:{session_id}\"\n                events_data = [\n                    {\n                        \"event_type\": e.event_type.value,\n                        \"timestamp\": e.timestamp.isoformat(),\n                        \"data\": e.data,\n                    }\n                    for e in self._events_cache[session_id]\n                ]\n                await redis.setex(redis_key, self.SESSION_TTL, json.dumps(events_data))\n            except Exception as e:\n                logger.warning(f\"Failed to persist event to Redis: {e}\")\n\n        logger.info(\n            f\"Memory event added: {event_type.value}\",\n            extra={\"session_id\": session_id, \"event_type\": event_type.value, \"data\": data},\n        )\n\n    async def get_context(\n        self,\n        session_id: str,\n        max_messages: int = 10,\n        include_rag: bool = True,\n    ) -> ConversationContext:\n        \"\"\"\n        Get conversation context for LLM prompt building.\n\n        Args:\n            session_id: Session identifier\n            max_messages: Maximum messages to include\n            include_rag: Whether to include RAG context\n\n        Returns:\n            ConversationContext with messages and metadata\n        \"\"\"\n        # Get from local cache or Redis\n        entries = await self.get_history(session_id, max_messages)\n\n        # Build messages list\n        messages = []\n        for entry in entries:\n            messages.append(\n                {\n                    \"role\": entry.role,\n                    \"content\": entry.content,\n                    \"mode\": entry.mode.value if isinstance(entry.mode, ConversationMode) else entry.mode,\n                    \"language\": entry.language,\n                }\n            )\n\n        # Get language events\n        language_events = await self.get_events(session_id, EventType.LANGUAGE_SWITCH, limit=5)\n\n        # Get mode events\n        mode_events = await self.get_events(session_id, EventType.MODE_SWITCH, limit=5)\n\n        # Determine current language and mode\n        current_language = \"en\"\n        current_mode = \"text\"\n        if entries:\n            current_language = entries[-1].language\n            current_mode = (\n                entries[-1].mode.value if isinstance(entries[-1].mode, ConversationMode) else entries[-1].mode\n            )\n\n        # Collect RAG context\n        rag_context = []\n        if include_rag:\n            for entry in entries:\n                if entry.sources:\n                    rag_context.extend(entry.sources)\n\n        return ConversationContext(\n            messages=messages,\n            language_history=[\n                {\"from_language\": e.data.get(\"from_language\"), \"to_language\": e.data.get(\"to_language\")}\n                for e in language_events\n            ],\n            mode_history=[\n                {\"from_mode\": e.data.get(\"from_mode\"), \"to_mode\": e.data.get(\"to_mode\")} for e in mode_events\n            ],\n            current_language=current_language,\n            current_mode=current_mode,\n            rag_context=rag_context[-5:] if rag_context else [],  # Last 5 sources\n        )\n\n    async def get_history(\n        self,\n        session_id: str,\n        max_messages: int = 50,\n    ) -> List[MemoryEntry]:\n        \"\"\"\n        Get conversation history for a session.\n\n        Args:\n            session_id: Session identifier\n            max_messages: Maximum messages to return\n\n        Returns:\n            List of MemoryEntry objects\n        \"\"\"\n        # Check local cache first\n        if session_id in self._local_cache:\n            return self._local_cache[session_id][-max_messages:]\n\n        # Try Redis\n        redis = await self._get_redis()\n        if redis:\n            try:\n                redis_key = f\"memory:{session_id}\"\n                data = await redis.get(redis_key)\n                if data:\n                    entries_data = json.loads(data)\n                    entries = [MemoryEntry.from_dict(e) for e in entries_data]\n                    self._local_cache[session_id] = entries\n                    return entries[-max_messages:]\n            except Exception as e:\n                logger.warning(f\"Failed to load memory from Redis: {e}\")\n\n        return []\n\n    async def get_events(\n        self,\n        session_id: str,\n        event_type: Optional[EventType] = None,\n        limit: int = 10,\n    ) -> List[MemoryEvent]:\n        \"\"\"\n        Get events from the conversation timeline.\n\n        Args:\n            session_id: Session identifier\n            event_type: Optional filter by event type\n            limit: Maximum events to return\n\n        Returns:\n            List of MemoryEvent objects\n        \"\"\"\n        # Check local cache\n        if session_id in self._events_cache:\n            events = self._events_cache[session_id]\n        else:\n            # Try Redis\n            events = []\n            redis = await self._get_redis()\n            if redis:\n                try:\n                    redis_key = f\"events:{session_id}\"\n                    data = await redis.get(redis_key)\n                    if data:\n                        events_data = json.loads(data)\n                        events = [\n                            MemoryEvent(\n                                event_type=EventType(e[\"event_type\"]),\n                                timestamp=datetime.fromisoformat(e[\"timestamp\"]),\n                                data=e[\"data\"],\n                            )\n                            for e in events_data\n                        ]\n                        self._events_cache[session_id] = events\n                except Exception as e:\n                    logger.warning(f\"Failed to load events from Redis: {e}\")\n\n        # Filter by type if specified\n        if event_type:\n            events = [e for e in events if e.event_type == event_type]\n\n        return events[-limit:]\n\n    async def track_language_switch(\n        self,\n        session_id: str,\n        from_language: str,\n        to_language: str,\n        trigger: str = \"auto_detected\",\n    ) -> None:\n        \"\"\"\n        Track when user switches languages.\n\n        Args:\n            session_id: Session identifier\n            from_language: Previous language code\n            to_language: New language code\n            trigger: What triggered the switch (user_request, auto_detected, explicit_setting)\n        \"\"\"\n        await self.add_event(\n            session_id=session_id,\n            event_type=EventType.LANGUAGE_SWITCH,\n            data={\n                \"from_language\": from_language,\n                \"to_language\": to_language,\n                \"trigger\": trigger,\n                \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            },\n        )\n\n    async def handle_mode_switch(\n        self,\n        session_id: str,\n        from_mode: ConversationMode,\n        to_mode: ConversationMode,\n    ) -> ConversationContext:\n        \"\"\"\n        Handle mode switch while preserving context.\n\n        Args:\n            session_id: Session identifier\n            from_mode: Previous mode\n            to_mode: New mode\n\n        Returns:\n            Conversation context for new mode\n        \"\"\"\n        # Add mode switch event\n        await self.add_event(\n            session_id=session_id,\n            event_type=EventType.MODE_SWITCH,\n            data={\n                \"from_mode\": from_mode.value,\n                \"to_mode\": to_mode.value,\n                \"timestamp\": datetime.now(timezone.utc).isoformat(),\n            },\n        )\n\n        # Return context for new mode\n        return await self.get_context(session_id)\n\n    async def extend_ttl(self, session_id: str) -> None:\n        \"\"\"Extend session TTL.\"\"\"\n        redis = await self._get_redis()\n        if redis:\n            try:\n                await redis.expire(f\"memory:{session_id}\", self.SESSION_TTL)\n                await redis.expire(f\"events:{session_id}\", self.SESSION_TTL)\n            except Exception as e:\n                logger.warning(f\"Failed to extend TTL: {e}\")\n\n    async def delete_session(self, session_id: str) -> None:\n        \"\"\"Delete all memory for a session.\"\"\"\n        # Clear local cache\n        self._local_cache.pop(session_id, None)\n        self._events_cache.pop(session_id, None)\n\n        # Clear Redis\n        redis = await self._get_redis()\n        if redis:\n            try:\n                await redis.delete(f\"memory:{session_id}\")\n                await redis.delete(f\"events:{session_id}\")\n            except Exception as e:\n                logger.warning(f\"Failed to delete session from Redis: {e}\")\n\n        logger.info(f\"Session memory deleted: {session_id}\")\n\n    async def delete_user_memory(\n        self,\n        user_id: str,\n        scope: Literal[\"session\", \"day\", \"all\"] = \"session\",\n    ) -> None:\n        \"\"\"\n        Delete user's conversation memory.\n\n        Args:\n            user_id: User identifier\n            scope: Deletion scope (session, day, or all)\n        \"\"\"\n        # Find sessions for this user\n        sessions_to_delete = []\n\n        for session_id, entries in self._local_cache.items():\n            if entries and entries[0].user_id == user_id:\n                if scope == \"all\":\n                    sessions_to_delete.append(session_id)\n                elif scope == \"day\":\n                    # Check if entries are from today\n                    today = datetime.now(timezone.utc).date()\n                    if any(e.timestamp.date() == today for e in entries):\n                        sessions_to_delete.append(session_id)\n\n        for session_id in sessions_to_delete:\n            await self.delete_session(session_id)\n\n        logger.info(f\"Deleted memory for user {user_id}, scope: {scope}\")\n\n    async def get_user_settings(self, user_id: str) -> MemorySettings:\n        \"\"\"Get user's memory settings.\"\"\"\n        if user_id in self._settings_cache:\n            return self._settings_cache[user_id]\n        return MemorySettings()\n\n    async def update_user_settings(\n        self,\n        user_id: str,\n        settings: MemorySettings,\n    ) -> None:\n        \"\"\"Update user's memory settings.\"\"\"\n        self._settings_cache[user_id] = settings\n\n        # Persist to Redis\n        redis = await self._get_redis()\n        if redis:\n            try:\n                await redis.setex(\n                    f\"memory_settings:{user_id}\",\n                    86400 * 365,  # 1 year TTL\n                    settings.model_dump_json(),\n                )\n            except Exception as e:\n                logger.warning(f\"Failed to persist settings: {e}\")\n\n\nasync def build_llm_context(\n    session_id: str,\n    current_query: str,\n    rag_results: List[Dict],\n    memory_service: UnifiedMemoryService,\n) -> List[Dict]:\n    \"\"\"\n    Build context for LLM including memory.\n\n    Args:\n        session_id: Session identifier\n        current_query: Current user query\n        rag_results: RAG retrieval results\n        memory_service: Unified memory service instance\n\n    Returns:\n        List of messages for LLM\n    \"\"\"\n    # Get conversation history\n    history = await memory_service.get_history(session_id, max_messages=10)\n\n    # Get language switches\n    language_events = await memory_service.get_events(session_id, EventType.LANGUAGE_SWITCH, limit=5)\n\n    # Build messages array\n    messages = []\n\n    # Build system prompt with context\n    system_content = \"You are a helpful medical assistant.\"\n    if language_events:\n        recent_lang = language_events[-1].data.get(\"to_language\", \"en\")\n        system_content += f\" The user's current language preference is {recent_lang}.\"\n\n    if rag_results:\n        context_texts = [f\"[{i+1}] {r.get('content', '')}\" for i, r in enumerate(rag_results[:5])]\n        system_content += \"\\n\\nRelevant context:\\n\" + \"\\n\\n\".join(context_texts)\n\n    messages.append({\"role\": \"system\", \"content\": system_content})\n\n    # Add conversation history\n    for entry in history:\n        messages.append(\n            {\n                \"role\": entry.role,\n                \"content\": entry.content,\n            }\n        )\n\n    # Add current query\n    messages.append(\n        {\n            \"role\": \"user\",\n            \"content\": current_query,\n        }\n    )\n\n    return messages\n\n\n# Singleton instance\n_unified_memory_service: Optional[UnifiedMemoryService] = None\n\n\nasync def get_unified_memory_service() -> UnifiedMemoryService:\n    \"\"\"Get or create unified memory service instance.\"\"\"\n    global _unified_memory_service\n    if _unified_memory_service is None:\n        _unified_memory_service = UnifiedMemoryService()\n    return _unified_memory_service\n"
}
