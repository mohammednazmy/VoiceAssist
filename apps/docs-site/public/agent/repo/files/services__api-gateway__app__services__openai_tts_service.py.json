{
  "path": "services/api-gateway/app/services/openai_tts_service.py",
  "language": "python",
  "size": 15673,
  "last_modified": "2025-12-04T11:26:58.897Z",
  "lines": 467,
  "content": "\"\"\"\nOpenAI TTS Service\n\nFallback TTS provider using OpenAI's text-to-speech API.\nProvides streaming audio synthesis as a resilient alternative to ElevenLabs.\n\nPhase: Voice Feature Hardening\n- TTS Provider Failover implementation\n- Automatic fallback when ElevenLabs is unavailable\n- Circuit breaker protection\n\nVoices:\n- alloy: Balanced, versatile\n- echo: Warm, natural\n- fable: British, expressive\n- onyx: Deep, authoritative (male)\n- nova: Friendly, conversational (female)\n- shimmer: Clear, warm (female)\n\"\"\"\n\nimport time\nfrom dataclasses import dataclass\nfrom typing import AsyncIterator, List, Optional\n\nimport httpx\nfrom app.core.config import settings\nfrom app.core.logging import get_logger\nfrom app.core.resilience import openai_tts_breaker, retry_openai_tts_operation\nfrom pybreaker import CircuitBreakerError\n\nlogger = get_logger(__name__)\n\n\n# ==============================================================================\n# Data Classes\n# ==============================================================================\n\n\n@dataclass\nclass OpenAIVoice:\n    \"\"\"Metadata for an OpenAI TTS voice.\"\"\"\n\n    voice_id: str\n    name: str\n    description: str\n    gender: str  # \"male\", \"female\", \"neutral\"\n\n\n@dataclass\nclass OpenAITTSResult:\n    \"\"\"Result of OpenAI TTS synthesis.\"\"\"\n\n    audio_data: bytes\n    content_type: str  # \"audio/mpeg\", \"audio/opus\", \"audio/aac\", \"audio/flac\", \"audio/pcm\"\n    latency_ms: int\n    voice_id: str\n    model: str\n\n\n# ==============================================================================\n# Voice Catalog\n# ==============================================================================\n\nOPENAI_VOICES: List[OpenAIVoice] = [\n    OpenAIVoice(\n        voice_id=\"alloy\",\n        name=\"Alloy\",\n        description=\"Balanced and versatile voice\",\n        gender=\"neutral\",\n    ),\n    OpenAIVoice(\n        voice_id=\"echo\",\n        name=\"Echo\",\n        description=\"Warm and natural voice\",\n        gender=\"male\",\n    ),\n    OpenAIVoice(\n        voice_id=\"fable\",\n        name=\"Fable\",\n        description=\"British, expressive voice\",\n        gender=\"neutral\",\n    ),\n    OpenAIVoice(\n        voice_id=\"onyx\",\n        name=\"Onyx\",\n        description=\"Deep, authoritative voice\",\n        gender=\"male\",\n    ),\n    OpenAIVoice(\n        voice_id=\"nova\",\n        name=\"Nova\",\n        description=\"Friendly, conversational voice\",\n        gender=\"female\",\n    ),\n    OpenAIVoice(\n        voice_id=\"shimmer\",\n        name=\"Shimmer\",\n        description=\"Clear, warm voice\",\n        gender=\"female\",\n    ),\n]\n\n# Voice ID mapping: ElevenLabs voice ID -> OpenAI voice\nELEVENLABS_TO_OPENAI_VOICE_MAP = {\n    # Premium male voices -> onyx or echo\n    \"pNInz6obpgDQGcFmaJgB\": \"onyx\",  # Adam -> onyx\n    \"TxGEqnHWrfWFTfGW9XjX\": \"echo\",  # Josh -> echo\n    \"ErXwobaYiN019PkySvjV\": \"echo\",  # Antoni -> echo\n    \"VR6AewLTigWG4xSOukaG\": \"onyx\",  # Arnold -> onyx\n    \"yoZ06aMxZJJ28mfd3POQ\": \"echo\",  # Sam -> echo\n    # Premium female voices -> nova or shimmer\n    \"EXAVITQu4vr4xnSDxMaL\": \"nova\",  # Bella -> nova\n    \"21m00Tcm4TlvDq8ikWAM\": \"shimmer\",  # Rachel -> shimmer\n    \"AZnzlk1XvdvUeBnXmlld\": \"nova\",  # Domi -> nova\n    \"MF3mGyEYCl7XYWbV9V6O\": \"shimmer\",  # Elli -> shimmer\n    # Conversational voices (warm, natural)\n    \"nPczCjzI2devNBz1zQrb\": \"echo\",  # Brian -> echo (friendly male)\n    \"XB0fDUnXU5powFXDhCwa\": \"shimmer\",  # Charlotte -> shimmer (calm female)\n    \"XrExE9yKIg1WjnnlVkGX\": \"nova\",  # Matilda -> nova (friendly female)\n    \"JBFqnCBsd6RMkjVDRZzb\": \"onyx\",  # George -> onyx (British male)\n    \"IKne3meq5aSn9XLyUdCD\": \"echo\",  # Charlie -> echo (conversational male)\n    \"pFZP5JQG7iQjIQuC4Bku\": \"shimmer\",  # Lily -> shimmer (warm female)\n    \"N2lVS1w4EtoT3dr4eOWO\": \"fable\",  # Callum -> fable (character male)\n    \"onwK4e9ZLuTAKqWW03F9\": \"onyx\",  # Daniel -> onyx (deep male)\n    \"Xb7hH8MSUJpSbSDYk0k2\": \"nova\",  # Alice -> nova (confident female)\n}\n\n\ndef map_elevenlabs_voice_to_openai(elevenlabs_voice_id: str) -> str:\n    \"\"\"\n    Map an ElevenLabs voice ID to the closest OpenAI voice.\n\n    Args:\n        elevenlabs_voice_id: ElevenLabs voice ID\n\n    Returns:\n        OpenAI voice ID (defaults to \"alloy\" if not mapped)\n    \"\"\"\n    return ELEVENLABS_TO_OPENAI_VOICE_MAP.get(elevenlabs_voice_id, \"alloy\")\n\n\n# ==============================================================================\n# Service Implementation\n# ==============================================================================\n\n\nclass OpenAITTSService:\n    \"\"\"\n    OpenAI Text-to-Speech service for fallback TTS.\n\n    Features:\n    - Streaming audio for low latency playback\n    - Multiple voice options\n    - HD quality model option\n    - Circuit breaker protection\n    - Connection warming for reduced latency\n\n    Models:\n    - tts-1: Optimized for speed (lower latency)\n    - tts-1-hd: Optimized for quality (higher latency)\n    \"\"\"\n\n    # API endpoints\n    BASE_URL = \"https://api.openai.com/v1\"\n    TTS_ENDPOINT = \"/audio/speech\"\n\n    # Models\n    MODEL_STANDARD = \"tts-1\"  # Fast, optimized for real-time\n    MODEL_HD = \"tts-1-hd\"  # Higher quality, more latency\n\n    # Output formats\n    FORMAT_MP3 = \"mp3\"  # Default, widely supported\n    FORMAT_OPUS = \"opus\"  # Efficient for web/streaming\n    FORMAT_AAC = \"aac\"  # Good for mobile\n    FORMAT_FLAC = \"flac\"  # Lossless\n    FORMAT_PCM = \"pcm\"  # Raw audio (16-bit little-endian)\n\n    # Limits\n    MAX_TEXT_LENGTH = 4096\n\n    def __init__(self):\n        self.api_key = settings.OPENAI_API_KEY\n        self.enabled = bool(self.api_key)\n        self.default_model = self.MODEL_STANDARD  # Prioritize speed for voice\n        self.default_voice = \"alloy\"\n        self._connection_warmed = False\n        self._http_client: Optional[httpx.AsyncClient] = None\n\n    def is_enabled(self) -> bool:\n        \"\"\"Check if OpenAI TTS is enabled and configured.\"\"\"\n        return self.enabled\n\n    async def _get_http_client(self) -> httpx.AsyncClient:\n        \"\"\"Get or create the persistent HTTP client.\"\"\"\n        if self._http_client is None or self._http_client.is_closed:\n            self._http_client = httpx.AsyncClient(\n                timeout=60.0,\n                limits=httpx.Limits(\n                    max_keepalive_connections=5,\n                    max_connections=10,\n                ),\n            )\n        return self._http_client\n\n    async def warm_connection(self) -> bool:\n        \"\"\"\n        Pre-warm the HTTP connection to OpenAI API.\n\n        Establishes TCP + TLS connection to reduce first-request latency.\n\n        Returns:\n            True if connection was warmed successfully\n        \"\"\"\n        if not self.enabled:\n            return False\n\n        if self._connection_warmed:\n            return True\n\n        try:\n            client = await self._get_http_client()\n            # Simple HEAD request to establish connection\n            response = await client.head(\n                f\"{self.BASE_URL}/models\",\n                headers={\"Authorization\": f\"Bearer {self.api_key}\"},\n            )\n            self._connection_warmed = response.status_code in (200, 401, 403)\n            logger.debug(\n                \"OpenAI TTS connection warmed\",\n                extra={\"status_code\": response.status_code},\n            )\n            return self._connection_warmed\n        except Exception as e:\n            logger.warning(f\"Failed to warm OpenAI TTS connection: {e}\")\n            return False\n\n    def get_voices(self) -> List[OpenAIVoice]:\n        \"\"\"Get available OpenAI TTS voices.\"\"\"\n        return OPENAI_VOICES.copy()\n\n    @retry_openai_tts_operation(max_attempts=2)\n    async def synthesize(\n        self,\n        text: str,\n        voice: str = \"alloy\",\n        model: str = \"tts-1\",\n        speed: float = 1.0,\n        response_format: str = \"mp3\",\n    ) -> OpenAITTSResult:\n        \"\"\"\n        Synthesize speech from text (non-streaming).\n\n        Args:\n            text: Text to synthesize (max 4096 chars)\n            voice: Voice ID (alloy, echo, fable, onyx, nova, shimmer)\n            model: Model to use (tts-1, tts-1-hd)\n            speed: Speech speed (0.25 to 4.0)\n            response_format: Output format (mp3, opus, aac, flac, pcm)\n\n        Returns:\n            OpenAITTSResult with audio data\n\n        Raises:\n            ValueError: If service is disabled or request fails\n            CircuitBreakerError: If circuit breaker is open\n        \"\"\"\n        if not self.enabled:\n            raise ValueError(\"OpenAI TTS is not configured\")\n\n        if len(text) > self.MAX_TEXT_LENGTH:\n            raise ValueError(f\"Text exceeds maximum length of {self.MAX_TEXT_LENGTH}\")\n\n        # Check circuit breaker\n        try:\n            openai_tts_breaker.call(lambda: None)\n        except CircuitBreakerError:\n            logger.error(\"OpenAI TTS circuit breaker is OPEN - failing fast\")\n            raise\n\n        start_time = time.time()\n\n        try:\n            client = await self._get_http_client()\n            response = await client.post(\n                f\"{self.BASE_URL}{self.TTS_ENDPOINT}\",\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\",\n                },\n                json={\n                    \"model\": model,\n                    \"input\": text,\n                    \"voice\": voice,\n                    \"response_format\": response_format,\n                    \"speed\": max(0.25, min(4.0, speed)),\n                },\n            )\n\n            if response.status_code != 200:\n                error_text = response.text\n                logger.error(\n                    \"OpenAI TTS synthesis failed\",\n                    extra={\n                        \"status_code\": response.status_code,\n                        \"error\": error_text[:200],\n                    },\n                )\n                raise ValueError(f\"OpenAI TTS failed: {response.status_code}\")\n\n            audio_data = response.content\n            latency_ms = int((time.time() - start_time) * 1000)\n\n            # Content type mapping\n            content_type_map = {\n                \"mp3\": \"audio/mpeg\",\n                \"opus\": \"audio/opus\",\n                \"aac\": \"audio/aac\",\n                \"flac\": \"audio/flac\",\n                \"pcm\": \"audio/pcm\",\n            }\n\n            logger.info(\n                \"OpenAI TTS synthesis complete\",\n                extra={\n                    \"voice\": voice,\n                    \"model\": model,\n                    \"text_length\": len(text),\n                    \"audio_size\": len(audio_data),\n                    \"latency_ms\": latency_ms,\n                },\n            )\n\n            return OpenAITTSResult(\n                audio_data=audio_data,\n                content_type=content_type_map.get(response_format, \"audio/mpeg\"),\n                latency_ms=latency_ms,\n                voice_id=voice,\n                model=model,\n            )\n\n        except httpx.TimeoutException as e:\n            logger.error(f\"OpenAI TTS timeout: {e}\")\n            raise ValueError(\"OpenAI TTS request timed out\")\n        except httpx.HTTPError as e:\n            logger.error(f\"OpenAI TTS HTTP error: {e}\")\n            raise ValueError(f\"OpenAI TTS request failed: {e}\")\n\n    @retry_openai_tts_operation(max_attempts=2)\n    async def synthesize_stream(\n        self,\n        text: str,\n        voice: str = \"alloy\",\n        model: str = \"tts-1\",\n        speed: float = 1.0,\n        response_format: str = \"pcm\",\n        chunk_size: int = 4096,\n    ) -> AsyncIterator[bytes]:\n        \"\"\"\n        Stream synthesized speech from text.\n\n        Args:\n            text: Text to synthesize (max 4096 chars)\n            voice: Voice ID (alloy, echo, fable, onyx, nova, shimmer)\n            model: Model to use (tts-1, tts-1-hd)\n            speed: Speech speed (0.25 to 4.0)\n            response_format: Output format (pcm recommended for streaming)\n            chunk_size: Size of audio chunks to yield\n\n        Yields:\n            Audio data chunks\n\n        Raises:\n            ValueError: If service is disabled or request fails\n            CircuitBreakerError: If circuit breaker is open\n        \"\"\"\n        if not self.enabled:\n            raise ValueError(\"OpenAI TTS is not configured\")\n\n        if len(text) > self.MAX_TEXT_LENGTH:\n            raise ValueError(f\"Text exceeds maximum length of {self.MAX_TEXT_LENGTH}\")\n\n        # Check circuit breaker\n        try:\n            openai_tts_breaker.call(lambda: None)\n        except CircuitBreakerError:\n            logger.error(\"OpenAI TTS circuit breaker is OPEN - failing fast\")\n            raise\n\n        start_time = time.time()\n        first_chunk_time: Optional[float] = None\n        total_bytes = 0\n\n        try:\n            client = await self._get_http_client()\n\n            async with client.stream(\n                \"POST\",\n                f\"{self.BASE_URL}{self.TTS_ENDPOINT}\",\n                headers={\n                    \"Authorization\": f\"Bearer {self.api_key}\",\n                    \"Content-Type\": \"application/json\",\n                },\n                json={\n                    \"model\": model,\n                    \"input\": text,\n                    \"voice\": voice,\n                    \"response_format\": response_format,\n                    \"speed\": max(0.25, min(4.0, speed)),\n                },\n            ) as response:\n                if response.status_code != 200:\n                    error_text = await response.aread()\n                    logger.error(\n                        \"OpenAI TTS streaming failed\",\n                        extra={\n                            \"status_code\": response.status_code,\n                            \"error\": error_text.decode()[:200],\n                        },\n                    )\n                    raise ValueError(f\"OpenAI TTS failed: {response.status_code}\")\n\n                async for chunk in response.aiter_bytes(chunk_size):\n                    if chunk:\n                        if first_chunk_time is None:\n                            first_chunk_time = time.time()\n                            ttfb_ms = int((first_chunk_time - start_time) * 1000)\n                            logger.debug(\n                                \"OpenAI TTS first chunk\",\n                                extra={\n                                    \"voice\": voice,\n                                    \"ttfb_ms\": ttfb_ms,\n                                },\n                            )\n                        total_bytes += len(chunk)\n                        yield chunk\n\n            total_latency_ms = int((time.time() - start_time) * 1000)\n            logger.info(\n                \"OpenAI TTS streaming complete\",\n                extra={\n                    \"voice\": voice,\n                    \"model\": model,\n                    \"text_length\": len(text),\n                    \"total_bytes\": total_bytes,\n                    \"total_latency_ms\": total_latency_ms,\n                    \"ttfb_ms\": (int((first_chunk_time - start_time) * 1000) if first_chunk_time else None),\n                },\n            )\n\n        except httpx.TimeoutException as e:\n            logger.error(f\"OpenAI TTS stream timeout: {e}\")\n            raise ValueError(\"OpenAI TTS stream timed out\")\n        except httpx.HTTPError as e:\n            logger.error(f\"OpenAI TTS stream HTTP error: {e}\")\n            raise ValueError(f\"OpenAI TTS stream failed: {e}\")\n\n    async def close(self):\n        \"\"\"Close the HTTP client.\"\"\"\n        if self._http_client and not self._http_client.is_closed:\n            await self._http_client.aclose()\n            self._http_client = None\n            self._connection_warmed = False\n\n\n# Singleton instance\nopenai_tts_service = OpenAITTSService()\n"
}
